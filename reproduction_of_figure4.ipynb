{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n",
      "import package finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from data_generator_glad import *\n",
    "import pickle as pkl\n",
    "print(\"import package finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "K_train = 10 # 10\n",
    "M = 100\n",
    "N = 100 # number of features\n",
    "graph_type = \"random_maxd\"\n",
    "SAMPLE_BATCHES = 10\n",
    "w_min = -1\n",
    "w_max = 1\n",
    "SIGNS = 0\n",
    "K_test = 100 # 100\n",
    "prob = 0.1\n",
    "MAX_DEG = 50\n",
    "K_valid = 10\n",
    "data_path = \"./data/syn/Ktrain{}_Ktest{}_M{}_N{}_prob{}.pkl\".format(K_train, K_test, M, N, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data_helper(graphs):\n",
    "    theta, s = [], [] # precision_mat, samples covariance mat\n",
    "    for g_num in graphs:\n",
    "        precision_mat, data = graphs[g_num] # data = M x N\n",
    "        theta.append(precision_mat)\n",
    "        s.append(np.matmul(data.T, data)/(M))\n",
    "        # check whether the diagonals are all positive\n",
    "        if np.all(s[-1].diagonal() > 0) == False:\n",
    "            print('Diagonals of emp cov matrix are negative: CHECK', s, s[-1].diagonal())\n",
    "#        else:\n",
    "#            print('Diagonals of emp cov matrix are positive:', s[-1].diagonal())\n",
    "\n",
    "    theta = np.array(theta)\n",
    "    s     = np.array(s)\n",
    "\n",
    "    # plt.figure()\n",
    "    # seaborn.heatmap(theta[0], cmap=\"pink_r\", vmax=1)\n",
    "    # plt.show()\n",
    "\n",
    "    return [theta, s]\n",
    "\n",
    "def prepare_data(mn):\n",
    "    train_data = prepare_data_helper(mn.train_graphs)\n",
    "    valid_data = []\n",
    "    if K_valid > 0:\n",
    "        valid_data = prepare_data_helper(mn.valid_graphs)\n",
    "    test_data  = prepare_data_helper(mn.test_graphs)\n",
    "    return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load finished.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(data_path):\n",
    "    print(\"Generating data...\")\n",
    "    mn = create_MN_vary_w(K_train, M, N, graph_type, SAMPLE_BATCHES, [w_min, w_max], K_test, [prob, MAX_DEG, SIGNS], K_valid)\n",
    "    train_data, valid_data, test_data = prepare_data(mn)\n",
    "    print(\"Data generation finished.\")\n",
    "\n",
    "    with open(data_path, 'wb') as f:\n",
    "        pkl.dump({\"train_data\":train_data, \"valid_data\":valid_data, \"test_data\":test_data}, f)\n",
    "\n",
    "else:\n",
    "    with open(data_path, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "        train_data, valid_data, test_data = data['train_data'], data['valid_data'], data['test_data']\n",
    "print(\"data load finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training\n",
    "\n",
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import training needed packages\n"
     ]
    }
   ],
   "source": [
    "from unrolled_model import *\n",
    "from torch.optim.lr_scheduler import LambdaLR, StepLR, MultiStepLR, ExponentialLR, ReduceLROnPlateau\n",
    "import random\n",
    "import metrics\n",
    "print(\"import training needed packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True\n",
    "USE_CUDA = True\n",
    "L = 30\n",
    "rho_init = 1\n",
    "lambda_init = 1\n",
    "theta_init_offset = 1e-2\n",
    "gamma_init = 0.1\n",
    "nF = 3\n",
    "H = 3\n",
    "init_lr = 0.001\n",
    "use_optimizer = 'adam'\n",
    "batch_size = 1\n",
    "train_epochs = 10\n",
    "INIT_DIAG = 0\n",
    "lossBCE = 0\n",
    "loss_signed = 0\n",
    "lossL1 = 0\n",
    "model_path = \"M{}_N{}_Ktrain{}_gt{}_prob{}_bs{}_L{}_lr{}.pth\".format(M, N, K_train, graph_type, prob, batch_size, L, init_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train validate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_glasso(data, valid_data=[]):  # tied lista\n",
    "    #    torch.set_grad_enabled(True)\n",
    "    print('training GLASSO')\n",
    "    theta, S = data\n",
    "    #    theta = theta[0]\n",
    "    if len(valid_data) > 0:\n",
    "        valid_theta, valid_S = valid_data\n",
    "        valid_theta_true = convert_to_torch(valid_theta, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "        valid_S = convert_to_torch(valid_S, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "    # theta -> K_train x N x N (Matrix)\n",
    "    # S -> K_train x N x N (observed vector)\n",
    "    # train using ALISTA style training.\n",
    "    # model = threshold_NN_lambda_single_model(L, rho_init, lambda_init, theta_init_offset, gamma_init, N, nF, H, USE_CUDA=USE_CUDA)\n",
    "    model = threshold_NN_lambda_unrolled_model(L, rho_init, lambda_init, theta_init_offset, gamma_init, N, nF, H, USE_CUDA=USE_CUDA)\n",
    "\n",
    "    model.train()\n",
    "    theta_true = convert_to_torch(theta, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "    S = convert_to_torch(S, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "\n",
    "    zero = torch.Tensor([0])  # .type(self.dtype)\n",
    "\n",
    "    #    print('check: theta ', theta_init.shape)\n",
    "    #    print('true: ', theta_true)\n",
    "    print('parameters to be learned')\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.shape, param.requires_grad)\n",
    "    dtype = torch.FloatTensor\n",
    "    if USE_CUDA:\n",
    "        model = model.cuda()\n",
    "        zero = zero.cuda()\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "\n",
    "    lr = init_lr\n",
    "    if use_optimizer == 'adadelta':\n",
    "        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, rho=0.9, eps=1e-06,\n",
    "                                         weight_decay=0)  # LR range = 5 ->\n",
    "    elif use_optimizer == 'rms':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.25,\n",
    "                                        centered=False)\n",
    "    elif use_optimizer == 'sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, dampening=0, weight_decay=0,\n",
    "                                    nesterov=False)\n",
    "    elif use_optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "    else:\n",
    "        print('Optimizer not found!')\n",
    "    # scheduler = MultiStepLR(optimizer, milestones=[1000], gamma=0.5)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[10, 15, 20, 25, 100, 200], gamma=0.25)\n",
    "    # scheduler = MultiStepLR(optimizer, milestones=[10, 15, 20, 100, 200], gamma=0.25)\n",
    "    # scheduler = MultiStepLR(optimizer, milestones=[10, 20, 30, 200], gamma=0.5)\n",
    "    # criterion = nn.MSELoss(reduction=\"sum\")  # input, target\n",
    "    criterion = nn.MSELoss()  # input, target\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    m_sig = nn.Sigmoid()\n",
    "    criterionBCE = nn.BCELoss()\n",
    "\n",
    "    # batch size is fixed\n",
    "    #    num_batches = int(args.K_train/args.batch_size)\n",
    "    #    if args.SAMPLE_BATCHES > 0:\n",
    "    #        num_batches = int(args.K_train*args.SAMPLE_BATCHES/args.batch_size)\n",
    "\n",
    "    num_batches = int(len(S) / batch_size)\n",
    "\n",
    "    #    if args.K_train >= 10:\n",
    "    #        args.batch_size = 10\n",
    "    # best_shd_model = model\n",
    "    best_valid_shd, best_valid_ps, best_valid_nmse = np.inf, -1 * np.inf, np.inf\n",
    "    EARLY_STOP = False\n",
    "    for epoch in range(train_epochs):  # 1 epoch is expected to go through complete data\n",
    "        scheduler.step()\n",
    "        #        if epoch%1==0:\n",
    "        #            for param_group in optimizer.param_groups:\n",
    "        #                print('epoch: ', epoch, ' lr ', param_group['lr'])\n",
    "        epoch_loss = []\n",
    "        frob_loss = []\n",
    "        duality_gap = []\n",
    "        mse_binary_loss = []\n",
    "        bce_loss = []\n",
    "        if EARLY_STOP:\n",
    "            break\n",
    "        #        print('ecpohc ', epoch)\n",
    "        for batch_num in range(num_batches):  # processing batchwise\n",
    "            optimizer.zero_grad()\n",
    "            # resetting the loss to zero\n",
    "            loss = torch.Tensor([0]).type(dtype)\n",
    "            # Get a batch\n",
    "            # ridx = random.sample(list(range(args.K_train)), args.batch_size)\n",
    "            ridx = random.sample(list(range(len(S))), batch_size)\n",
    "            Sb = S[ridx]  # [0]\n",
    "            #            print('errr train check : ', batch_num, theta_true, Sb, theta_true.expand_as(Sb))\n",
    "\n",
    "            if INIT_DIAG == 1:\n",
    "                # print(' extract batchwise diagonals, add offset and take inverse')\n",
    "                batch_diags = 1 / (torch.diagonal(Sb, offset=0, dim1=-2, dim2=-1) + model.theta_init_offset)\n",
    "                theta_init = torch.diag_embed(batch_diags)\n",
    "            else:\n",
    "                # print('***************** (S+theta_offset*I)^-1 is used')\n",
    "                theta_init = torch.inverse(\n",
    "                    Sb + model.theta_init_offset * torch.eye(Sb.shape[-1]).expand_as(Sb).type_as(Sb))\n",
    "\n",
    "\n",
    "            # theta_pred = S_inv[r_idx]\n",
    "            # ll = torch.cholesky(theta_init[ridx])#(theta_pred) # lower triangular\n",
    "            # ll = my_cholesky(theta_init[ridx][0])#(theta_pred) # lower triangular\n",
    "            # ll = batch_cholesky(theta_init[ridx])#(theta_pred) # lower triangular\n",
    "            theta_pred = theta_init  # [ridx]\n",
    "            # theta_pred = theta_init[ridx]\n",
    "            # theta_pred.requires_grad = True\n",
    "            # Sb = S[ridx][0]\n",
    "            # step_size = get_init_step_size(theta_init[ridx])\n",
    "            identity_mat = torch.eye(Sb.shape[-1]).expand_as(Sb)\n",
    "            if USE_CUDA == True:\n",
    "                identity_mat = identity_mat.cuda()\n",
    "            # print('ERRR check: ', theta_pred.shape, get_frobenius_norm(theta_pred), get_frobenius_norm(theta_pred).shape)\n",
    "            # lambda_k = model.lambda_f(get_frobenius_norm(theta_pred))\n",
    "            lambda_k = model.lambda_forward(zero + lambda_init, zero, k=0)\n",
    "            for k in range(L):\n",
    "                #                print('itr = ', itr, theta_pred)#, theta_true[ridx])\n",
    "                # step 1 : AM\n",
    "                b = 1.0 / lambda_k * Sb - theta_pred\n",
    "                b2_4ac = torch.matmul(b.transpose(-1, -2), b) + 4.0 / lambda_k * identity_mat\n",
    "                sqrt_term = batch_matrix_sqrt(b2_4ac)\n",
    "                theta_k1 = 1.0 / 2 * (-1 * b + sqrt_term)\n",
    "                \"\"\"\n",
    "                # extract the diagonals of the matrices\n",
    "                theta_diag = torch.diag_embed(torch.diagonal(theta_k1, offset=0, dim1=-2, dim2=-1))\n",
    "                # soft threshold on remaining entries \n",
    "                theta_pred = model.eta_forward(theta_k1-theta_diag, k)\n",
    "                # add the diagonals\n",
    "                theta_pred = theta_pred + theta_diag\n",
    "                \"\"\"\n",
    "                # softthresholding on all the entries\n",
    "                # theta_pred = model.eta_forward(theta_k1, k)\n",
    "\n",
    "                # if MODEL_type == 'th':\n",
    "                #     # soft thresholding + eigenvalue correctness term\n",
    "                #     theta_pred = model.eta_forward(theta_k1, k) + torch.max(model.gamma_c[k],\n",
    "                #                                                             zero + 1e-2) * identity_mat\n",
    "                # elif MODEL_type == 'th_NN':\n",
    "                theta_pred = model.eta_forward(theta_k1, Sb, k, theta_pred)  #\n",
    "                # update the lambda\n",
    "                lambda_k = model.lambda_forward(torch.Tensor([get_frobenius_norm(theta_pred - theta_k1)]).type(dtype),\n",
    "                                                lambda_k, k)\n",
    "                # accumulating loss\n",
    "                #                print('k= ', k, ' lambda_value ', lambda_k, get_frobenius_norm(theta_pred-theta_k1))\n",
    "\n",
    "                loss += criterion(theta_pred, theta_true[ridx]) / L\n",
    "                # loss += criterion(theta_pred, theta_true.expand_as(theta_pred))/args.L\n",
    "\n",
    "            #            print('k= ', k, ' lambda_value ', lambda_k)\n",
    "            # print('thetapred: ', theta_pred, check_sym(theta_pred[0].data.cpu().numpy()))\n",
    "            # delta = batch_duality_gap(theta_pred, Sb, model.rho)\n",
    "            # NOTE: ******* IMP: Change thissss!@!! ****************************\n",
    "            delta = torch.ones([1]) * -1\n",
    "\n",
    "            loss += criterion(theta_pred, theta_true[ridx]) / L\n",
    "\n",
    "            # loss += criterion(theta_pred, theta_true.expand_as(theta_pred))/args.L\n",
    "\n",
    "            lossf = get_frobenius_norm(theta_pred - theta_true[ridx])\n",
    "            # total_loss = loss #+ delta\n",
    "            # total_loss = lossB #+ loss #+ delta\n",
    "            # total_loss = loss + lossB+ delta + lossBCE\n",
    "            #            total_loss = lossBCE\n",
    "            # total_loss = delta\n",
    "            if lossBCE == 1:  # binary cross entropy\n",
    "                total_loss = lossBCE\n",
    "            elif loss_signed == 1:  # signed loss\n",
    "                # total_loss = criterion(torch.sign(theta_pred), torch.sign(theta_true.expand_as(theta_pred)))\n",
    "                total_loss = criterion(theta_pred, torch.sign(theta_true.expand_as(theta_pred)))\n",
    "            elif lossL1 == 1:  # signed loss\n",
    "                total_loss = criterion_L1(theta_pred, theta_true.expand_as(theta_pred))\n",
    "            else:  # frobenius norm\n",
    "                total_loss = loss\n",
    "                # total_loss = lossf\n",
    "            #            total_loss.requires_grad = True\n",
    "            #            print('err: ', total_loss, total_loss.requires_grad)\n",
    "\n",
    "            lv = loss.data.cpu().numpy()\n",
    "            if lv <= 1e-7:  # loss value\n",
    "                print('Early stopping as loss = ', lv)\n",
    "                EARLY_STOP = True\n",
    "                break\n",
    "\n",
    "            total_loss.backward()\n",
    "            # delta.backward()\n",
    "\n",
    "            #            for name, param in model.named_parameters():\n",
    "            #                print('befoer: ', name, param)\n",
    "            optimizer.step()\n",
    "\n",
    "            #            for name, param in model.named_parameters():\n",
    "            #                print('after: ', name, param)\n",
    "\n",
    "            #            mse_binary_loss.append(lossB.data.cpu().numpy())\n",
    "            #            bce_loss.append(lossBCE.data.cpu().numpy())\n",
    "            #            duality_gap.append(delta.data.cpu().numpy())\n",
    "            frob_loss.append(lossf.data.cpu().numpy())\n",
    "            epoch_loss.append(loss.data.cpu().numpy())\n",
    "        if epoch % 2 == 0 and EARLY_STOP == False:\n",
    "            # print(len(epoch_loss))\n",
    "            # print('loss_summary: MSE: ', sum(epoch_loss)/len(epoch_loss), ' Mean Frobenius loss: ',sum(frob_loss)/len(frob_loss), ' MSE_binary loss: ', sum(mse_binary_loss)/len(mse_binary_loss), 'BCE_loss: ', sum(bce_loss)/len(bce_loss), 'duality gap = ', sum(duality_gap)/len(duality_gap))\n",
    "            print('loss_summary: MSE: ', sum(epoch_loss)/len(epoch_loss), ' Mean Frobenius loss: ',sum(frob_loss)/len(frob_loss))\n",
    "            if lossBCE == 1:\n",
    "                print(epoch, sum(epoch_loss) / len(epoch_loss), sum(bce_loss) / len(bce_loss))\n",
    "            else:\n",
    "                print('loss_values: ', epoch, sum(epoch_loss) / len(epoch_loss))  # , sum(duality_gap)/len(duality_gap))\n",
    "        # Checking the results on valid data and updating the best model\n",
    "        if len(valid_data) > 0:\n",
    "            # get the SHD on the valid data and the train data\n",
    "            # curr_valid_shd, curr_valid_nmse = glasso_predict(model, valid_data)\n",
    "            curr_valid_shd, curr_valid_ps, curr_valid_nmse, curr_valid_gmse = glasso_predict(model, valid_data)\n",
    "            curr_train_shd, curr_train_ps, curr_train_nmse, curr_valid_gmse = glasso_predict(model, data)\n",
    "            print('valid/train: shd %0.2f/%0.2f ps %0.2f/%0.2f nmse %0.2f/%0.2f' % (\n",
    "            curr_valid_shd, curr_train_shd, curr_valid_ps, curr_train_ps, curr_valid_nmse, curr_train_nmse))\n",
    "            #            if curr_valid_shd <= best_valid_shd:\n",
    "            if curr_valid_ps >= best_valid_ps:\n",
    "                print('epoch = ', epoch, ' Updating the best ps model with valid ps = ', curr_valid_ps)\n",
    "                best_ps_model = copy.deepcopy(model)\n",
    "                best_valid_ps = curr_valid_ps\n",
    "\n",
    "            if curr_valid_shd <= best_valid_shd:\n",
    "                print('epoch = ', epoch, ' Updating the best shd model with valid shd = ', curr_valid_shd)\n",
    "                best_shd_model = copy.deepcopy(model)\n",
    "                best_valid_shd = curr_valid_shd\n",
    "\n",
    "            if curr_valid_nmse <= best_valid_nmse:\n",
    "                print('epoch = ', epoch, ' Updating the best nmse model with valid nmse = ', curr_valid_nmse)\n",
    "                best_nmse_model = copy.deepcopy(model)\n",
    "                best_valid_nmse = curr_valid_nmse\n",
    "                print('epoch = ', epoch, ' Updating the best nmse model with valid gmse = ', curr_valid_gmse)\n",
    "            model.train()\n",
    "            print('loss_summary:: epoch: ', epoch, ' loss: ', sum(epoch_loss)/len(epoch_loss))#, ' NMSE loss: ', 10*np.log10( (np.sum(np.array(epoch_loss)))/(len(epoch_loss)*E_norm_xtrue)))\n",
    "    #    print('ans: ', theta_pred)\n",
    "    #    print('true: ', theta_true)\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param)\n",
    "    # return best_ps_model # model\n",
    "    return best_nmse_model, best_shd_model, best_ps_model  # model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glasso_predict(model, data, flagP=False, SAVE_GRAPH=False, eM=0, name='', mn=''):\n",
    "    with torch.no_grad():\n",
    "        print('Running unrolled ADMM predict')\n",
    "        # predict as a complete batch?\n",
    "        model.eval()\n",
    "        criterion = nn.MSELoss()  # input, target\n",
    "        m_sig = nn.Sigmoid()\n",
    "        criterionBCE = nn.BCELoss()\n",
    "        theta, S = data\n",
    "        #    theta = theta[0]\n",
    "        # theta -> K_train x N x N (Matrix)\n",
    "        # S -> K_train x N x N (observed vector)\n",
    "        # theta_true = convert_to_torch(theta, TESTING_FLAG=True, USE_CUDA=False)\n",
    "        theta_true = convert_to_torch(theta, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "        S = convert_to_torch(S, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "\n",
    "        zero = torch.Tensor([0])  # .type(self.dtype)\n",
    "        dtype = torch.FloatTensor\n",
    "        if USE_CUDA == True:\n",
    "            zero = zero.cuda()\n",
    "            model = model.cuda()\n",
    "            dtype = torch.cuda.FloatTensor\n",
    "\n",
    "        # batch size is fixed for testing as 1\n",
    "        batch_size = 1\n",
    "        print('CEHCKK: Total graphs = ', len(S))\n",
    "        num_batches = int(len(S) / batch_size)\n",
    "        #    print('num batches: ', num_batches)\n",
    "        epoch_loss = []\n",
    "        mse_binary_loss = []\n",
    "        bce_loss = []\n",
    "        frob_loss = []\n",
    "        duality_gap = []\n",
    "        ans = []\n",
    "        if flagP:\n",
    "            res_conv = {}\n",
    "            for k in range(L + 1):\n",
    "                res_conv[k] = []\n",
    "        #        print('ITR, conv.loss, obj_val_pred, obj_val_true_model_rho, obj_val_pred_args_rho')#, theta_pred)\n",
    "\n",
    "        res = []\n",
    "        for batch_num in range(num_batches):  # processing batchwise\n",
    "            # Get a batch\n",
    "            # ll = my_cholesky(theta_init[ridx][0])#(theta_pred) # lower triangular\n",
    "            # theta_pred = theta_init[batch_num*batch_size: (batch_num+1)*batch_size] #(theta_pred) # lower triangular\n",
    "            # theta_true_b = theta_true[batch_num*batch_size: (batch_num+1)*batch_size]\n",
    "            theta_true_b = theta_true[batch_num * batch_size: (batch_num + 1) * batch_size]\n",
    "            Sb = S[batch_num * batch_size: (batch_num + 1) * batch_size]  # [0]\n",
    "            identity_mat = torch.eye(Sb.shape[-1]).expand_as(Sb)\n",
    "            if USE_CUDA == True:\n",
    "                identity_mat = identity_mat.cuda()\n",
    "                Sb = Sb.cuda()\n",
    "            #    theta_pred = theta_pred.cuda()\n",
    "            #    theta_true_b = theta_true_b.cuda()\n",
    "\n",
    "            if INIT_DIAG == 1:\n",
    "                # print(' extract batchwise diagonals, add offset and take inverse')\n",
    "                batch_diags = 1 / (torch.diagonal(Sb, offset=0, dim1=-2, dim2=-1) + model.theta_init_offset)\n",
    "                theta_pred = torch.diag_embed(batch_diags)\n",
    "            else:\n",
    "                # print('***************** (S+theta_offset*I)^-1 is used')\n",
    "                theta_pred = torch.inverse(\n",
    "                    Sb + model.theta_init_offset * torch.eye(Sb.shape[-1]).expand_as(Sb).type_as(Sb))\n",
    "\n",
    "            # lambda_k = model.lambda_f(get_frobenius_norm(theta_pred))\n",
    "            lambda_k = model.lambda_forward(zero + lambda_init, zero, k=0)\n",
    "\n",
    "            #        if flagP:\n",
    "            #            print('ITR, conv.loss, obj_val_pred, obj_val_true_model_rho, obj_val_pred_args_rho')#, theta_pred)\n",
    "            for k in range(L):\n",
    "                #            start = time.time()\n",
    "                if flagP:\n",
    "                    theta_pred_diag = torch.diag_embed(torch.diagonal(theta_pred[0], offset=0, dim1=-2, dim2=-1))\n",
    "                    # theta_true_b_diag = torch.diag_embed(torch.diagonal(theta_true_b[0], offset=0, dim1=-2, dim2=-1))\n",
    "                    theta_true_b_diag = torch.diag_embed(torch.diagonal(theta_true_b, offset=0, dim1=-2, dim2=-1))\n",
    "                    # if MODEL_type == 'th':\n",
    "                    #     cv_loss, cv_loss_off_diag, obj_pred, obj_true_rho, obj_true_orig = get_convergence_loss(\n",
    "                    #         theta_pred[0], theta_true_b), get_convergence_loss(theta_pred[0] - theta_pred_diag,\n",
    "                    #                                                            theta_true_b - theta_true_b_diag), get_obj_val(\n",
    "                    #         theta_pred[0], Sb[0], model.rho_l1[k]), get_obj_val(theta_true_b, Sb[0],\n",
    "                    #                                                             model.rho_l1[k]), get_obj_val(\n",
    "                    #         theta_true_b, Sb[0], rho_init)\n",
    "                    #     res_conv[k].append([cv_loss, obj_pred, obj_true_rho, obj_true_orig, cv_loss_off_diag])\n",
    "                    # elif MODEL_type == 'th_NN':\n",
    "                    cv_loss, cv_loss_off_diag = get_convergence_loss(theta_pred[0],\n",
    "                                                                         theta_true_b), -1  # get_convergence_loss(theta_pred[0]-theta_pred_diag, theta_true_b-theta_true_b_diag)\n",
    "                    res_conv[k].append([cv_loss, cv_loss_off_diag])\n",
    "                # step 1 : AM\n",
    "                b = 1.0 / lambda_k * Sb - theta_pred\n",
    "                b2_4ac = torch.matmul(b.transpose(-1, -2), b) + 4.0 / lambda_k * identity_mat\n",
    "                sqrt_term = batch_matrix_sqrt(b2_4ac)\n",
    "                theta_k1 = 1.0 / 2 * (-1 * b + sqrt_term)\n",
    "\n",
    "                # step 2 : AM\n",
    "                \"\"\" \n",
    "                # extract the diagonals of the matrices\n",
    "                theta_diag = torch.diag_embed(torch.diagonal(theta_k1, offset=0, dim1=-2, dim2=-1))\n",
    "                # soft threshold on remaining entries \n",
    "                theta_pred = model.eta_forward(theta_k1-theta_diag, k)\n",
    "                # add the diagonals\n",
    "                theta_pred = theta_pred + theta_diag\n",
    "                \"\"\"\n",
    "                # soft thresholding on all the entries\n",
    "                # theta_pred = model.eta_forward(theta_k1, k)\n",
    "                # if MODEL_type == 'th':\n",
    "                #     # soft thresholding + eigenvalue correctness term\n",
    "                #     theta_pred = model.eta_forward(theta_k1, k) + torch.max(model.gamma_c[k],\n",
    "                #                                                             zero + 1e-2) * identity_mat\n",
    "                # elif MODEL_type == 'th_NN':\n",
    "                    # theta_pred = model.eta_forward(theta_k1, Sb, k) + torch.max(model.gamma_c[k], zero+1e-2) * identity_mat\n",
    "                    # theta_pred = model.eta_forward(theta_k1, Sb, k, theta_pred) + torch.max(model.gamma_c[k], zero+1e-2) * identity_mat\n",
    "                theta_pred = model.eta_forward(theta_k1, Sb, k,\n",
    "                                                   theta_pred)  # + torch.max(model.gamma_c[k], zero+1e-2) * identity_mat\n",
    "\n",
    "                # updating lambda\n",
    "                lambda_k = model.lambda_forward(torch.Tensor([get_frobenius_norm(theta_pred - theta_k1)]).type(dtype),\n",
    "                                                lambda_k, k)\n",
    "                # lambda_k = model.lambda_f(get_frobenius_norm(theta_pred-theta_k1))\n",
    "            #            print('k= ', k, ' lambda_value ', lambda_k, get_frobenius_norm(theta_pred-theta_k1))\n",
    "            #            stop = time.time()\n",
    "            #            print('Walltimes: ', k, stop-start)\n",
    "            #        br\n",
    "            if flagP:\n",
    "                theta_pred_diag = torch.diag_embed(torch.diagonal(theta_pred[0], offset=0, dim1=-2, dim2=-1))\n",
    "                # Getting the final predicted convergence loss\n",
    "                if torch.min(torch.eig(theta_pred[0])[0][:, 0]) == 0:\n",
    "                    adjust_eval_identity = torch.eye(theta_pred.shape[-1]).expand_as(theta_pred[0]).type_as(\n",
    "                        theta_pred[0])\n",
    "                    print('Adjusting the minimum eigenvalue to 1, SHOULD NOT BE CALLED AFTER THE GAMMA ADDITION!')\n",
    "                    theta_pred[0] += adjust_eval_identity  # change the eigenval to 1\n",
    "                # if MODEL_type == 'th':\n",
    "                #     cv_loss, cv_loss_off_diag, obj_pred, obj_true_rho, obj_true_orig = get_convergence_loss(\n",
    "                #         theta_pred[0], theta_true_b), get_convergence_loss(theta_pred[0] - theta_pred_diag,\n",
    "                #                                                            theta_true_b - theta_true_b_diag), get_obj_val(\n",
    "                #         theta_pred[0], Sb[0], model.rho_l1[k]), get_obj_val(theta_true_b, Sb[0],\n",
    "                #                                                             model.rho_l1[k]), get_obj_val(theta_true_b,\n",
    "                #                                                                                           Sb[0],\n",
    "                #                                                                                           args.rho_init)\n",
    "                #     res_conv[k + 1].append([cv_loss, obj_pred, obj_true_rho, obj_true_orig, cv_loss_off_diag])\n",
    "                # elif MODEL_type == 'th_NN':\n",
    "                cv_loss, cv_loss_off_diag = get_convergence_loss(theta_pred[0],\n",
    "                                                                     theta_true_b), -1  # get_convergence_loss(theta_pred[0]-theta_pred_diag, theta_true_b-theta_true_b_diag)\n",
    "                res_conv[k + 1].append([cv_loss, cv_loss_off_diag])\n",
    "\n",
    "#             plt.figure()\n",
    "#             seaborn.heatmap(theta_pred[0].cpu().detach().numpy(),cmap=\"pink_r\")\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.figure()\n",
    "#             seaborn.heatmap(theta_true_b[0].cpu().detach().numpy(),cmap=\"pink_r\")\n",
    "#             plt.show()\n",
    "\n",
    "            final_nmse, final_gmse = get_convergence_loss(theta_pred[0], theta_true_b)\n",
    "            theta_pred = theta_pred[0].data.cpu().numpy()\n",
    "            #        theta_true_b = theta_true_b[0].data.cpu().numpy()\n",
    "            theta_true_b = theta_true_b.data.cpu().numpy()\n",
    "\n",
    "            fdr, tpr, fpr, shd, nnz, nnz_true, ps = metrics.report_metrics(theta_true_b, theta_pred)\n",
    "            cond_theta_pred, cond_theta_true_b = np.linalg.cond(theta_pred), -1  # np.linalg.cond(theta_true_b)\n",
    "            res.append([fdr, tpr, fpr, shd, nnz, nnz_true, ps, cond_theta_pred, cond_theta_true_b])\n",
    "\n",
    "        res_mean = np.mean(np.array(res), 0)\n",
    "        res_std = np.std(np.array(res), 0)\n",
    "        res_mean = [\"%.3f\" % x for x in res_mean]\n",
    "        res_std = [\"%.3f\" % x for x in res_std]\n",
    "\n",
    "        if flagP:\n",
    "            print('Structure learning Metrics')\n",
    "            print('Average result over test graphs')\n",
    "            # print('fdr, tpr, fpr, shd, nnz, nnz_true, np.linalg.cond(theta_pred), np.linalg.cond(theta_true)')\n",
    "            print('fdr, tpr, fpr, shd, nnz, nnz_true, ps, np.linalg.cond(theta_pred), np.linalg.cond(theta_true)')\n",
    "            print(*sum(list(map(list, zip(res_mean, res_std))), []), sep=', ')\n",
    "\n",
    "            # print('ITR, conv.loss, obj_val_pred, obj_val_true_model_rho, obj_val_pred_args_rho')#, theta_pred)\n",
    "            print(\n",
    "                'ITR, conv_loss\"ecoli_M\"+str(eM), obj_val_pred, obj_val_true_model_rho, obj_val_pred_args_rho, conv_loss_off_diag')  # , theta_pred)\n",
    "            for i in res_conv:\n",
    "                mean_vec = [\"%.3f\" % x for x in np.mean(res_conv[i], 0)]\n",
    "                std_vec = [\"%.3f\" % x for x in np.std(res_conv[i], 0)]\n",
    "                print(i, *sum(list(map(list, zip(mean_vec, std_vec))), []), sep=', ')\n",
    "        #            print(i, np.mean(res_conv[i], 0), np.std(res_conv[i], 0))\n",
    "\n",
    "        if SAVE_GRAPH:\n",
    "            x = np.where(theta_pred > 0, 1, 0)\n",
    "            A = np.matrix(x - np.eye(x.shape[0]))\n",
    "            G = nx.from_numpy_matrix(A)\n",
    "            fig = plt.figure(figsize=(15, 15))\n",
    "            mapping = {n1: n2 for n1, n2 in zip(G.nodes(), mn.nodes)}\n",
    "            G = nx.relabel_nodes(G, mapping)\n",
    "            # nx.draw_networkx(G, pos=nx.spring_layout(G), with_labels = True)\n",
    "            # nx.draw_networkx(G, pos=nx.circular_layout(G), with_labels = True)\n",
    "            nx.draw_networkx(G, pos=nx.shell_layout(G), with_labels=True)\n",
    "            plt.savefig(name + '_' + str(eM) + \".pdf\", bbox_inches='tight')\n",
    "            nx.draw_networkx(mn.G_true, pos=nx.shell_layout(G), with_labels=True)\n",
    "            plt.savefig(name + '_true_' + str(eM) + \".pdf\", bbox_inches='tight')\n",
    "            # saving the graph\n",
    "            # nx.write_gpickle(G, name+'_'+str(eM)+'.gpickle')\n",
    "            nx.write_adjlist(G, name + '_' + str(eM) + '.adjlist')\n",
    "\n",
    "        return np.float(res_mean[3]), np.float(res_mean[6]), final_nmse, final_gmse  # The PS mean value, final NMSE obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the glasso model\n",
      "check:  (100, 100, 100) (100, 100, 100)\n",
      "training GLASSO\n",
      "shifting to cuda\n",
      "CHECK RHO INITIAL:  Parameter containing:\n",
      "tensor([[ 0.0953,  0.0201, -0.5515],\n",
      "        [-0.3191,  0.3386, -0.2008],\n",
      "        [ 0.2312, -0.2043,  0.4499]], device='cuda:0', requires_grad=True)\n",
      "parameters to be learned\n",
      "theta_init_offset torch.Size([1]) True\n",
      "rho_l1.0.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.0.0.bias torch.Size([3]) True\n",
      "rho_l1.0.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.0.2.bias torch.Size([3]) True\n",
      "rho_l1.0.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.0.4.bias torch.Size([3]) True\n",
      "rho_l1.0.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.0.6.bias torch.Size([3]) True\n",
      "rho_l1.0.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.0.8.bias torch.Size([3]) True\n",
      "rho_l1.0.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.0.10.bias torch.Size([1]) True\n",
      "rho_l1.1.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.1.0.bias torch.Size([3]) True\n",
      "rho_l1.1.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.1.2.bias torch.Size([3]) True\n",
      "rho_l1.1.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.1.4.bias torch.Size([3]) True\n",
      "rho_l1.1.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.1.6.bias torch.Size([3]) True\n",
      "rho_l1.1.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.1.8.bias torch.Size([3]) True\n",
      "rho_l1.1.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.1.10.bias torch.Size([1]) True\n",
      "rho_l1.2.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.2.0.bias torch.Size([3]) True\n",
      "rho_l1.2.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.2.2.bias torch.Size([3]) True\n",
      "rho_l1.2.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.2.4.bias torch.Size([3]) True\n",
      "rho_l1.2.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.2.6.bias torch.Size([3]) True\n",
      "rho_l1.2.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.2.8.bias torch.Size([3]) True\n",
      "rho_l1.2.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.2.10.bias torch.Size([1]) True\n",
      "rho_l1.3.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.3.0.bias torch.Size([3]) True\n",
      "rho_l1.3.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.3.2.bias torch.Size([3]) True\n",
      "rho_l1.3.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.3.4.bias torch.Size([3]) True\n",
      "rho_l1.3.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.3.6.bias torch.Size([3]) True\n",
      "rho_l1.3.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.3.8.bias torch.Size([3]) True\n",
      "rho_l1.3.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.3.10.bias torch.Size([1]) True\n",
      "rho_l1.4.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.4.0.bias torch.Size([3]) True\n",
      "rho_l1.4.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.4.2.bias torch.Size([3]) True\n",
      "rho_l1.4.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.4.4.bias torch.Size([3]) True\n",
      "rho_l1.4.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.4.6.bias torch.Size([3]) True\n",
      "rho_l1.4.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.4.8.bias torch.Size([3]) True\n",
      "rho_l1.4.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.4.10.bias torch.Size([1]) True\n",
      "rho_l1.5.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.5.0.bias torch.Size([3]) True\n",
      "rho_l1.5.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.5.2.bias torch.Size([3]) True\n",
      "rho_l1.5.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.5.4.bias torch.Size([3]) True\n",
      "rho_l1.5.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.5.6.bias torch.Size([3]) True\n",
      "rho_l1.5.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.5.8.bias torch.Size([3]) True\n",
      "rho_l1.5.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.5.10.bias torch.Size([1]) True\n",
      "rho_l1.6.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.6.0.bias torch.Size([3]) True\n",
      "rho_l1.6.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.6.2.bias torch.Size([3]) True\n",
      "rho_l1.6.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.6.4.bias torch.Size([3]) True\n",
      "rho_l1.6.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.6.6.bias torch.Size([3]) True\n",
      "rho_l1.6.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.6.8.bias torch.Size([3]) True\n",
      "rho_l1.6.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.6.10.bias torch.Size([1]) True\n",
      "rho_l1.7.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.7.0.bias torch.Size([3]) True\n",
      "rho_l1.7.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.7.2.bias torch.Size([3]) True\n",
      "rho_l1.7.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.7.4.bias torch.Size([3]) True\n",
      "rho_l1.7.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.7.6.bias torch.Size([3]) True\n",
      "rho_l1.7.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.7.8.bias torch.Size([3]) True\n",
      "rho_l1.7.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.7.10.bias torch.Size([1]) True\n",
      "rho_l1.8.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.8.0.bias torch.Size([3]) True\n",
      "rho_l1.8.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.8.2.bias torch.Size([3]) True\n",
      "rho_l1.8.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.8.4.bias torch.Size([3]) True\n",
      "rho_l1.8.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.8.6.bias torch.Size([3]) True\n",
      "rho_l1.8.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.8.8.bias torch.Size([3]) True\n",
      "rho_l1.8.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.8.10.bias torch.Size([1]) True\n",
      "rho_l1.9.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.9.0.bias torch.Size([3]) True\n",
      "rho_l1.9.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.9.2.bias torch.Size([3]) True\n",
      "rho_l1.9.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.9.4.bias torch.Size([3]) True\n",
      "rho_l1.9.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.9.6.bias torch.Size([3]) True\n",
      "rho_l1.9.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.9.8.bias torch.Size([3]) True\n",
      "rho_l1.9.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.9.10.bias torch.Size([1]) True\n",
      "rho_l1.10.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.10.0.bias torch.Size([3]) True\n",
      "rho_l1.10.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.10.2.bias torch.Size([3]) True\n",
      "rho_l1.10.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.10.4.bias torch.Size([3]) True\n",
      "rho_l1.10.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.10.6.bias torch.Size([3]) True\n",
      "rho_l1.10.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.10.8.bias torch.Size([3]) True\n",
      "rho_l1.10.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.10.10.bias torch.Size([1]) True\n",
      "rho_l1.11.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.11.0.bias torch.Size([3]) True\n",
      "rho_l1.11.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.11.2.bias torch.Size([3]) True\n",
      "rho_l1.11.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.11.4.bias torch.Size([3]) True\n",
      "rho_l1.11.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.11.6.bias torch.Size([3]) True\n",
      "rho_l1.11.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.11.8.bias torch.Size([3]) True\n",
      "rho_l1.11.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.11.10.bias torch.Size([1]) True\n",
      "rho_l1.12.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.12.0.bias torch.Size([3]) True\n",
      "rho_l1.12.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.12.2.bias torch.Size([3]) True\n",
      "rho_l1.12.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.12.4.bias torch.Size([3]) True\n",
      "rho_l1.12.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.12.6.bias torch.Size([3]) True\n",
      "rho_l1.12.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.12.8.bias torch.Size([3]) True\n",
      "rho_l1.12.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.12.10.bias torch.Size([1]) True\n",
      "rho_l1.13.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.13.0.bias torch.Size([3]) True\n",
      "rho_l1.13.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.13.2.bias torch.Size([3]) True\n",
      "rho_l1.13.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.13.4.bias torch.Size([3]) True\n",
      "rho_l1.13.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.13.6.bias torch.Size([3]) True\n",
      "rho_l1.13.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.13.8.bias torch.Size([3]) True\n",
      "rho_l1.13.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.13.10.bias torch.Size([1]) True\n",
      "rho_l1.14.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.14.0.bias torch.Size([3]) True\n",
      "rho_l1.14.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.14.2.bias torch.Size([3]) True\n",
      "rho_l1.14.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.14.4.bias torch.Size([3]) True\n",
      "rho_l1.14.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.14.6.bias torch.Size([3]) True\n",
      "rho_l1.14.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.14.8.bias torch.Size([3]) True\n",
      "rho_l1.14.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.14.10.bias torch.Size([1]) True\n",
      "rho_l1.15.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.15.0.bias torch.Size([3]) True\n",
      "rho_l1.15.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.15.2.bias torch.Size([3]) True\n",
      "rho_l1.15.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.15.4.bias torch.Size([3]) True\n",
      "rho_l1.15.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.15.6.bias torch.Size([3]) True\n",
      "rho_l1.15.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.15.8.bias torch.Size([3]) True\n",
      "rho_l1.15.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.15.10.bias torch.Size([1]) True\n",
      "rho_l1.16.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.16.0.bias torch.Size([3]) True\n",
      "rho_l1.16.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.16.2.bias torch.Size([3]) True\n",
      "rho_l1.16.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.16.4.bias torch.Size([3]) True\n",
      "rho_l1.16.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.16.6.bias torch.Size([3]) True\n",
      "rho_l1.16.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.16.8.bias torch.Size([3]) True\n",
      "rho_l1.16.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.16.10.bias torch.Size([1]) True\n",
      "rho_l1.17.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.17.0.bias torch.Size([3]) True\n",
      "rho_l1.17.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.17.2.bias torch.Size([3]) True\n",
      "rho_l1.17.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.17.4.bias torch.Size([3]) True\n",
      "rho_l1.17.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.17.6.bias torch.Size([3]) True\n",
      "rho_l1.17.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.17.8.bias torch.Size([3]) True\n",
      "rho_l1.17.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.17.10.bias torch.Size([1]) True\n",
      "rho_l1.18.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.18.0.bias torch.Size([3]) True\n",
      "rho_l1.18.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.18.2.bias torch.Size([3]) True\n",
      "rho_l1.18.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.18.4.bias torch.Size([3]) True\n",
      "rho_l1.18.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.18.6.bias torch.Size([3]) True\n",
      "rho_l1.18.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.18.8.bias torch.Size([3]) True\n",
      "rho_l1.18.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.18.10.bias torch.Size([1]) True\n",
      "rho_l1.19.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.19.0.bias torch.Size([3]) True\n",
      "rho_l1.19.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.19.2.bias torch.Size([3]) True\n",
      "rho_l1.19.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.19.4.bias torch.Size([3]) True\n",
      "rho_l1.19.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.19.6.bias torch.Size([3]) True\n",
      "rho_l1.19.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.19.8.bias torch.Size([3]) True\n",
      "rho_l1.19.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.19.10.bias torch.Size([1]) True\n",
      "rho_l1.20.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.20.0.bias torch.Size([3]) True\n",
      "rho_l1.20.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.20.2.bias torch.Size([3]) True\n",
      "rho_l1.20.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.20.4.bias torch.Size([3]) True\n",
      "rho_l1.20.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.20.6.bias torch.Size([3]) True\n",
      "rho_l1.20.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.20.8.bias torch.Size([3]) True\n",
      "rho_l1.20.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.20.10.bias torch.Size([1]) True\n",
      "rho_l1.21.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.21.0.bias torch.Size([3]) True\n",
      "rho_l1.21.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.21.2.bias torch.Size([3]) True\n",
      "rho_l1.21.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.21.4.bias torch.Size([3]) True\n",
      "rho_l1.21.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.21.6.bias torch.Size([3]) True\n",
      "rho_l1.21.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.21.8.bias torch.Size([3]) True\n",
      "rho_l1.21.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.21.10.bias torch.Size([1]) True\n",
      "rho_l1.22.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.22.0.bias torch.Size([3]) True\n",
      "rho_l1.22.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.22.2.bias torch.Size([3]) True\n",
      "rho_l1.22.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.22.4.bias torch.Size([3]) True\n",
      "rho_l1.22.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.22.6.bias torch.Size([3]) True\n",
      "rho_l1.22.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.22.8.bias torch.Size([3]) True\n",
      "rho_l1.22.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.22.10.bias torch.Size([1]) True\n",
      "rho_l1.23.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.23.0.bias torch.Size([3]) True\n",
      "rho_l1.23.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.23.2.bias torch.Size([3]) True\n",
      "rho_l1.23.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.23.4.bias torch.Size([3]) True\n",
      "rho_l1.23.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.23.6.bias torch.Size([3]) True\n",
      "rho_l1.23.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.23.8.bias torch.Size([3]) True\n",
      "rho_l1.23.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.23.10.bias torch.Size([1]) True\n",
      "rho_l1.24.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.24.0.bias torch.Size([3]) True\n",
      "rho_l1.24.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.24.2.bias torch.Size([3]) True\n",
      "rho_l1.24.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.24.4.bias torch.Size([3]) True\n",
      "rho_l1.24.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.24.6.bias torch.Size([3]) True\n",
      "rho_l1.24.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.24.8.bias torch.Size([3]) True\n",
      "rho_l1.24.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.24.10.bias torch.Size([1]) True\n",
      "rho_l1.25.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.25.0.bias torch.Size([3]) True\n",
      "rho_l1.25.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.25.2.bias torch.Size([3]) True\n",
      "rho_l1.25.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.25.4.bias torch.Size([3]) True\n",
      "rho_l1.25.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.25.6.bias torch.Size([3]) True\n",
      "rho_l1.25.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.25.8.bias torch.Size([3]) True\n",
      "rho_l1.25.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.25.10.bias torch.Size([1]) True\n",
      "rho_l1.26.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.26.0.bias torch.Size([3]) True\n",
      "rho_l1.26.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.26.2.bias torch.Size([3]) True\n",
      "rho_l1.26.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.26.4.bias torch.Size([3]) True\n",
      "rho_l1.26.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.26.6.bias torch.Size([3]) True\n",
      "rho_l1.26.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.26.8.bias torch.Size([3]) True\n",
      "rho_l1.26.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.26.10.bias torch.Size([1]) True\n",
      "rho_l1.27.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.27.0.bias torch.Size([3]) True\n",
      "rho_l1.27.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.27.2.bias torch.Size([3]) True\n",
      "rho_l1.27.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.27.4.bias torch.Size([3]) True\n",
      "rho_l1.27.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.27.6.bias torch.Size([3]) True\n",
      "rho_l1.27.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.27.8.bias torch.Size([3]) True\n",
      "rho_l1.27.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.27.10.bias torch.Size([1]) True\n",
      "rho_l1.28.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.28.0.bias torch.Size([3]) True\n",
      "rho_l1.28.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.28.2.bias torch.Size([3]) True\n",
      "rho_l1.28.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.28.4.bias torch.Size([3]) True\n",
      "rho_l1.28.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.28.6.bias torch.Size([3]) True\n",
      "rho_l1.28.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.28.8.bias torch.Size([3]) True\n",
      "rho_l1.28.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.28.10.bias torch.Size([1]) True\n",
      "rho_l1.29.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.29.0.bias torch.Size([3]) True\n",
      "rho_l1.29.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.29.2.bias torch.Size([3]) True\n",
      "rho_l1.29.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.29.4.bias torch.Size([3]) True\n",
      "rho_l1.29.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.29.6.bias torch.Size([3]) True\n",
      "rho_l1.29.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.29.8.bias torch.Size([3]) True\n",
      "rho_l1.29.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.29.10.bias torch.Size([1]) True\n",
      "lambda_f.0.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.0.0.bias torch.Size([3]) True\n",
      "lambda_f.0.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.0.2.bias torch.Size([3]) True\n",
      "lambda_f.0.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.0.4.bias torch.Size([3]) True\n",
      "lambda_f.0.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.0.6.bias torch.Size([1]) True\n",
      "lambda_f.1.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.1.0.bias torch.Size([3]) True\n",
      "lambda_f.1.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.1.2.bias torch.Size([3]) True\n",
      "lambda_f.1.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.1.4.bias torch.Size([3]) True\n",
      "lambda_f.1.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.1.6.bias torch.Size([1]) True\n",
      "lambda_f.2.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.2.0.bias torch.Size([3]) True\n",
      "lambda_f.2.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.2.2.bias torch.Size([3]) True\n",
      "lambda_f.2.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.2.4.bias torch.Size([3]) True\n",
      "lambda_f.2.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.2.6.bias torch.Size([1]) True\n",
      "lambda_f.3.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.3.0.bias torch.Size([3]) True\n",
      "lambda_f.3.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.3.2.bias torch.Size([3]) True\n",
      "lambda_f.3.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.3.4.bias torch.Size([3]) True\n",
      "lambda_f.3.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.3.6.bias torch.Size([1]) True\n",
      "lambda_f.4.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.4.0.bias torch.Size([3]) True\n",
      "lambda_f.4.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.4.2.bias torch.Size([3]) True\n",
      "lambda_f.4.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.4.4.bias torch.Size([3]) True\n",
      "lambda_f.4.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.4.6.bias torch.Size([1]) True\n",
      "lambda_f.5.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.5.0.bias torch.Size([3]) True\n",
      "lambda_f.5.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.5.2.bias torch.Size([3]) True\n",
      "lambda_f.5.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.5.4.bias torch.Size([3]) True\n",
      "lambda_f.5.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.5.6.bias torch.Size([1]) True\n",
      "lambda_f.6.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.6.0.bias torch.Size([3]) True\n",
      "lambda_f.6.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.6.2.bias torch.Size([3]) True\n",
      "lambda_f.6.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.6.4.bias torch.Size([3]) True\n",
      "lambda_f.6.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.6.6.bias torch.Size([1]) True\n",
      "lambda_f.7.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.7.0.bias torch.Size([3]) True\n",
      "lambda_f.7.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.7.2.bias torch.Size([3]) True\n",
      "lambda_f.7.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.7.4.bias torch.Size([3]) True\n",
      "lambda_f.7.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.7.6.bias torch.Size([1]) True\n",
      "lambda_f.8.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.8.0.bias torch.Size([3]) True\n",
      "lambda_f.8.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.8.2.bias torch.Size([3]) True\n",
      "lambda_f.8.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.8.4.bias torch.Size([3]) True\n",
      "lambda_f.8.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.8.6.bias torch.Size([1]) True\n",
      "lambda_f.9.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.9.0.bias torch.Size([3]) True\n",
      "lambda_f.9.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.9.2.bias torch.Size([3]) True\n",
      "lambda_f.9.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.9.4.bias torch.Size([3]) True\n",
      "lambda_f.9.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.9.6.bias torch.Size([1]) True\n",
      "lambda_f.10.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.10.0.bias torch.Size([3]) True\n",
      "lambda_f.10.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.10.2.bias torch.Size([3]) True\n",
      "lambda_f.10.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.10.4.bias torch.Size([3]) True\n",
      "lambda_f.10.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.10.6.bias torch.Size([1]) True\n",
      "lambda_f.11.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.11.0.bias torch.Size([3]) True\n",
      "lambda_f.11.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.11.2.bias torch.Size([3]) True\n",
      "lambda_f.11.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.11.4.bias torch.Size([3]) True\n",
      "lambda_f.11.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.11.6.bias torch.Size([1]) True\n",
      "lambda_f.12.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.12.0.bias torch.Size([3]) True\n",
      "lambda_f.12.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.12.2.bias torch.Size([3]) True\n",
      "lambda_f.12.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.12.4.bias torch.Size([3]) True\n",
      "lambda_f.12.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.12.6.bias torch.Size([1]) True\n",
      "lambda_f.13.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.13.0.bias torch.Size([3]) True\n",
      "lambda_f.13.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.13.2.bias torch.Size([3]) True\n",
      "lambda_f.13.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.13.4.bias torch.Size([3]) True\n",
      "lambda_f.13.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.13.6.bias torch.Size([1]) True\n",
      "lambda_f.14.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.14.0.bias torch.Size([3]) True\n",
      "lambda_f.14.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.14.2.bias torch.Size([3]) True\n",
      "lambda_f.14.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.14.4.bias torch.Size([3]) True\n",
      "lambda_f.14.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.14.6.bias torch.Size([1]) True\n",
      "lambda_f.15.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.15.0.bias torch.Size([3]) True\n",
      "lambda_f.15.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.15.2.bias torch.Size([3]) True\n",
      "lambda_f.15.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.15.4.bias torch.Size([3]) True\n",
      "lambda_f.15.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.15.6.bias torch.Size([1]) True\n",
      "lambda_f.16.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.16.0.bias torch.Size([3]) True\n",
      "lambda_f.16.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.16.2.bias torch.Size([3]) True\n",
      "lambda_f.16.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.16.4.bias torch.Size([3]) True\n",
      "lambda_f.16.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.16.6.bias torch.Size([1]) True\n",
      "lambda_f.17.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.17.0.bias torch.Size([3]) True\n",
      "lambda_f.17.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.17.2.bias torch.Size([3]) True\n",
      "lambda_f.17.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.17.4.bias torch.Size([3]) True\n",
      "lambda_f.17.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.17.6.bias torch.Size([1]) True\n",
      "lambda_f.18.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.18.0.bias torch.Size([3]) True\n",
      "lambda_f.18.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.18.2.bias torch.Size([3]) True\n",
      "lambda_f.18.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.18.4.bias torch.Size([3]) True\n",
      "lambda_f.18.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.18.6.bias torch.Size([1]) True\n",
      "lambda_f.19.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.19.0.bias torch.Size([3]) True\n",
      "lambda_f.19.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.19.2.bias torch.Size([3]) True\n",
      "lambda_f.19.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.19.4.bias torch.Size([3]) True\n",
      "lambda_f.19.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.19.6.bias torch.Size([1]) True\n",
      "lambda_f.20.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.20.0.bias torch.Size([3]) True\n",
      "lambda_f.20.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.20.2.bias torch.Size([3]) True\n",
      "lambda_f.20.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.20.4.bias torch.Size([3]) True\n",
      "lambda_f.20.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.20.6.bias torch.Size([1]) True\n",
      "lambda_f.21.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.21.0.bias torch.Size([3]) True\n",
      "lambda_f.21.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.21.2.bias torch.Size([3]) True\n",
      "lambda_f.21.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.21.4.bias torch.Size([3]) True\n",
      "lambda_f.21.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.21.6.bias torch.Size([1]) True\n",
      "lambda_f.22.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.22.0.bias torch.Size([3]) True\n",
      "lambda_f.22.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.22.2.bias torch.Size([3]) True\n",
      "lambda_f.22.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.22.4.bias torch.Size([3]) True\n",
      "lambda_f.22.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.22.6.bias torch.Size([1]) True\n",
      "lambda_f.23.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.23.0.bias torch.Size([3]) True\n",
      "lambda_f.23.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.23.2.bias torch.Size([3]) True\n",
      "lambda_f.23.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.23.4.bias torch.Size([3]) True\n",
      "lambda_f.23.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.23.6.bias torch.Size([1]) True\n",
      "lambda_f.24.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.24.0.bias torch.Size([3]) True\n",
      "lambda_f.24.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.24.2.bias torch.Size([3]) True\n",
      "lambda_f.24.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.24.4.bias torch.Size([3]) True\n",
      "lambda_f.24.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.24.6.bias torch.Size([1]) True\n",
      "lambda_f.25.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.25.0.bias torch.Size([3]) True\n",
      "lambda_f.25.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.25.2.bias torch.Size([3]) True\n",
      "lambda_f.25.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.25.4.bias torch.Size([3]) True\n",
      "lambda_f.25.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.25.6.bias torch.Size([1]) True\n",
      "lambda_f.26.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.26.0.bias torch.Size([3]) True\n",
      "lambda_f.26.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.26.2.bias torch.Size([3]) True\n",
      "lambda_f.26.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.26.4.bias torch.Size([3]) True\n",
      "lambda_f.26.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.26.6.bias torch.Size([1]) True\n",
      "lambda_f.27.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.27.0.bias torch.Size([3]) True\n",
      "lambda_f.27.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.27.2.bias torch.Size([3]) True\n",
      "lambda_f.27.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.27.4.bias torch.Size([3]) True\n",
      "lambda_f.27.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.27.6.bias torch.Size([1]) True\n",
      "lambda_f.28.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.28.0.bias torch.Size([3]) True\n",
      "lambda_f.28.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.28.2.bias torch.Size([3]) True\n",
      "lambda_f.28.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.28.4.bias torch.Size([3]) True\n",
      "lambda_f.28.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.28.6.bias torch.Size([1]) True\n",
      "lambda_f.29.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.29.0.bias torch.Size([3]) True\n",
      "lambda_f.29.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.29.2.bias torch.Size([3]) True\n",
      "lambda_f.29.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.29.4.bias torch.Size([3]) True\n",
      "lambda_f.29.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.29.6.bias torch.Size([1]) True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_summary: MSE:  [0.13896549]  Mean Frobenius loss:  430.0365512084961\n",
      "loss_values:  0 [0.13896549]\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanessa/.conda/envs/glad/lib/python3.7/site-packages/ipykernel_launcher.py:200: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanessa/.conda/envs/glad/lib/python3.7/site-packages/ipykernel_launcher.py:200: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid/train: shd 495.64/489.46 ps 0.00/0.00 nmse -6.20/-6.34\n",
      "epoch =  0  Updating the best ps model with valid ps =  0.0\n",
      "epoch =  0  Updating the best shd model with valid shd =  495.64\n",
      "epoch =  0  Updating the best nmse model with valid nmse =  -6.202041506767273\n",
      "epoch =  0  Updating the best nmse model with valid gmse =  tensor(0.2320, device='cuda:0')\n",
      "loss_summary:: epoch:  0  loss:  [0.13896549]\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanessa/.conda/envs/glad/lib/python3.7/site-packages/ipykernel_launcher.py:200: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vanessa/.conda/envs/glad/lib/python3.7/site-packages/ipykernel_launcher.py:200: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid/train: shd 476.24/472.74 ps 0.00/0.00 nmse -8.12/-8.42\n",
      "epoch =  1  Updating the best ps model with valid ps =  0.0\n",
      "epoch =  1  Updating the best shd model with valid shd =  476.24\n",
      "epoch =  1  Updating the best nmse model with valid nmse =  -8.118193745613098\n",
      "epoch =  1  Updating the best nmse model with valid gmse =  tensor(0.1438, device='cuda:0')\n",
      "loss_summary:: epoch:  1  loss:  [0.05022386]\n"
     ]
    }
   ],
   "source": [
    "if TRAIN == True:\n",
    "    print('Training the glasso model')\n",
    "    print('check: ', train_data[0].shape, train_data[1].shape)\n",
    "    nmse_model, shd_model, ps_model = train_glasso(train_data, valid_data)\n",
    "\n",
    "model = nmse_model  # shd_model # or nmse_model\n",
    "\n",
    "torch.save(nmse_model.state_dict(), model_path)\n",
    "\n",
    "print('TIMING check:')\n",
    "glasso_predict(model, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model trained: Predicting on...')\n",
    "# torch.save(model.state_dict(), 'Gista_model.pt')\n",
    "print('****Train Data, same pred matrix, different samples****')\n",
    "#glasso_predict(nmse_model, train_data, True)\n",
    "glasso_predict(model, train_data, True)\n",
    "if len(valid_data)>0:\n",
    "    print('****Valid Data****')\n",
    "    #glasso_predict(nmse_model, valid_data, True)\n",
    "    glasso_predict(model, valid_data, True)\n",
    "print('****Test Data, model_NMSE: average results over different samples****')\n",
    "glasso_predict(model, test_data, True)\n",
    "print('****Test Data, tag: model_SHD : average results over different samples****')\n",
    "glasso_predict(ps_model, test_data, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-glad] *",
   "language": "python",
   "name": "conda-env-.conda-glad-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
