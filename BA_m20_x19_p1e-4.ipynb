{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n",
      "import package finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from data_generator_glad import *\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"import package finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 20, 20)\n",
      "(64, 20, 20)\n",
      "(1000, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "K_train = 10 # 10\n",
    "M = 100\n",
    "N = 20 # number of features\n",
    "graph_type = \"BA\"\n",
    "SAMPLE_BATCHES = 10\n",
    "w_min = -1\n",
    "w_max = 1\n",
    "SIGNS = 0\n",
    "K_test = 100 # 100\n",
    "prob = 0.1\n",
    "MAX_DEG = 50\n",
    "K_valid = 10\n",
    "edge_type = \"lognormal\"\n",
    "scale = True\n",
    "ee = 1e-4\n",
    "data_path = \"./data/syn/Ktrain{}_Ktest{}_M{}_N{}_prob{}.pkl\".format(K_train, K_test, M, N, prob)\n",
    "train_data_path = \"data/syn/dataset_{}_{}_{}nodes_train_{}_{}.pickle\".format(graph_type, edge_type, N, scale, ee)\n",
    "test_data_path = \"data/syn/dataset_{}_{}_{}nodes_test_{}_{}.pickle\".format(graph_type, edge_type, N, scale, ee)\n",
    "val_data_path = \"data/syn/dataset_{}_{}_{}nodes_val_{}_{}.pickle\".format(graph_type, edge_type, N, scale, ee)\n",
    "\n",
    "with open(train_data_path, 'rb') as trainf:\n",
    "    train_data_ = pkl.load(trainf)\n",
    "train_data = [np.array(train_data_['p']), np.array(train_data_['cov'])]\n",
    "print(train_data[0].shape)\n",
    "\n",
    "with open(test_data_path, 'rb') as testf:\n",
    "    test_data_ = pkl.load(testf)\n",
    "test_data = [np.array(test_data_['p']), np.array(test_data_['cov'])]\n",
    "print(test_data[0].shape)\n",
    "\n",
    "with open(val_data_path, 'rb') as valf:\n",
    "    val_data_ = pkl.load(valf)\n",
    "val_data = [np.array(val_data_['p']), np.array(val_data_['cov'])]\n",
    "print(val_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import training needed packages\n"
     ]
    }
   ],
   "source": [
    "from unrolled_model import *\n",
    "from torch.optim.lr_scheduler import LambdaLR, StepLR, MultiStepLR, ExponentialLR, ReduceLROnPlateau\n",
    "import random\n",
    "import binary_metrics as metrics\n",
    "print(\"import training needed packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN = True\n",
    "USE_CUDA = True\n",
    "L = 30\n",
    "rho_init = 1\n",
    "lambda_init = 1\n",
    "theta_init_offset = 1e-2\n",
    "gamma_init = 0.1\n",
    "nF = 3\n",
    "H = 3\n",
    "init_lr = 0.001\n",
    "use_optimizer = 'adam'\n",
    "batch_size = 10\n",
    "train_epochs = 5\n",
    "INIT_DIAG = 0\n",
    "lossBCE = 0\n",
    "loss_signed = 0\n",
    "lossL1 = 0\n",
    "model_path = \"M{}_N{}_Ktrain{}_gt{}_prob{}_bs{}_L{}_lr{}_ee{}.pth\".format(M, N, K_train, graph_type, prob, batch_size, L, init_lr, ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_glasso(data, valid_data=[]):  # tied lista\n",
    "    #    torch.set_grad_enabled(True)\n",
    "    print('training GLASSO')\n",
    "    theta, S = data\n",
    "    #    theta = theta[0]\n",
    "    if len(valid_data) > 0:\n",
    "        valid_theta, valid_S = valid_data\n",
    "        valid_theta_true = convert_to_torch(valid_theta, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "        valid_S = convert_to_torch(valid_S, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "    # theta -> K_train x N x N (Matrix)\n",
    "    # S -> K_train x N x N (observed vector)\n",
    "    # train using ALISTA style training.\n",
    "    # model = threshold_NN_lambda_single_model(L, rho_init, lambda_init, theta_init_offset, gamma_init, N, nF, H, USE_CUDA=USE_CUDA)\n",
    "    model = threshold_NN_lambda_unrolled_model(L, rho_init, lambda_init, theta_init_offset, gamma_init, N, nF, H, USE_CUDA=USE_CUDA)\n",
    "\n",
    "    model.train()\n",
    "    theta_true = convert_to_torch(theta, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "    S = convert_to_torch(S, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "\n",
    "    zero = torch.Tensor([0])  # .type(self.dtype)\n",
    "\n",
    "    #    print('check: theta ', theta_init.shape)\n",
    "    #    print('true: ', theta_true)\n",
    "    print('parameters to be learned')\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param.shape, param.requires_grad)\n",
    "    dtype = torch.FloatTensor\n",
    "    if USE_CUDA:\n",
    "        model = model.cuda()\n",
    "        zero = zero.cuda()\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "\n",
    "    lr = init_lr\n",
    "    if use_optimizer == 'adadelta':\n",
    "        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr, rho=0.9, eps=1e-06,\n",
    "                                         weight_decay=0)  # LR range = 5 ->\n",
    "    elif use_optimizer == 'rms':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0.25,\n",
    "                                        centered=False)\n",
    "    elif use_optimizer == 'sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, dampening=0, weight_decay=0,\n",
    "                                    nesterov=False)\n",
    "    elif use_optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "    else:\n",
    "        print('Optimizer not found!')\n",
    "    # scheduler = MultiStepLR(optimizer, milestones=[1000], gamma=0.5)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[10, 15, 20, 25, 100, 200], gamma=0.25)\n",
    "    # scheduler = MultiStepLR(optimizer, milestones=[10, 15, 20, 100, 200], gamma=0.25)\n",
    "    # scheduler = MultiStepLR(optimizer, milestones=[10, 20, 30, 200], gamma=0.5)\n",
    "    # criterion = nn.MSELoss(reduction=\"sum\")  # input, target\n",
    "    criterion = nn.MSELoss()  # input, target\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    m_sig = nn.Sigmoid()\n",
    "    criterionBCE = nn.BCELoss()\n",
    "\n",
    "    # batch size is fixed\n",
    "    #    num_batches = int(args.K_train/args.batch_size)\n",
    "    #    if args.SAMPLE_BATCHES > 0:\n",
    "    #        num_batches = int(args.K_train*args.SAMPLE_BATCHES/args.batch_size)\n",
    "\n",
    "    num_batches = int(len(S) / batch_size)\n",
    "\n",
    "    #    if args.K_train >= 10:\n",
    "    #        args.batch_size = 10\n",
    "    # best_shd_model = model\n",
    "    best_valid_shd, best_valid_ps, best_valid_nmse = np.inf, -1 * np.inf, np.inf\n",
    "    EARLY_STOP = False\n",
    "    for epoch in range(train_epochs):  # 1 epoch is expected to go through complete data\n",
    "        scheduler.step()\n",
    "        #        if epoch%1==0:\n",
    "        #            for param_group in optimizer.param_groups:\n",
    "        #                print('epoch: ', epoch, ' lr ', param_group['lr'])\n",
    "        epoch_loss = []\n",
    "        frob_loss = []\n",
    "        duality_gap = []\n",
    "        mse_binary_loss = []\n",
    "        bce_loss = []\n",
    "        if EARLY_STOP:\n",
    "            break\n",
    "        #        print('ecpohc ', epoch)\n",
    "        for batch_num in range(num_batches):  # processing batchwise\n",
    "            optimizer.zero_grad()\n",
    "            # resetting the loss to zero\n",
    "            loss = torch.Tensor([0]).type(dtype)\n",
    "            # Get a batch\n",
    "            # ridx = random.sample(list(range(args.K_train)), args.batch_size)\n",
    "            ridx = random.sample(list(range(len(S))), batch_size)\n",
    "            Sb = S[ridx]  # [0]\n",
    "            #            print('errr train check : ', batch_num, theta_true, Sb, theta_true.expand_as(Sb))\n",
    "\n",
    "            if INIT_DIAG == 1:\n",
    "                # print(' extract batchwise diagonals, add offset and take inverse')\n",
    "                batch_diags = 1 / (torch.diagonal(Sb, offset=0, dim1=-2, dim2=-1) + model.theta_init_offset)\n",
    "                theta_init = torch.diag_embed(batch_diags)\n",
    "            else:\n",
    "                # print('***************** (S+theta_offset*I)^-1 is used')\n",
    "                theta_init = torch.inverse(\n",
    "                    Sb + model.theta_init_offset * torch.eye(Sb.shape[-1]).expand_as(Sb).type_as(Sb))\n",
    "\n",
    "\n",
    "            # theta_pred = S_inv[r_idx]\n",
    "            # ll = torch.cholesky(theta_init[ridx])#(theta_pred) # lower triangular\n",
    "            # ll = my_cholesky(theta_init[ridx][0])#(theta_pred) # lower triangular\n",
    "            # ll = batch_cholesky(theta_init[ridx])#(theta_pred) # lower triangular\n",
    "            theta_pred = theta_init  # [ridx]\n",
    "            # theta_pred = theta_init[ridx]\n",
    "            # theta_pred.requires_grad = True\n",
    "            # Sb = S[ridx][0]\n",
    "            # step_size = get_init_step_size(theta_init[ridx])\n",
    "            identity_mat = torch.eye(Sb.shape[-1]).expand_as(Sb)\n",
    "            if USE_CUDA == True:\n",
    "                identity_mat = identity_mat.cuda()\n",
    "            # print('ERRR check: ', theta_pred.shape, get_frobenius_norm(theta_pred), get_frobenius_norm(theta_pred).shape)\n",
    "            # lambda_k = model.lambda_f(get_frobenius_norm(theta_pred))\n",
    "            lambda_k = model.lambda_forward(zero + lambda_init, zero, k=0)\n",
    "            for k in range(L):\n",
    "                #                print('itr = ', itr, theta_pred)#, theta_true[ridx])\n",
    "                # step 1 : AM\n",
    "                b = 1.0 / lambda_k * Sb - theta_pred\n",
    "                b2_4ac = torch.matmul(b.transpose(-1, -2), b) + 4.0 / lambda_k * identity_mat\n",
    "                sqrt_term = batch_matrix_sqrt(b2_4ac)\n",
    "                theta_k1 = 1.0 / 2 * (-1 * b + sqrt_term)\n",
    "                \"\"\"\n",
    "                # extract the diagonals of the matrices\n",
    "                theta_diag = torch.diag_embed(torch.diagonal(theta_k1, offset=0, dim1=-2, dim2=-1))\n",
    "                # soft threshold on remaining entries\n",
    "                theta_pred = model.eta_forward(theta_k1-theta_diag, k)\n",
    "                # add the diagonals\n",
    "                theta_pred = theta_pred + theta_diag\n",
    "                \"\"\"\n",
    "                # softthresholding on all the entries\n",
    "                # theta_pred = model.eta_forward(theta_k1, k)\n",
    "\n",
    "                # if MODEL_type == 'th':\n",
    "                #     # soft thresholding + eigenvalue correctness term\n",
    "                #     theta_pred = model.eta_forward(theta_k1, k) + torch.max(model.gamma_c[k],\n",
    "                #                                                             zero + 1e-2) * identity_mat\n",
    "                # elif MODEL_type == 'th_NN':\n",
    "                theta_pred = model.eta_forward(theta_k1, Sb, k, theta_pred)  #\n",
    "                # update the lambda\n",
    "                lambda_k = model.lambda_forward(torch.Tensor([get_frobenius_norm(theta_pred - theta_k1)]).type(dtype),\n",
    "                                                lambda_k, k)\n",
    "                # accumulating loss\n",
    "                #                print('k= ', k, ' lambda_value ', lambda_k, get_frobenius_norm(theta_pred-theta_k1))\n",
    "\n",
    "                loss += criterion(theta_pred, theta_true[ridx]) / L\n",
    "                # loss += criterion(theta_pred, theta_true.expand_as(theta_pred))/args.L\n",
    "\n",
    "            #            print('k= ', k, ' lambda_value ', lambda_k)\n",
    "            # print('thetapred: ', theta_pred, check_sym(theta_pred[0].data.cpu().numpy()))\n",
    "            # delta = batch_duality_gap(theta_pred, Sb, model.rho)\n",
    "            # NOTE: ******* IMP: Change thissss!@!! ****************************\n",
    "            delta = torch.ones([1]) * -1\n",
    "\n",
    "            loss += criterion(theta_pred, theta_true[ridx]) / L\n",
    "\n",
    "            # loss += criterion(theta_pred, theta_true.expand_as(theta_pred))/args.L\n",
    "\n",
    "            lossf = get_frobenius_norm(theta_pred - theta_true[ridx])\n",
    "#             lossgmse = get_frobenius_norm_except_diag(theta_pred - theta_true[ridx])\n",
    "            # total_loss = loss #+ delta\n",
    "            # total_loss = lossB #+ loss #+ delta\n",
    "            # total_loss = loss + lossB+ delta + lossBCE\n",
    "            #            total_loss = lossBCE\n",
    "            # total_loss = delta\n",
    "            if lossBCE == 1:  # binary cross entropy\n",
    "                total_loss = lossBCE\n",
    "            elif loss_signed == 1:  # signed loss\n",
    "                # total_loss = criterion(torch.sign(theta_pred), torch.sign(theta_true.expand_as(theta_pred)))\n",
    "                total_loss = criterion(theta_pred, torch.sign(theta_true.expand_as(theta_pred)))\n",
    "            elif lossL1 == 1:  # signed loss\n",
    "                total_loss = criterion_L1(theta_pred, theta_true.expand_as(theta_pred))\n",
    "            else:  # frobenius norm\n",
    "                total_loss = loss\n",
    "                # total_loss = lossf\n",
    "            #            total_loss.requires_grad = True\n",
    "            #            print('err: ', total_loss, total_loss.requires_grad)\n",
    "\n",
    "            lv = loss.data.cpu().numpy()\n",
    "            if lv <= 1e-7:  # loss value\n",
    "                print('Early stopping as loss = ', lv)\n",
    "                EARLY_STOP = True\n",
    "                break\n",
    "\n",
    "            total_loss.backward()\n",
    "            # delta.backward()\n",
    "\n",
    "            #            for name, param in model.named_parameters():\n",
    "            #                print('befoer: ', name, param)\n",
    "            optimizer.step()\n",
    "\n",
    "            #            for name, param in model.named_parameters():\n",
    "            #                print('after: ', name, param)\n",
    "\n",
    "            #            mse_binary_loss.append(lossB.data.cpu().numpy())\n",
    "            #            bce_loss.append(lossBCE.data.cpu().numpy())\n",
    "            #            duality_gap.append(delta.data.cpu().numpy())\n",
    "            frob_loss.append(lossf.data.cpu().numpy())\n",
    "            epoch_loss.append(loss.data.cpu().numpy())\n",
    "        if epoch % 2 == 0 and EARLY_STOP == False:\n",
    "            # print(len(epoch_loss))\n",
    "            # print('loss_summary: MSE: ', sum(epoch_loss)/len(epoch_loss), ' Mean Frobenius loss: ',sum(frob_loss)/len(frob_loss), ' MSE_binary loss: ', sum(mse_binary_loss)/len(mse_binary_loss), 'BCE_loss: ', sum(bce_loss)/len(bce_loss), 'duality gap = ', sum(duality_gap)/len(duality_gap))\n",
    "            print('loss_summary: MSE: ', sum(epoch_loss)/len(epoch_loss), ' Mean Frobenius loss: ',sum(frob_loss)/len(frob_loss))\n",
    "            if lossBCE == 1:\n",
    "                print(epoch, sum(epoch_loss) / len(epoch_loss), sum(bce_loss) / len(bce_loss))\n",
    "            else:\n",
    "                print('loss_values: ', epoch, sum(epoch_loss) / len(epoch_loss))  # , sum(duality_gap)/len(duality_gap))\n",
    "        # Checking the results on valid data and updating the best model\n",
    "        if len(valid_data) > 0:\n",
    "            # get the SHD on the valid data and the train data\n",
    "            # curr_valid_shd, curr_valid_nmse = glasso_predict(model, valid_data)\n",
    "            curr_valid_ps_mean, curr_valid_ps_std, \\\n",
    "            curr_valid_aps_mean, curr_valid_aps_std, \\\n",
    "            curr_valid_aucs_mean, curr_valid_aucs_std, \\\n",
    "            curr_valid_nmse, \\\n",
    "            curr_valid_gmse, curr_valid_gmse_m, curr_valid_gmse_h = glasso_predict(model, valid_data)\n",
    "            curr_train_ps_mean, curr_train_ps_std, \\\n",
    "            curr_train_aps_mean, curr_train_aps_std, \\\n",
    "            curr_train_aucs_mean, curr_train_aucs_std, \\\n",
    "            curr_train_nmse, \\\n",
    "            curr_train_gmse, curr_train_gmse_m, curr_train_gmse_h = glasso_predict(model, data)\n",
    "            print('valid/train: ps %0.4f/%0.4f aps %0.4f/%0.4f aucs %0.4f/%0.4f nmse %0.4f/%0.4f' % (\n",
    "            curr_valid_ps_mean, curr_train_ps_mean, curr_valid_aps_mean, curr_train_aps_mean,\n",
    "            curr_valid_aucs_mean, curr_train_aucs_mean, curr_valid_nmse, curr_train_nmse))\n",
    "            #            if curr_valid_shd <= best_valid_shd:\n",
    "            if curr_valid_ps_mean >= best_valid_ps:\n",
    "                print('epoch = ', epoch, ' Updating the best ps model with valid ps = ', curr_valid_ps_mean)\n",
    "                best_ps_model = copy.deepcopy(model)\n",
    "                best_valid_ps = curr_valid_ps_mean\n",
    "\n",
    "            # if curr_valid_shd <= best_valid_shd:\n",
    "            #     print('epoch = ', epoch, ' Updating the best shd model with valid shd = ', curr_valid_shd)\n",
    "            #     best_shd_model = copy.deepcopy(model)\n",
    "            #     best_valid_shd = curr_valid_shd\n",
    "\n",
    "            if curr_valid_nmse <= best_valid_nmse:\n",
    "                print('epoch = ', epoch, ' Updating the best nmse model with valid nmse = ', curr_valid_nmse)\n",
    "                best_nmse_model = copy.deepcopy(model)\n",
    "                best_valid_nmse = curr_valid_nmse\n",
    "                print('epoch = ', epoch, ' Updating the best nmse model with valid gmse = ', curr_valid_gmse)\n",
    "                print('epoch = ', epoch, ' Updating the best nmse model with valid gmse except diag = {}+-{}'.format(curr_valid_gmse_m, curr_valid_gmse_h))\n",
    "            model.train()\n",
    "            print('loss_summary:: epoch: ', epoch, ' loss: ', sum(epoch_loss)/len(epoch_loss))#, ' NMSE loss: ', 10*np.log10( (np.sum(np.array(epoch_loss)))/(len(epoch_loss)*E_norm_xtrue)))\n",
    "    #    print('ans: ', theta_pred)\n",
    "    #    print('true: ', theta_true)\n",
    "    for name, param in model.named_parameters():\n",
    "        print(name, param)\n",
    "    # return best_ps_model # model\n",
    "    # return best_nmse_model, best_shd_model, best_ps_model  # model\n",
    "    return best_nmse_model, best_ps_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def glasso_predict(model, data, flagP=False, SAVE_GRAPH=False, eM=0, name='', mn=''):\n",
    "    with torch.no_grad():\n",
    "        print('Running unrolled ADMM predict')\n",
    "        # predict as a complete batch?\n",
    "        model.eval()\n",
    "        criterion = nn.MSELoss()  # input, target\n",
    "        m_sig = nn.Sigmoid()\n",
    "        criterionBCE = nn.BCELoss()\n",
    "        theta, S = data\n",
    "        #    theta = theta[0]\n",
    "        # theta -> K_train x N x N (Matrix)\n",
    "        # S -> K_train x N x N (observed vector)\n",
    "        # theta_true = convert_to_torch(theta, TESTING_FLAG=True, USE_CUDA=False)\n",
    "        theta_true = convert_to_torch(theta, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "        S = convert_to_torch(S, TESTING_FLAG=True, USE_CUDA=USE_CUDA)\n",
    "\n",
    "        zero = torch.Tensor([0])  # .type(self.dtype)\n",
    "        dtype = torch.FloatTensor\n",
    "        if USE_CUDA == True:\n",
    "            zero = zero.cuda()\n",
    "            model = model.cuda()\n",
    "            dtype = torch.cuda.FloatTensor\n",
    "\n",
    "        # batch size is fixed for testing as 1\n",
    "        batch_size = 1\n",
    "        print('CEHCKK: Total graphs = ', len(S))\n",
    "        num_batches = int(len(S) / batch_size)\n",
    "        #    print('num batches: ', num_batches)\n",
    "        epoch_loss = []\n",
    "        mse_binary_loss = []\n",
    "        bce_loss = []\n",
    "        frob_loss = []\n",
    "        duality_gap = []\n",
    "        ans = []\n",
    "        if flagP:\n",
    "            res_conv = {}\n",
    "            for k in range(L + 1):\n",
    "                res_conv[k] = []\n",
    "        #        print('ITR, conv.loss, obj_val_pred, obj_val_true_model_rho, obj_val_pred_args_rho')#, theta_pred)\n",
    "\n",
    "        res = []\n",
    "        gmse_res = []\n",
    "        for batch_num in range(num_batches):  # processing batchwise\n",
    "            # Get a batch\n",
    "            # ll = my_cholesky(theta_init[ridx][0])#(theta_pred) # lower triangular\n",
    "            # theta_pred = theta_init[batch_num*batch_size: (batch_num+1)*batch_size] #(theta_pred) # lower triangular\n",
    "            # theta_true_b = theta_true[batch_num*batch_size: (batch_num+1)*batch_size]\n",
    "            theta_true_b = theta_true[batch_num * batch_size: (batch_num + 1) * batch_size]\n",
    "            Sb = S[batch_num * batch_size: (batch_num + 1) * batch_size]  # [0]\n",
    "            identity_mat = torch.eye(Sb.shape[-1]).expand_as(Sb)\n",
    "            if USE_CUDA == True:\n",
    "                identity_mat = identity_mat.cuda()\n",
    "                Sb = Sb.cuda()\n",
    "            #    theta_pred = theta_pred.cuda()\n",
    "            #    theta_true_b = theta_true_b.cuda()\n",
    "\n",
    "            if INIT_DIAG == 1:\n",
    "                # print(' extract batchwise diagonals, add offset and take inverse')\n",
    "                batch_diags = 1 / (torch.diagonal(Sb, offset=0, dim1=-2, dim2=-1) + model.theta_init_offset)\n",
    "                theta_pred = torch.diag_embed(batch_diags)\n",
    "            else:\n",
    "                # print('***************** (S+theta_offset*I)^-1 is used')\n",
    "                theta_pred = torch.inverse(\n",
    "                    Sb + model.theta_init_offset * torch.eye(Sb.shape[-1]).expand_as(Sb).type_as(Sb))\n",
    "\n",
    "            # lambda_k = model.lambda_f(get_frobenius_norm(theta_pred))\n",
    "            lambda_k = model.lambda_forward(zero + lambda_init, zero, k=0)\n",
    "\n",
    "            #        if flagP:\n",
    "            #            print('ITR, conv.loss, obj_val_pred, obj_val_true_model_rho, obj_val_pred_args_rho')#, theta_pred)\n",
    "            for k in range(L):\n",
    "                #            start = time.time()\n",
    "                if flagP:\n",
    "                    theta_pred_diag = torch.diag_embed(torch.diagonal(theta_pred[0], offset=0, dim1=-2, dim2=-1))\n",
    "                    # theta_true_b_diag = torch.diag_embed(torch.diagonal(theta_true_b[0], offset=0, dim1=-2, dim2=-1))\n",
    "                    theta_true_b_diag = torch.diag_embed(torch.diagonal(theta_true_b, offset=0, dim1=-2, dim2=-1))\n",
    "                    # if MODEL_type == 'th':\n",
    "                    #     cv_loss, cv_loss_off_diag, obj_pred, obj_true_rho, obj_true_orig = get_convergence_loss(\n",
    "                    #         theta_pred[0], theta_true_b), get_convergence_loss(theta_pred[0] - theta_pred_diag,\n",
    "                    #                                                            theta_true_b - theta_true_b_diag), get_obj_val(\n",
    "                    #         theta_pred[0], Sb[0], model.rho_l1[k]), get_obj_val(theta_true_b, Sb[0],\n",
    "                    #                                                             model.rho_l1[k]), get_obj_val(\n",
    "                    #         theta_true_b, Sb[0], rho_init)\n",
    "                    #     res_conv[k].append([cv_loss, obj_pred, obj_true_rho, obj_true_orig, cv_loss_off_diag])\n",
    "                    # elif MODEL_type == 'th_NN':\n",
    "                    cv_loss, cv_loss_off_diag = get_convergence_loss(theta_pred[0],\n",
    "                                                                         theta_true_b), -1  # get_convergence_loss(theta_pred[0]-theta_pred_diag, theta_true_b-theta_true_b_diag)\n",
    "                    res_conv[k].append([cv_loss, cv_loss_off_diag])\n",
    "                # step 1 : AM\n",
    "                b = 1.0 / lambda_k * Sb - theta_pred\n",
    "                b2_4ac = torch.matmul(b.transpose(-1, -2), b) + 4.0 / lambda_k * identity_mat\n",
    "                sqrt_term = batch_matrix_sqrt(b2_4ac)\n",
    "                theta_k1 = 1.0 / 2 * (-1 * b + sqrt_term)\n",
    "\n",
    "                # step 2 : AM\n",
    "                \"\"\"\n",
    "                # extract the diagonals of the matrices\n",
    "                theta_diag = torch.diag_embed(torch.diagonal(theta_k1, offset=0, dim1=-2, dim2=-1))\n",
    "                # soft threshold on remaining entries\n",
    "                theta_pred = model.eta_forward(theta_k1-theta_diag, k)\n",
    "                # add the diagonals\n",
    "                theta_pred = theta_pred + theta_diag\n",
    "                \"\"\"\n",
    "                # soft thresholding on all the entries\n",
    "                # theta_pred = model.eta_forward(theta_k1, k)\n",
    "                # if MODEL_type == 'th':\n",
    "                #     # soft thresholding + eigenvalue correctness term\n",
    "                #     theta_pred = model.eta_forward(theta_k1, k) + torch.max(model.gamma_c[k],\n",
    "                #                                                             zero + 1e-2) * identity_mat\n",
    "                # elif MODEL_type == 'th_NN':\n",
    "                    # theta_pred = model.eta_forward(theta_k1, Sb, k) + torch.max(model.gamma_c[k], zero+1e-2) * identity_mat\n",
    "                    # theta_pred = model.eta_forward(theta_k1, Sb, k, theta_pred) + torch.max(model.gamma_c[k], zero+1e-2) * identity_mat\n",
    "                theta_pred = model.eta_forward(theta_k1, Sb, k,\n",
    "                                                   theta_pred)  # + torch.max(model.gamma_c[k], zero+1e-2) * identity_mat\n",
    "\n",
    "                # updating lambda\n",
    "                lambda_k = model.lambda_forward(torch.Tensor([get_frobenius_norm(theta_pred - theta_k1)]).type(dtype),\n",
    "                                                lambda_k, k)\n",
    "                # lambda_k = model.lambda_f(get_frobenius_norm(theta_pred-theta_k1))\n",
    "            #            print('k= ', k, ' lambda_value ', lambda_k, get_frobenius_norm(theta_pred-theta_k1))\n",
    "            #            stop = time.time()\n",
    "            #            print('Walltimes: ', k, stop-start)\n",
    "            #        br\n",
    "            if flagP:\n",
    "                theta_pred_diag = torch.diag_embed(torch.diagonal(theta_pred[0], offset=0, dim1=-2, dim2=-1))\n",
    "                # Getting the final predicted convergence loss\n",
    "                if torch.min(torch.eig(theta_pred[0])[0][:, 0]) == 0:\n",
    "                    adjust_eval_identity = torch.eye(theta_pred.shape[-1]).expand_as(theta_pred[0]).type_as(\n",
    "                        theta_pred[0])\n",
    "                    print('Adjusting the minimum eigenvalue to 1, SHOULD NOT BE CALLED AFTER THE GAMMA ADDITION!')\n",
    "                    theta_pred[0] += adjust_eval_identity  # change the eigenval to 1\n",
    "                # if MODEL_type == 'th':\n",
    "                #     cv_loss, cv_loss_off_diag, obj_pred, obj_true_rho, obj_true_orig = get_convergence_loss(\n",
    "                #         theta_pred[0], theta_true_b), get_convergence_loss(theta_pred[0] - theta_pred_diag,\n",
    "                #                                                            theta_true_b - theta_true_b_diag), get_obj_val(\n",
    "                #         theta_pred[0], Sb[0], model.rho_l1[k]), get_obj_val(theta_true_b, Sb[0],\n",
    "                #                                                             model.rho_l1[k]), get_obj_val(theta_true_b,\n",
    "                #                                                                                           Sb[0],\n",
    "                #                                                                                           args.rho_init)\n",
    "                #     res_conv[k + 1].append([cv_loss, obj_pred, obj_true_rho, obj_true_orig, cv_loss_off_diag])\n",
    "                # elif MODEL_type == 'th_NN':\n",
    "                cv_loss, cv_loss_off_diag = get_convergence_loss(theta_pred[0],\n",
    "                                                                     theta_true_b), -1  # get_convergence_loss(theta_pred[0]-theta_pred_diag, theta_true_b-theta_true_b_diag)\n",
    "                res_conv[k + 1].append([cv_loss, cv_loss_off_diag])\n",
    "\n",
    "            if Plot:\n",
    "                print(\"=====================\")\n",
    "\n",
    "                plt.figure()\n",
    "                seaborn.heatmap(theta_pred[0][:100,:100].cpu().detach().numpy(),cmap=\"pink_r\",vmax=1)\n",
    "                plt.show()\n",
    "\n",
    "                plt.figure()\n",
    "                seaborn.heatmap(theta_true_b[0][:100,:100].cpu().detach().numpy(),cmap=\"pink_r\",vmax=1)\n",
    "                plt.show()\n",
    "\n",
    "            final_nmse, final_gmse, n, d, final_gmse_exp_diag, n1, d1 = get_convergence_loss(theta_pred, theta_true_b)\n",
    "            theta_pred = theta_pred.data.cpu().numpy()\n",
    "            #        theta_true_b = theta_true_b[0].data.cpu().numpy()\n",
    "            theta_true_b = theta_true_b.data.cpu().numpy()\n",
    "\n",
    "            FDRs, TPRs, FPRs, SHDs, Ts, Ps, precisions, recalls, \\\n",
    "            F_betas, auprs, aucs = metrics.report_metrics(theta_true_b, theta_pred, batch_size=batch_size)\n",
    "            cond_theta_pred, cond_theta_true_b = np.linalg.cond(theta_pred), -1  # np.linalg.cond(theta_true_b)\n",
    "            res.append([FDRs, TPRs, FPRs, SHDs, Ts, Ps, precisions, recalls, F_betas, auprs, aucs])\n",
    "            gmse_res.append(final_gmse_exp_diag)\n",
    "\n",
    "        res_mean = np.mean(np.array(res), 0)\n",
    "        res_std = np.std(np.array(res), 0)\n",
    "        res_mean = [\"%.5f\" % x for x in res_mean]\n",
    "        res_std = [\"%.5f\" % x for x in res_std]\n",
    "\n",
    "        if flagP:\n",
    "            print('Structure learning Metrics')\n",
    "            print('Average result over test graphs')\n",
    "            # print('fdr, tpr, fpr, shd, nnz, nnz_true, np.linalg.cond(theta_pred), np.linalg.cond(theta_true)')\n",
    "            print('FDRs, TPRs, FPRs, SHDs, Ts, Ps, precisions, recalls, F_betas, auprs, aucs')\n",
    "            print(*sum(list(map(list, zip(res_mean, res_std))), []), sep=', ')\n",
    "\n",
    "            # print('ITR, conv.loss, obj_val_pred, obj_val_true_model_rho, obj_val_pred_args_rho')#, theta_pred)\n",
    "#             print(\n",
    "#                 'ITR, conv_loss\"ecoli_M\"+str(eM), obj_val_pred, obj_val_true_model_rho, obj_val_pred_args_rho, conv_loss_off_diag')  # , theta_pred)\n",
    "#             for i in res_conv:\n",
    "#                 mean_vec = [\"%.3f\" % x for x in np.mean(np.array(res_conv[i].cpu().detach()), 0)]\n",
    "#                 std_vec = [\"%.3f\" % x for x in np.std(np.array(res_conv[i].cpu().detach()), 0)]\n",
    "#                 print(i, *sum(list(map(list, zip(mean_vec, std_vec))), []), sep=', ')\n",
    "        #            print(i, np.mean(res_conv[i], 0), np.std(res_conv[i], 0))\n",
    "\n",
    "        if SAVE_GRAPH:\n",
    "            x = np.where(theta_pred > 0, 1, 0)\n",
    "            A = np.matrix(x - np.eye(x.shape[0]))\n",
    "            G = nx.from_numpy_matrix(A)\n",
    "            fig = plt.figure(figsize=(15, 15))\n",
    "            mapping = {n1: n2 for n1, n2 in zip(G.nodes(), mn.nodes)}\n",
    "            G = nx.relabel_nodes(G, mapping)\n",
    "            # nx.draw_networkx(G, pos=nx.spring_layout(G), with_labels = True)\n",
    "            # nx.draw_networkx(G, pos=nx.circular_layout(G), with_labels = True)\n",
    "            nx.draw_networkx(G, pos=nx.shell_layout(G), with_labels=True)\n",
    "            plt.savefig(name + '_' + str(eM) + \".pdf\", bbox_inches='tight')\n",
    "            nx.draw_networkx(mn.G_true, pos=nx.shell_layout(G), with_labels=True)\n",
    "            plt.savefig(name + '_true_' + str(eM) + \".pdf\", bbox_inches='tight')\n",
    "            # saving the graph\n",
    "            # nx.write_gpickle(G, name+'_'+str(eM)+'.gpickle')\n",
    "            nx.write_adjlist(G, name + '_' + str(eM) + '.adjlist')\n",
    "\n",
    "        gmsem, gmseh, _, __ = metrics.mean_confidence_interval(gmse_res)\n",
    "        # pr, aps, auc\n",
    "        return np.float(res_mean[5]), np.float(res_std[5]), \\\n",
    "               np.float(res_mean[9]), np.float(res_std[9]), \\\n",
    "               np.float(res_mean[10]), np.float(res_std[10]), \\\n",
    "               final_nmse, final_gmse, gmsem, gmseh  # The PS mean value, final NMSE obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the glasso model\n",
      "check:  (4000, 20, 20) (4000, 20, 20)\n",
      "training GLASSO\n",
      "shifting to cuda\n",
      "CHECK RHO INITIAL:  Parameter containing:\n",
      "tensor([[-0.3543, -0.3788,  0.0514],\n",
      "        [-0.4119, -0.0413, -0.5542],\n",
      "        [-0.2788, -0.3570,  0.5541]], device='cuda:0', requires_grad=True)\n",
      "parameters to be learned\n",
      "theta_init_offset torch.Size([1]) True\n",
      "rho_l1.0.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.0.0.bias torch.Size([3]) True\n",
      "rho_l1.0.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.0.2.bias torch.Size([3]) True\n",
      "rho_l1.0.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.0.4.bias torch.Size([3]) True\n",
      "rho_l1.0.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.0.6.bias torch.Size([3]) True\n",
      "rho_l1.0.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.0.8.bias torch.Size([3]) True\n",
      "rho_l1.0.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.0.10.bias torch.Size([1]) True\n",
      "rho_l1.1.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.1.0.bias torch.Size([3]) True\n",
      "rho_l1.1.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.1.2.bias torch.Size([3]) True\n",
      "rho_l1.1.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.1.4.bias torch.Size([3]) True\n",
      "rho_l1.1.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.1.6.bias torch.Size([3]) True\n",
      "rho_l1.1.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.1.8.bias torch.Size([3]) True\n",
      "rho_l1.1.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.1.10.bias torch.Size([1]) True\n",
      "rho_l1.2.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.2.0.bias torch.Size([3]) True\n",
      "rho_l1.2.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.2.2.bias torch.Size([3]) True\n",
      "rho_l1.2.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.2.4.bias torch.Size([3]) True\n",
      "rho_l1.2.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.2.6.bias torch.Size([3]) True\n",
      "rho_l1.2.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.2.8.bias torch.Size([3]) True\n",
      "rho_l1.2.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.2.10.bias torch.Size([1]) True\n",
      "rho_l1.3.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.3.0.bias torch.Size([3]) True\n",
      "rho_l1.3.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.3.2.bias torch.Size([3]) True\n",
      "rho_l1.3.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.3.4.bias torch.Size([3]) True\n",
      "rho_l1.3.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.3.6.bias torch.Size([3]) True\n",
      "rho_l1.3.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.3.8.bias torch.Size([3]) True\n",
      "rho_l1.3.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.3.10.bias torch.Size([1]) True\n",
      "rho_l1.4.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.4.0.bias torch.Size([3]) True\n",
      "rho_l1.4.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.4.2.bias torch.Size([3]) True\n",
      "rho_l1.4.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.4.4.bias torch.Size([3]) True\n",
      "rho_l1.4.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.4.6.bias torch.Size([3]) True\n",
      "rho_l1.4.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.4.8.bias torch.Size([3]) True\n",
      "rho_l1.4.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.4.10.bias torch.Size([1]) True\n",
      "rho_l1.5.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.5.0.bias torch.Size([3]) True\n",
      "rho_l1.5.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.5.2.bias torch.Size([3]) True\n",
      "rho_l1.5.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.5.4.bias torch.Size([3]) True\n",
      "rho_l1.5.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.5.6.bias torch.Size([3]) True\n",
      "rho_l1.5.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.5.8.bias torch.Size([3]) True\n",
      "rho_l1.5.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.5.10.bias torch.Size([1]) True\n",
      "rho_l1.6.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.6.0.bias torch.Size([3]) True\n",
      "rho_l1.6.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.6.2.bias torch.Size([3]) True\n",
      "rho_l1.6.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.6.4.bias torch.Size([3]) True\n",
      "rho_l1.6.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.6.6.bias torch.Size([3]) True\n",
      "rho_l1.6.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.6.8.bias torch.Size([3]) True\n",
      "rho_l1.6.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.6.10.bias torch.Size([1]) True\n",
      "rho_l1.7.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.7.0.bias torch.Size([3]) True\n",
      "rho_l1.7.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.7.2.bias torch.Size([3]) True\n",
      "rho_l1.7.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.7.4.bias torch.Size([3]) True\n",
      "rho_l1.7.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.7.6.bias torch.Size([3]) True\n",
      "rho_l1.7.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.7.8.bias torch.Size([3]) True\n",
      "rho_l1.7.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.7.10.bias torch.Size([1]) True\n",
      "rho_l1.8.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.8.0.bias torch.Size([3]) True\n",
      "rho_l1.8.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.8.2.bias torch.Size([3]) True\n",
      "rho_l1.8.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.8.4.bias torch.Size([3]) True\n",
      "rho_l1.8.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.8.6.bias torch.Size([3]) True\n",
      "rho_l1.8.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.8.8.bias torch.Size([3]) True\n",
      "rho_l1.8.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.8.10.bias torch.Size([1]) True\n",
      "rho_l1.9.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.9.0.bias torch.Size([3]) True\n",
      "rho_l1.9.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.9.2.bias torch.Size([3]) True\n",
      "rho_l1.9.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.9.4.bias torch.Size([3]) True\n",
      "rho_l1.9.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.9.6.bias torch.Size([3]) True\n",
      "rho_l1.9.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.9.8.bias torch.Size([3]) True\n",
      "rho_l1.9.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.9.10.bias torch.Size([1]) True\n",
      "rho_l1.10.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.10.0.bias torch.Size([3]) True\n",
      "rho_l1.10.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.10.2.bias torch.Size([3]) True\n",
      "rho_l1.10.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.10.4.bias torch.Size([3]) True\n",
      "rho_l1.10.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.10.6.bias torch.Size([3]) True\n",
      "rho_l1.10.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.10.8.bias torch.Size([3]) True\n",
      "rho_l1.10.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.10.10.bias torch.Size([1]) True\n",
      "rho_l1.11.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.11.0.bias torch.Size([3]) True\n",
      "rho_l1.11.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.11.2.bias torch.Size([3]) True\n",
      "rho_l1.11.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.11.4.bias torch.Size([3]) True\n",
      "rho_l1.11.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.11.6.bias torch.Size([3]) True\n",
      "rho_l1.11.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.11.8.bias torch.Size([3]) True\n",
      "rho_l1.11.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.11.10.bias torch.Size([1]) True\n",
      "rho_l1.12.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.12.0.bias torch.Size([3]) True\n",
      "rho_l1.12.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.12.2.bias torch.Size([3]) True\n",
      "rho_l1.12.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.12.4.bias torch.Size([3]) True\n",
      "rho_l1.12.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.12.6.bias torch.Size([3]) True\n",
      "rho_l1.12.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.12.8.bias torch.Size([3]) True\n",
      "rho_l1.12.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.12.10.bias torch.Size([1]) True\n",
      "rho_l1.13.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.13.0.bias torch.Size([3]) True\n",
      "rho_l1.13.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.13.2.bias torch.Size([3]) True\n",
      "rho_l1.13.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.13.4.bias torch.Size([3]) True\n",
      "rho_l1.13.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.13.6.bias torch.Size([3]) True\n",
      "rho_l1.13.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.13.8.bias torch.Size([3]) True\n",
      "rho_l1.13.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.13.10.bias torch.Size([1]) True\n",
      "rho_l1.14.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.14.0.bias torch.Size([3]) True\n",
      "rho_l1.14.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.14.2.bias torch.Size([3]) True\n",
      "rho_l1.14.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.14.4.bias torch.Size([3]) True\n",
      "rho_l1.14.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.14.6.bias torch.Size([3]) True\n",
      "rho_l1.14.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.14.8.bias torch.Size([3]) True\n",
      "rho_l1.14.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.14.10.bias torch.Size([1]) True\n",
      "rho_l1.15.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.15.0.bias torch.Size([3]) True\n",
      "rho_l1.15.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.15.2.bias torch.Size([3]) True\n",
      "rho_l1.15.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.15.4.bias torch.Size([3]) True\n",
      "rho_l1.15.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.15.6.bias torch.Size([3]) True\n",
      "rho_l1.15.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.15.8.bias torch.Size([3]) True\n",
      "rho_l1.15.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.15.10.bias torch.Size([1]) True\n",
      "rho_l1.16.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.16.0.bias torch.Size([3]) True\n",
      "rho_l1.16.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.16.2.bias torch.Size([3]) True\n",
      "rho_l1.16.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.16.4.bias torch.Size([3]) True\n",
      "rho_l1.16.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.16.6.bias torch.Size([3]) True\n",
      "rho_l1.16.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.16.8.bias torch.Size([3]) True\n",
      "rho_l1.16.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.16.10.bias torch.Size([1]) True\n",
      "rho_l1.17.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.17.0.bias torch.Size([3]) True\n",
      "rho_l1.17.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.17.2.bias torch.Size([3]) True\n",
      "rho_l1.17.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.17.4.bias torch.Size([3]) True\n",
      "rho_l1.17.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.17.6.bias torch.Size([3]) True\n",
      "rho_l1.17.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.17.8.bias torch.Size([3]) True\n",
      "rho_l1.17.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.17.10.bias torch.Size([1]) True\n",
      "rho_l1.18.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.18.0.bias torch.Size([3]) True\n",
      "rho_l1.18.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.18.2.bias torch.Size([3]) True\n",
      "rho_l1.18.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.18.4.bias torch.Size([3]) True\n",
      "rho_l1.18.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.18.6.bias torch.Size([3]) True\n",
      "rho_l1.18.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.18.8.bias torch.Size([3]) True\n",
      "rho_l1.18.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.18.10.bias torch.Size([1]) True\n",
      "rho_l1.19.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.19.0.bias torch.Size([3]) True\n",
      "rho_l1.19.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.19.2.bias torch.Size([3]) True\n",
      "rho_l1.19.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.19.4.bias torch.Size([3]) True\n",
      "rho_l1.19.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.19.6.bias torch.Size([3]) True\n",
      "rho_l1.19.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.19.8.bias torch.Size([3]) True\n",
      "rho_l1.19.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.19.10.bias torch.Size([1]) True\n",
      "rho_l1.20.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.20.0.bias torch.Size([3]) True\n",
      "rho_l1.20.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.20.2.bias torch.Size([3]) True\n",
      "rho_l1.20.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.20.4.bias torch.Size([3]) True\n",
      "rho_l1.20.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.20.6.bias torch.Size([3]) True\n",
      "rho_l1.20.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.20.8.bias torch.Size([3]) True\n",
      "rho_l1.20.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.20.10.bias torch.Size([1]) True\n",
      "rho_l1.21.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.21.0.bias torch.Size([3]) True\n",
      "rho_l1.21.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.21.2.bias torch.Size([3]) True\n",
      "rho_l1.21.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.21.4.bias torch.Size([3]) True\n",
      "rho_l1.21.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.21.6.bias torch.Size([3]) True\n",
      "rho_l1.21.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.21.8.bias torch.Size([3]) True\n",
      "rho_l1.21.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.21.10.bias torch.Size([1]) True\n",
      "rho_l1.22.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.22.0.bias torch.Size([3]) True\n",
      "rho_l1.22.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.22.2.bias torch.Size([3]) True\n",
      "rho_l1.22.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.22.4.bias torch.Size([3]) True\n",
      "rho_l1.22.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.22.6.bias torch.Size([3]) True\n",
      "rho_l1.22.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.22.8.bias torch.Size([3]) True\n",
      "rho_l1.22.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.22.10.bias torch.Size([1]) True\n",
      "rho_l1.23.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.23.0.bias torch.Size([3]) True\n",
      "rho_l1.23.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.23.2.bias torch.Size([3]) True\n",
      "rho_l1.23.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.23.4.bias torch.Size([3]) True\n",
      "rho_l1.23.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.23.6.bias torch.Size([3]) True\n",
      "rho_l1.23.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.23.8.bias torch.Size([3]) True\n",
      "rho_l1.23.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.23.10.bias torch.Size([1]) True\n",
      "rho_l1.24.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.24.0.bias torch.Size([3]) True\n",
      "rho_l1.24.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.24.2.bias torch.Size([3]) True\n",
      "rho_l1.24.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.24.4.bias torch.Size([3]) True\n",
      "rho_l1.24.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.24.6.bias torch.Size([3]) True\n",
      "rho_l1.24.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.24.8.bias torch.Size([3]) True\n",
      "rho_l1.24.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.24.10.bias torch.Size([1]) True\n",
      "rho_l1.25.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.25.0.bias torch.Size([3]) True\n",
      "rho_l1.25.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.25.2.bias torch.Size([3]) True\n",
      "rho_l1.25.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.25.4.bias torch.Size([3]) True\n",
      "rho_l1.25.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.25.6.bias torch.Size([3]) True\n",
      "rho_l1.25.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.25.8.bias torch.Size([3]) True\n",
      "rho_l1.25.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.25.10.bias torch.Size([1]) True\n",
      "rho_l1.26.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.26.0.bias torch.Size([3]) True\n",
      "rho_l1.26.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.26.2.bias torch.Size([3]) True\n",
      "rho_l1.26.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.26.4.bias torch.Size([3]) True\n",
      "rho_l1.26.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.26.6.bias torch.Size([3]) True\n",
      "rho_l1.26.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.26.8.bias torch.Size([3]) True\n",
      "rho_l1.26.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.26.10.bias torch.Size([1]) True\n",
      "rho_l1.27.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.27.0.bias torch.Size([3]) True\n",
      "rho_l1.27.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.27.2.bias torch.Size([3]) True\n",
      "rho_l1.27.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.27.4.bias torch.Size([3]) True\n",
      "rho_l1.27.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.27.6.bias torch.Size([3]) True\n",
      "rho_l1.27.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.27.8.bias torch.Size([3]) True\n",
      "rho_l1.27.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.27.10.bias torch.Size([1]) True\n",
      "rho_l1.28.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.28.0.bias torch.Size([3]) True\n",
      "rho_l1.28.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.28.2.bias torch.Size([3]) True\n",
      "rho_l1.28.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.28.4.bias torch.Size([3]) True\n",
      "rho_l1.28.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.28.6.bias torch.Size([3]) True\n",
      "rho_l1.28.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.28.8.bias torch.Size([3]) True\n",
      "rho_l1.28.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.28.10.bias torch.Size([1]) True\n",
      "rho_l1.29.0.weight torch.Size([3, 3]) True\n",
      "rho_l1.29.0.bias torch.Size([3]) True\n",
      "rho_l1.29.2.weight torch.Size([3, 3]) True\n",
      "rho_l1.29.2.bias torch.Size([3]) True\n",
      "rho_l1.29.4.weight torch.Size([3, 3]) True\n",
      "rho_l1.29.4.bias torch.Size([3]) True\n",
      "rho_l1.29.6.weight torch.Size([3, 3]) True\n",
      "rho_l1.29.6.bias torch.Size([3]) True\n",
      "rho_l1.29.8.weight torch.Size([3, 3]) True\n",
      "rho_l1.29.8.bias torch.Size([3]) True\n",
      "rho_l1.29.10.weight torch.Size([1, 3]) True\n",
      "rho_l1.29.10.bias torch.Size([1]) True\n",
      "lambda_f.0.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.0.0.bias torch.Size([3]) True\n",
      "lambda_f.0.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.0.2.bias torch.Size([3]) True\n",
      "lambda_f.0.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.0.4.bias torch.Size([3]) True\n",
      "lambda_f.0.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.0.6.bias torch.Size([1]) True\n",
      "lambda_f.1.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.1.0.bias torch.Size([3]) True\n",
      "lambda_f.1.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.1.2.bias torch.Size([3]) True\n",
      "lambda_f.1.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.1.4.bias torch.Size([3]) True\n",
      "lambda_f.1.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.1.6.bias torch.Size([1]) True\n",
      "lambda_f.2.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.2.0.bias torch.Size([3]) True\n",
      "lambda_f.2.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.2.2.bias torch.Size([3]) True\n",
      "lambda_f.2.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.2.4.bias torch.Size([3]) True\n",
      "lambda_f.2.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.2.6.bias torch.Size([1]) True\n",
      "lambda_f.3.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.3.0.bias torch.Size([3]) True\n",
      "lambda_f.3.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.3.2.bias torch.Size([3]) True\n",
      "lambda_f.3.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.3.4.bias torch.Size([3]) True\n",
      "lambda_f.3.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.3.6.bias torch.Size([1]) True\n",
      "lambda_f.4.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.4.0.bias torch.Size([3]) True\n",
      "lambda_f.4.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.4.2.bias torch.Size([3]) True\n",
      "lambda_f.4.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.4.4.bias torch.Size([3]) True\n",
      "lambda_f.4.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.4.6.bias torch.Size([1]) True\n",
      "lambda_f.5.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.5.0.bias torch.Size([3]) True\n",
      "lambda_f.5.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.5.2.bias torch.Size([3]) True\n",
      "lambda_f.5.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.5.4.bias torch.Size([3]) True\n",
      "lambda_f.5.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.5.6.bias torch.Size([1]) True\n",
      "lambda_f.6.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.6.0.bias torch.Size([3]) True\n",
      "lambda_f.6.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.6.2.bias torch.Size([3]) True\n",
      "lambda_f.6.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.6.4.bias torch.Size([3]) True\n",
      "lambda_f.6.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.6.6.bias torch.Size([1]) True\n",
      "lambda_f.7.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.7.0.bias torch.Size([3]) True\n",
      "lambda_f.7.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.7.2.bias torch.Size([3]) True\n",
      "lambda_f.7.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.7.4.bias torch.Size([3]) True\n",
      "lambda_f.7.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.7.6.bias torch.Size([1]) True\n",
      "lambda_f.8.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.8.0.bias torch.Size([3]) True\n",
      "lambda_f.8.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.8.2.bias torch.Size([3]) True\n",
      "lambda_f.8.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.8.4.bias torch.Size([3]) True\n",
      "lambda_f.8.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.8.6.bias torch.Size([1]) True\n",
      "lambda_f.9.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.9.0.bias torch.Size([3]) True\n",
      "lambda_f.9.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.9.2.bias torch.Size([3]) True\n",
      "lambda_f.9.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.9.4.bias torch.Size([3]) True\n",
      "lambda_f.9.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.9.6.bias torch.Size([1]) True\n",
      "lambda_f.10.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.10.0.bias torch.Size([3]) True\n",
      "lambda_f.10.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.10.2.bias torch.Size([3]) True\n",
      "lambda_f.10.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.10.4.bias torch.Size([3]) True\n",
      "lambda_f.10.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.10.6.bias torch.Size([1]) True\n",
      "lambda_f.11.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.11.0.bias torch.Size([3]) True\n",
      "lambda_f.11.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.11.2.bias torch.Size([3]) True\n",
      "lambda_f.11.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.11.4.bias torch.Size([3]) True\n",
      "lambda_f.11.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.11.6.bias torch.Size([1]) True\n",
      "lambda_f.12.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.12.0.bias torch.Size([3]) True\n",
      "lambda_f.12.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.12.2.bias torch.Size([3]) True\n",
      "lambda_f.12.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.12.4.bias torch.Size([3]) True\n",
      "lambda_f.12.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.12.6.bias torch.Size([1]) True\n",
      "lambda_f.13.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.13.0.bias torch.Size([3]) True\n",
      "lambda_f.13.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.13.2.bias torch.Size([3]) True\n",
      "lambda_f.13.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.13.4.bias torch.Size([3]) True\n",
      "lambda_f.13.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.13.6.bias torch.Size([1]) True\n",
      "lambda_f.14.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.14.0.bias torch.Size([3]) True\n",
      "lambda_f.14.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.14.2.bias torch.Size([3]) True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_f.14.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.14.4.bias torch.Size([3]) True\n",
      "lambda_f.14.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.14.6.bias torch.Size([1]) True\n",
      "lambda_f.15.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.15.0.bias torch.Size([3]) True\n",
      "lambda_f.15.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.15.2.bias torch.Size([3]) True\n",
      "lambda_f.15.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.15.4.bias torch.Size([3]) True\n",
      "lambda_f.15.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.15.6.bias torch.Size([1]) True\n",
      "lambda_f.16.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.16.0.bias torch.Size([3]) True\n",
      "lambda_f.16.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.16.2.bias torch.Size([3]) True\n",
      "lambda_f.16.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.16.4.bias torch.Size([3]) True\n",
      "lambda_f.16.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.16.6.bias torch.Size([1]) True\n",
      "lambda_f.17.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.17.0.bias torch.Size([3]) True\n",
      "lambda_f.17.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.17.2.bias torch.Size([3]) True\n",
      "lambda_f.17.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.17.4.bias torch.Size([3]) True\n",
      "lambda_f.17.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.17.6.bias torch.Size([1]) True\n",
      "lambda_f.18.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.18.0.bias torch.Size([3]) True\n",
      "lambda_f.18.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.18.2.bias torch.Size([3]) True\n",
      "lambda_f.18.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.18.4.bias torch.Size([3]) True\n",
      "lambda_f.18.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.18.6.bias torch.Size([1]) True\n",
      "lambda_f.19.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.19.0.bias torch.Size([3]) True\n",
      "lambda_f.19.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.19.2.bias torch.Size([3]) True\n",
      "lambda_f.19.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.19.4.bias torch.Size([3]) True\n",
      "lambda_f.19.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.19.6.bias torch.Size([1]) True\n",
      "lambda_f.20.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.20.0.bias torch.Size([3]) True\n",
      "lambda_f.20.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.20.2.bias torch.Size([3]) True\n",
      "lambda_f.20.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.20.4.bias torch.Size([3]) True\n",
      "lambda_f.20.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.20.6.bias torch.Size([1]) True\n",
      "lambda_f.21.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.21.0.bias torch.Size([3]) True\n",
      "lambda_f.21.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.21.2.bias torch.Size([3]) True\n",
      "lambda_f.21.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.21.4.bias torch.Size([3]) True\n",
      "lambda_f.21.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.21.6.bias torch.Size([1]) True\n",
      "lambda_f.22.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.22.0.bias torch.Size([3]) True\n",
      "lambda_f.22.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.22.2.bias torch.Size([3]) True\n",
      "lambda_f.22.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.22.4.bias torch.Size([3]) True\n",
      "lambda_f.22.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.22.6.bias torch.Size([1]) True\n",
      "lambda_f.23.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.23.0.bias torch.Size([3]) True\n",
      "lambda_f.23.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.23.2.bias torch.Size([3]) True\n",
      "lambda_f.23.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.23.4.bias torch.Size([3]) True\n",
      "lambda_f.23.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.23.6.bias torch.Size([1]) True\n",
      "lambda_f.24.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.24.0.bias torch.Size([3]) True\n",
      "lambda_f.24.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.24.2.bias torch.Size([3]) True\n",
      "lambda_f.24.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.24.4.bias torch.Size([3]) True\n",
      "lambda_f.24.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.24.6.bias torch.Size([1]) True\n",
      "lambda_f.25.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.25.0.bias torch.Size([3]) True\n",
      "lambda_f.25.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.25.2.bias torch.Size([3]) True\n",
      "lambda_f.25.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.25.4.bias torch.Size([3]) True\n",
      "lambda_f.25.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.25.6.bias torch.Size([1]) True\n",
      "lambda_f.26.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.26.0.bias torch.Size([3]) True\n",
      "lambda_f.26.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.26.2.bias torch.Size([3]) True\n",
      "lambda_f.26.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.26.4.bias torch.Size([3]) True\n",
      "lambda_f.26.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.26.6.bias torch.Size([1]) True\n",
      "lambda_f.27.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.27.0.bias torch.Size([3]) True\n",
      "lambda_f.27.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.27.2.bias torch.Size([3]) True\n",
      "lambda_f.27.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.27.4.bias torch.Size([3]) True\n",
      "lambda_f.27.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.27.6.bias torch.Size([1]) True\n",
      "lambda_f.28.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.28.0.bias torch.Size([3]) True\n",
      "lambda_f.28.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.28.2.bias torch.Size([3]) True\n",
      "lambda_f.28.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.28.4.bias torch.Size([3]) True\n",
      "lambda_f.28.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.28.6.bias torch.Size([1]) True\n",
      "lambda_f.29.0.weight torch.Size([3, 2]) True\n",
      "lambda_f.29.0.bias torch.Size([3]) True\n",
      "lambda_f.29.2.weight torch.Size([3, 3]) True\n",
      "lambda_f.29.2.bias torch.Size([3]) True\n",
      "lambda_f.29.4.weight torch.Size([3, 3]) True\n",
      "lambda_f.29.4.bias torch.Size([3]) True\n",
      "lambda_f.29.6.weight torch.Size([1, 3]) True\n",
      "lambda_f.29.6.bias torch.Size([1]) True\n",
      "loss_summary: MSE:  [0.4843389]  Mean Frobenius loss:  236.28690076828002\n",
      "loss_values:  0 [0.4843389]\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  1000\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  4000\n",
      "valid/train: ps 17.3750/16.8830 aps 0.2405/0.2383 aucs 0.5858/0.5834 nmse 3.9899/2.0773\n",
      "epoch =  0  Updating the best ps model with valid ps =  17.375\n",
      "epoch =  0  Updating the best nmse model with valid nmse =  3.989940583705902\n",
      "epoch =  0  Updating the best nmse model with valid gmse =  2.506075\n",
      "epoch =  0  Updating the best nmse model with valid gmse except diag = 2.150136709213257+-0.1759775879656607\n",
      "loss_summary:: epoch:  0  loss:  [0.4843389]\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  1000\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  4000\n",
      "valid/train: ps 8.6600/8.3848 aps 0.2082/0.2047 aucs 0.5629/0.5593 nmse 2.4787/1.2004\n",
      "epoch =  1  Updating the best nmse model with valid nmse =  2.4786607921123505\n",
      "epoch =  1  Updating the best nmse model with valid gmse =  1.7695632\n",
      "epoch =  1  Updating the best nmse model with valid gmse except diag = 1.333984613418579+-0.06907905098305547\n",
      "loss_summary:: epoch:  1  loss:  [0.22687654]\n",
      "loss_summary: MSE:  [6.2585616]  Mean Frobenius loss:  2318.942042913437\n",
      "loss_values:  2 [6.2585616]\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  1000\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  4000\n",
      "valid/train: ps 5.9440/5.7748 aps 0.1927/0.1903 aucs 0.5533/0.5507 nmse 1.9276/0.8505\n",
      "epoch =  2  Updating the best nmse model with valid nmse =  1.92758709192276\n",
      "epoch =  2  Updating the best nmse model with valid gmse =  1.5586863\n",
      "epoch =  2  Updating the best nmse model with valid gmse except diag = 1.1657629013061523+-0.0421629880608357\n",
      "loss_summary:: epoch:  2  loss:  [6.2585616]\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  1000\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  4000\n",
      "valid/train: ps 4.8780/4.7305 aps 0.1846/0.1830 aucs 0.5484/0.5465 nmse 1.6870/0.7227\n",
      "epoch =  3  Updating the best nmse model with valid nmse =  1.6870178282260895\n",
      "epoch =  3  Updating the best nmse model with valid gmse =  1.4746935\n",
      "epoch =  3  Updating the best nmse model with valid gmse except diag = 1.1102690696716309+-0.03232432342469525\n",
      "loss_summary:: epoch:  3  loss:  [0.17680359]\n",
      "loss_summary: MSE:  [0.16910914]  Mean Frobenius loss:  66.97817923545837\n",
      "loss_values:  4 [0.16910914]\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  1000\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  4000\n",
      "valid/train: ps 4.3270/4.1790 aps 0.1800/0.1786 aucs 0.5454/0.5438 nmse 1.5443/0.6452\n",
      "epoch =  4  Updating the best nmse model with valid nmse =  1.544313132762909\n",
      "epoch =  4  Updating the best nmse model with valid gmse =  1.4270241\n",
      "epoch =  4  Updating the best nmse model with valid gmse except diag = 1.0835636854171753+-0.027307349720896264\n",
      "loss_summary:: epoch:  4  loss:  [0.16910914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_init_offset Parameter containing:\n",
      "tensor([-0.1293], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.0.weight Parameter containing:\n",
      "tensor([[-0.3543, -0.3788,  0.0514],\n",
      "        [-0.3652, -0.0944, -0.5070],\n",
      "        [-0.2788, -0.3570,  0.5541]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.0.bias Parameter containing:\n",
      "tensor([-0.1378, -0.4910, -0.5694], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.2.weight Parameter containing:\n",
      "tensor([[-0.1082, -0.0864,  0.5991],\n",
      "        [ 0.6811,  0.7125,  0.3698],\n",
      "        [-0.6083,  0.0364,  0.1465]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.2.bias Parameter containing:\n",
      "tensor([-0.4468, -0.1658, -0.2776], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.4.weight Parameter containing:\n",
      "tensor([[ 0.6515,  0.8592,  0.1142],\n",
      "        [ 0.2611, -0.1748,  0.2753],\n",
      "        [ 0.7046,  0.5205, -0.3579]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.4.bias Parameter containing:\n",
      "tensor([-0.0581,  0.0729, -0.4551], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.6.weight Parameter containing:\n",
      "tensor([[-1.0505,  0.1491, -0.0960],\n",
      "        [-0.9605, -0.0864, -0.5399],\n",
      "        [ 0.6566, -0.1034,  0.6184]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.6.bias Parameter containing:\n",
      "tensor([ 0.7522, -0.0805, -0.2709], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.8.weight Parameter containing:\n",
      "tensor([[ 0.2385,  0.3532, -0.3949],\n",
      "        [ 0.1211, -0.1718,  1.0438],\n",
      "        [-0.8537, -0.3674,  0.7032]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.8.bias Parameter containing:\n",
      "tensor([ 0.8701, -0.2336,  0.0028], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.10.weight Parameter containing:\n",
      "tensor([[ 0.6605, -0.6839, -1.0749]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.0.10.bias Parameter containing:\n",
      "tensor([0.3629], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.0.weight Parameter containing:\n",
      "tensor([[ 0.0029, -0.3024, -0.4623],\n",
      "        [-0.2515,  0.1886, -0.3196],\n",
      "        [ 0.1772, -0.2348,  0.3799]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.0.bias Parameter containing:\n",
      "tensor([ 0.2902, -0.2380, -0.3521], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.2.weight Parameter containing:\n",
      "tensor([[-0.6202,  0.4157,  0.1804],\n",
      "        [ 0.7695, -0.1963,  0.3595],\n",
      "        [ 0.0300,  0.0611, -0.0906]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.2.bias Parameter containing:\n",
      "tensor([ 0.4226,  0.2534, -0.2448], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.4.weight Parameter containing:\n",
      "tensor([[-0.0747,  0.9062,  0.1195],\n",
      "        [-0.5525,  0.5607, -0.0865],\n",
      "        [ 0.7953, -0.4453,  0.0855]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.4.bias Parameter containing:\n",
      "tensor([-0.4586, -0.8021, -0.0797], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.6.weight Parameter containing:\n",
      "tensor([[ 0.8569,  0.4173, -0.6076],\n",
      "        [-0.5436, -0.6647,  0.4992],\n",
      "        [ 0.8445,  0.7856, -0.6079]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.6.bias Parameter containing:\n",
      "tensor([-0.6154,  0.3847, -0.0643], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.8.weight Parameter containing:\n",
      "tensor([[ 0.0800, -0.4065,  0.7411],\n",
      "        [-0.4457,  0.2325, -0.7086],\n",
      "        [ 0.5064, -0.3312,  1.0475]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.8.bias Parameter containing:\n",
      "tensor([-0.3571,  0.7768, -0.0839], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.10.weight Parameter containing:\n",
      "tensor([[-0.3457,  0.8839, -0.9152]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.1.10.bias Parameter containing:\n",
      "tensor([0.3992], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.0.weight Parameter containing:\n",
      "tensor([[-0.2923,  0.0828, -0.1650],\n",
      "        [-0.1646, -0.3121,  0.2584],\n",
      "        [-0.3658, -0.5142, -0.2759]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.0.bias Parameter containing:\n",
      "tensor([0.5997, 0.4808, 0.0030], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.2.weight Parameter containing:\n",
      "tensor([[-0.4403, -0.4923, -0.5791],\n",
      "        [ 0.0991, -0.3929, -0.4933],\n",
      "        [ 0.1096, -0.0922, -0.0815]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.2.bias Parameter containing:\n",
      "tensor([0.4330, 0.2988, 0.2406], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.4.weight Parameter containing:\n",
      "tensor([[-0.1686,  0.8549,  0.7217],\n",
      "        [ 0.5878,  0.8726,  0.4821],\n",
      "        [-0.5259, -0.5778,  0.2363]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.4.bias Parameter containing:\n",
      "tensor([0.8971, 0.4995, 0.3606], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.6.weight Parameter containing:\n",
      "tensor([[-0.5588, -0.4333,  0.1539],\n",
      "        [ 0.4640,  0.1731, -0.2466],\n",
      "        [ 0.9436,  0.7201,  0.4466]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.6.bias Parameter containing:\n",
      "tensor([-0.9151,  0.1795,  0.2474], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.8.weight Parameter containing:\n",
      "tensor([[-0.1642,  0.5907,  0.5308],\n",
      "        [ 0.6174, -0.3529, -0.2291],\n",
      "        [-0.6727,  0.7142,  0.7788]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.8.bias Parameter containing:\n",
      "tensor([ 0.8323, -0.8458, -0.2044], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.10.weight Parameter containing:\n",
      "tensor([[ 1.1707, -0.9402,  0.8721]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.2.10.bias Parameter containing:\n",
      "tensor([-0.1337], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.0.weight Parameter containing:\n",
      "tensor([[-0.0419, -0.1839,  0.2190],\n",
      "        [-0.0785,  0.3664,  0.5353],\n",
      "        [-0.3952,  0.1281,  0.0102]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.0.bias Parameter containing:\n",
      "tensor([-0.1500, -0.3727, -0.3552], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.2.weight Parameter containing:\n",
      "tensor([[ 0.3486, -0.0030, -0.3625],\n",
      "        [ 0.7749, -0.8379, -0.5748],\n",
      "        [ 0.0347,  0.0622, -0.4172]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.2.bias Parameter containing:\n",
      "tensor([-0.7832,  0.2993,  0.5081], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.4.weight Parameter containing:\n",
      "tensor([[-0.7357, -0.4620,  0.1871],\n",
      "        [ 0.7224,  0.4860, -0.4569],\n",
      "        [ 0.4703,  0.2763,  0.2915]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.4.bias Parameter containing:\n",
      "tensor([ 0.3684, -0.1533,  0.0190], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.6.weight Parameter containing:\n",
      "tensor([[-0.0760,  0.8119, -0.3372],\n",
      "        [ 0.3732, -0.6653, -0.5541],\n",
      "        [ 0.8433, -0.1501,  0.1390]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.6.bias Parameter containing:\n",
      "tensor([-0.1029,  0.1159,  0.6271], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.8.weight Parameter containing:\n",
      "tensor([[ 0.1988, -1.1213, -0.0277],\n",
      "        [ 0.3964, -0.7976, -0.7927],\n",
      "        [ 0.5577, -0.5022, -0.7050]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.8.bias Parameter containing:\n",
      "tensor([-0.2752, -0.4036, -0.3677], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.10.weight Parameter containing:\n",
      "tensor([[-1.0413, -0.9583, -1.0643]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.3.10.bias Parameter containing:\n",
      "tensor([0.6715], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.0.weight Parameter containing:\n",
      "tensor([[-0.5019, -0.0877, -0.0177],\n",
      "        [ 0.4119,  0.0250,  0.3930],\n",
      "        [ 0.3815,  0.1380, -0.1205]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.0.bias Parameter containing:\n",
      "tensor([ 0.4080, -0.3964, -0.3104], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.2.weight Parameter containing:\n",
      "tensor([[ 0.1100, -0.3997,  0.1639],\n",
      "        [-0.2571,  0.4661,  0.0528],\n",
      "        [-0.5515, -0.3885,  0.2818]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.2.bias Parameter containing:\n",
      "tensor([-0.5024,  0.3398,  0.8502], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.4.weight Parameter containing:\n",
      "tensor([[-0.0626,  0.8233,  0.2407],\n",
      "        [-0.6600,  0.6135,  0.4037],\n",
      "        [ 0.6027, -0.1246, -0.2977]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.4.bias Parameter containing:\n",
      "tensor([ 0.4761,  0.3507, -0.0195], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.6.weight Parameter containing:\n",
      "tensor([[-0.5076, -0.4011,  0.0862],\n",
      "        [ 0.8148,  0.7645,  0.2312],\n",
      "        [ 0.5319,  0.7783, -0.7167]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.6.bias Parameter containing:\n",
      "tensor([-0.8073,  0.6556,  0.1322], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.8.weight Parameter containing:\n",
      "tensor([[-0.4537,  0.4073,  1.0240],\n",
      "        [ 0.0891, -0.2727, -0.7462],\n",
      "        [ 0.7456, -0.2655, -0.6498]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.8.bias Parameter containing:\n",
      "tensor([ 0.5224, -0.5815, -0.1633], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.10.weight Parameter containing:\n",
      "tensor([[ 0.6197, -0.9704, -1.0275]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.4.10.bias Parameter containing:\n",
      "tensor([0.8477], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.0.weight Parameter containing:\n",
      "tensor([[ 0.3511,  0.3303,  0.4527],\n",
      "        [ 0.4447, -0.3752, -0.0453],\n",
      "        [-0.4954,  0.3442,  0.0409]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.0.bias Parameter containing:\n",
      "tensor([-0.1399,  0.4801, -0.2710], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.2.weight Parameter containing:\n",
      "tensor([[-0.6252,  0.4994, -0.4677],\n",
      "        [ 0.1208,  0.4159, -0.5612],\n",
      "        [-0.2614, -0.2582,  0.7694]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.2.bias Parameter containing:\n",
      "tensor([-0.7314, -0.4269,  0.4106], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.4.weight Parameter containing:\n",
      "tensor([[ 0.3901,  0.1166, -0.3882],\n",
      "        [ 0.3972,  0.0295, -0.6888],\n",
      "        [-0.2793, -0.3875,  0.8769]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.4.bias Parameter containing:\n",
      "tensor([-0.3327,  0.0865,  0.1792], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.6.weight Parameter containing:\n",
      "tensor([[-0.3722, -0.3537,  0.1059],\n",
      "        [-0.8186, -0.5923,  0.5375],\n",
      "        [-0.4271, -0.3338,  0.7919]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.6.bias Parameter containing:\n",
      "tensor([ 0.5999,  0.3523, -0.0323], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.8.weight Parameter containing:\n",
      "tensor([[-0.7220, -0.7449, -0.5586],\n",
      "        [-0.3968, -0.9549, -0.2906],\n",
      "        [ 0.6659,  0.8310,  0.6281]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.8.bias Parameter containing:\n",
      "tensor([ 0.0141, -0.7674, -0.0378], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.10.weight Parameter containing:\n",
      "tensor([[-0.9285, -0.5858,  0.7666]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.5.10.bias Parameter containing:\n",
      "tensor([0.6594], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.0.weight Parameter containing:\n",
      "tensor([[-0.2966, -0.5104,  0.3671],\n",
      "        [ 0.0424, -0.5255, -0.0544],\n",
      "        [-0.5021,  0.1714,  0.5708]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.0.bias Parameter containing:\n",
      "tensor([-0.3770, -0.5189,  0.2766], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.2.weight Parameter containing:\n",
      "tensor([[ 0.6066,  0.8327, -0.0419],\n",
      "        [ 0.6979,  0.4792, -0.3399],\n",
      "        [-0.3258, -0.6080,  0.7321]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.2.bias Parameter containing:\n",
      "tensor([0.2668, 0.2231, 0.6002], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.4.weight Parameter containing:\n",
      "tensor([[ 0.0127,  0.4613, -0.0613],\n",
      "        [-0.4641, -0.6410,  0.6656],\n",
      "        [-0.8368, -0.5569,  0.5629]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.4.bias Parameter containing:\n",
      "tensor([-0.6735,  0.3551,  0.6149], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.6.weight Parameter containing:\n",
      "tensor([[ 7.6027e-04, -3.2712e-01, -5.8657e-01],\n",
      "        [ 2.3284e-01, -7.6677e-01, -1.0317e+00],\n",
      "        [-7.8215e-01,  6.8805e-01,  5.0799e-01]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "rho_l1.6.6.bias Parameter containing:\n",
      "tensor([-0.9391, -0.3341,  0.7741], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.8.weight Parameter containing:\n",
      "tensor([[-0.3459, -1.0365,  0.4792],\n",
      "        [-0.8302, -0.5589,  0.6883],\n",
      "        [-0.6723, -0.4232,  0.6792]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.8.bias Parameter containing:\n",
      "tensor([0.0209, 0.5545, 0.0627], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.10.weight Parameter containing:\n",
      "tensor([[0.6878, 0.7878, 1.1181]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.6.10.bias Parameter containing:\n",
      "tensor([0.0241], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.0.weight Parameter containing:\n",
      "tensor([[ 0.0411,  0.4826,  0.5596],\n",
      "        [-0.4148, -0.1037,  0.4315],\n",
      "        [-0.5307,  0.2299,  0.0582]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.0.bias Parameter containing:\n",
      "tensor([ 0.0631, -0.1965, -0.3918], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.2.weight Parameter containing:\n",
      "tensor([[ 0.1542,  0.8417, -0.4736],\n",
      "        [ 0.4095,  0.0294,  0.2853],\n",
      "        [-0.1004, -0.1222, -0.3537]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.2.bias Parameter containing:\n",
      "tensor([-0.8372, -0.1989, -0.4469], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.4.weight Parameter containing:\n",
      "tensor([[-0.9442,  0.4541, -0.4862],\n",
      "        [-0.3916,  0.2437, -0.3987],\n",
      "        [-0.0916,  0.2700, -0.4675]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.4.bias Parameter containing:\n",
      "tensor([ 0.4126,  0.0677, -0.1002], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.6.weight Parameter containing:\n",
      "tensor([[-0.0149, -0.5790, -0.2941],\n",
      "        [ 0.2518, -0.0094, -0.0778],\n",
      "        [-0.9830, -0.5949,  0.0136]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.6.bias Parameter containing:\n",
      "tensor([-0.0889,  0.3379, -0.3165], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.8.weight Parameter containing:\n",
      "tensor([[ 0.0460, -0.0786,  0.8767],\n",
      "        [ 0.2328, -0.3662,  0.3068],\n",
      "        [-0.3626,  0.0245, -0.9983]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.8.bias Parameter containing:\n",
      "tensor([-0.6762, -1.0411,  0.5632], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.10.weight Parameter containing:\n",
      "tensor([[-1.0139, -0.8886,  0.9842]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.7.10.bias Parameter containing:\n",
      "tensor([0.5894], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.0.weight Parameter containing:\n",
      "tensor([[ 0.1505, -0.5582, -0.4711],\n",
      "        [-0.5569,  0.4275, -0.5113],\n",
      "        [-0.3327,  0.1561, -0.2023]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.0.bias Parameter containing:\n",
      "tensor([0.1066, 0.4345, 0.1429], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.2.weight Parameter containing:\n",
      "tensor([[ 0.4804,  0.3665, -0.1204],\n",
      "        [ 0.3425,  0.6346,  0.6143],\n",
      "        [ 0.2077,  0.6931, -0.0619]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.2.bias Parameter containing:\n",
      "tensor([-0.1950,  0.6522,  0.6295], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.4.weight Parameter containing:\n",
      "tensor([[-0.6054,  0.4759,  0.8304],\n",
      "        [-0.1752,  0.0636,  0.2914],\n",
      "        [ 0.0652,  0.4331,  0.5335]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.4.bias Parameter containing:\n",
      "tensor([0.1542, 0.5936, 0.4240], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.6.weight Parameter containing:\n",
      "tensor([[ 0.3388,  0.4766,  0.5715],\n",
      "        [ 0.3951,  1.0144,  0.6376],\n",
      "        [-0.7015, -0.5273, -0.7282]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.6.bias Parameter containing:\n",
      "tensor([ 0.5337,  0.3850, -0.5977], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.8.weight Parameter containing:\n",
      "tensor([[ 0.7324,  0.1163, -0.5304],\n",
      "        [-0.8683, -0.4549,  0.0500],\n",
      "        [ 0.3717,  0.8049, -0.6814]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.8.bias Parameter containing:\n",
      "tensor([ 0.4458, -0.1227,  0.1625], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.10.weight Parameter containing:\n",
      "tensor([[ 0.9994, -0.8523,  0.9823]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.8.10.bias Parameter containing:\n",
      "tensor([0.8574], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.0.weight Parameter containing:\n",
      "tensor([[ 0.3784,  0.5360, -0.1740],\n",
      "        [ 0.5245,  0.4642, -0.2542],\n",
      "        [-0.0883, -0.3983, -0.0660]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.0.bias Parameter containing:\n",
      "tensor([-4.8229e-01, -2.1672e-04, -5.1695e-01], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "rho_l1.9.2.weight Parameter containing:\n",
      "tensor([[-0.6995, -0.4630, -0.0648],\n",
      "        [-0.2513, -0.0864, -0.2237],\n",
      "        [-0.2628, -0.8193,  0.2028]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.2.bias Parameter containing:\n",
      "tensor([-0.4375,  0.4775,  0.1168], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.4.weight Parameter containing:\n",
      "tensor([[-0.8233,  0.2993, -0.6889],\n",
      "        [ 0.0490, -0.5756,  0.4964],\n",
      "        [ 0.2251, -0.2123, -0.0862]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.4.bias Parameter containing:\n",
      "tensor([ 0.0443, -0.8879,  0.0760], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.6.weight Parameter containing:\n",
      "tensor([[-0.9021,  0.4154, -0.0869],\n",
      "        [ 0.0371, -0.6481,  0.1600],\n",
      "        [ 0.6993, -0.9255, -0.6842]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.6.bias Parameter containing:\n",
      "tensor([-0.2739,  0.1499,  0.5654], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.8.weight Parameter containing:\n",
      "tensor([[ 1.2101,  0.0112, -0.5441],\n",
      "        [ 0.9389, -0.2122, -0.6514],\n",
      "        [-0.8920,  0.5222,  0.6302]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.8.bias Parameter containing:\n",
      "tensor([-0.9262, -0.7427,  0.7272], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.10.weight Parameter containing:\n",
      "tensor([[-0.5600, -0.9496,  0.7109]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.9.10.bias Parameter containing:\n",
      "tensor([0.7109], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.0.weight Parameter containing:\n",
      "tensor([[-0.1566, -0.5165, -0.5655],\n",
      "        [-0.0150,  0.3319, -0.2499],\n",
      "        [ 0.2611, -0.1296,  0.0691]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.0.bias Parameter containing:\n",
      "tensor([ 0.3001,  0.2669, -0.0736], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.2.weight Parameter containing:\n",
      "tensor([[ 0.7662, -0.3178,  0.6042],\n",
      "        [ 0.4455,  0.3577,  0.3123],\n",
      "        [ 0.0451,  0.2588, -0.1121]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.2.bias Parameter containing:\n",
      "tensor([-0.2085, -0.2875,  0.4126], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.4.weight Parameter containing:\n",
      "tensor([[-0.5746, -0.5850,  0.9023],\n",
      "        [ 0.8271,  0.4646, -0.4793],\n",
      "        [ 0.1104,  0.8095, -0.7804]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.4.bias Parameter containing:\n",
      "tensor([ 0.4741, -0.6031, -0.2404], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.6.weight Parameter containing:\n",
      "tensor([[-0.8370,  0.5121,  0.1627],\n",
      "        [-0.6282, -0.0720,  0.3204],\n",
      "        [-0.3620,  0.4366,  0.6942]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.6.bias Parameter containing:\n",
      "tensor([-0.2799, -0.7205, -0.4375], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.8.weight Parameter containing:\n",
      "tensor([[ 0.1637,  1.0126,  0.6618],\n",
      "        [ 0.3782,  0.2777,  0.9639],\n",
      "        [-0.2509, -0.8532, -0.7081]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.8.bias Parameter containing:\n",
      "tensor([-0.0769, -0.1771,  0.1458], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.10.weight Parameter containing:\n",
      "tensor([[-0.4123, -1.1730,  1.2074]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.10.10.bias Parameter containing:\n",
      "tensor([0.6402], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.0.weight Parameter containing:\n",
      "tensor([[ 0.4253, -0.4482,  0.1824],\n",
      "        [ 0.3977, -0.5377, -0.0986],\n",
      "        [-0.5221, -0.0842, -0.1204]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.0.bias Parameter containing:\n",
      "tensor([ 0.0460,  0.3329, -0.5651], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.2.weight Parameter containing:\n",
      "tensor([[-0.7025, -0.7042,  0.0495],\n",
      "        [ 0.2764, -0.0618, -0.6953],\n",
      "        [ 0.7711,  0.0771,  0.4481]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho_l1.11.2.bias Parameter containing:\n",
      "tensor([ 0.3351,  0.5909, -0.0933], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.4.weight Parameter containing:\n",
      "tensor([[-0.3095, -0.8393,  0.6966],\n",
      "        [-0.3016,  0.6705, -0.6952],\n",
      "        [ 0.1970,  0.5739, -0.0125]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.4.bias Parameter containing:\n",
      "tensor([-0.1640,  0.3946,  0.2887], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.6.weight Parameter containing:\n",
      "tensor([[ 1.0222, -0.4763, -0.5979],\n",
      "        [-0.9654,  0.5652,  0.5932],\n",
      "        [ 0.9810, -0.4887, -0.3463]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.6.bias Parameter containing:\n",
      "tensor([-0.1523, -0.0382, -0.2440], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.8.weight Parameter containing:\n",
      "tensor([[-0.4813,  0.7838, -0.9384],\n",
      "        [-0.8986,  0.5425, -0.1742],\n",
      "        [-0.3858,  0.5112, -0.7328]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.8.bias Parameter containing:\n",
      "tensor([-0.0968,  0.6576,  0.4709], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.10.weight Parameter containing:\n",
      "tensor([[0.7885, 0.8521, 1.2382]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.11.10.bias Parameter containing:\n",
      "tensor([-0.1055], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.0.weight Parameter containing:\n",
      "tensor([[-0.1294, -0.4606, -0.0533],\n",
      "        [ 0.2433, -0.3831,  0.2414],\n",
      "        [-0.3820, -0.1845,  0.1021]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.0.bias Parameter containing:\n",
      "tensor([-0.1455, -0.1559, -0.2865], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.2.weight Parameter containing:\n",
      "tensor([[-0.5030, -0.6718,  0.3315],\n",
      "        [ 0.0086,  0.0906,  0.2467],\n",
      "        [-0.4748,  0.2926, -0.3952]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.2.bias Parameter containing:\n",
      "tensor([ 0.4587, -0.1966,  0.4607], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.4.weight Parameter containing:\n",
      "tensor([[-0.4073,  0.1290, -0.8839],\n",
      "        [ 0.2178,  0.3520, -0.2022],\n",
      "        [ 0.7005, -0.3699,  0.4192]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.4.bias Parameter containing:\n",
      "tensor([-0.0342,  0.2543,  0.2496], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.6.weight Parameter containing:\n",
      "tensor([[ 0.7319,  0.2284, -0.6972],\n",
      "        [ 0.0232, -0.3656,  0.7689],\n",
      "        [-0.9253,  0.6282,  0.6946]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.6.bias Parameter containing:\n",
      "tensor([-0.6951,  0.6276,  0.2737], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.8.weight Parameter containing:\n",
      "tensor([[ 0.8666, -0.0597, -0.4504],\n",
      "        [-0.3151,  0.5262,  0.7330],\n",
      "        [ 0.6367, -0.8205, -0.8354]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.8.bias Parameter containing:\n",
      "tensor([-0.1192,  0.7630, -0.1563], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.10.weight Parameter containing:\n",
      "tensor([[-0.7366,  0.9264, -1.0676]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.12.10.bias Parameter containing:\n",
      "tensor([0.5418], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.0.weight Parameter containing:\n",
      "tensor([[ 0.0192,  0.0875,  0.2401],\n",
      "        [-0.2455,  0.3556, -0.5139],\n",
      "        [ 0.4318,  0.3769,  0.4288]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.0.bias Parameter containing:\n",
      "tensor([ 0.4942, -0.2741,  0.0482], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.2.weight Parameter containing:\n",
      "tensor([[ 0.5687,  0.1863, -0.1481],\n",
      "        [-0.6238, -0.7453, -0.5622],\n",
      "        [ 0.6346,  0.2352,  0.4373]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.2.bias Parameter containing:\n",
      "tensor([ 0.8053, -0.5590,  0.3156], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.4.weight Parameter containing:\n",
      "tensor([[ 0.3750, -0.6272, -0.0438],\n",
      "        [ 0.2313, -0.2332,  0.4559],\n",
      "        [-0.6062,  0.6740, -0.6396]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.4.bias Parameter containing:\n",
      "tensor([ 0.4327,  0.6042, -0.0107], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.6.weight Parameter containing:\n",
      "tensor([[-0.9013, -0.3986,  0.1018],\n",
      "        [ 0.8098,  0.8070, -0.7914],\n",
      "        [-0.4431, -0.4206,  0.6648]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.6.bias Parameter containing:\n",
      "tensor([ 0.0215,  0.3069, -0.3363], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.8.weight Parameter containing:\n",
      "tensor([[ 0.2115, -0.8823,  0.9786],\n",
      "        [-0.7052,  0.1171, -0.8719],\n",
      "        [-0.1894,  0.2140, -0.6447]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.8.bias Parameter containing:\n",
      "tensor([0.2021, 0.6413, 0.4205], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.10.weight Parameter containing:\n",
      "tensor([[-1.0795,  0.8643,  0.9132]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.13.10.bias Parameter containing:\n",
      "tensor([0.3299], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.0.weight Parameter containing:\n",
      "tensor([[ 0.2071,  0.1645, -0.1834],\n",
      "        [ 0.4619, -0.0447, -0.5113],\n",
      "        [ 0.1772, -0.1855, -0.3527]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.0.bias Parameter containing:\n",
      "tensor([ 0.4444, -0.5090,  0.1449], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.2.weight Parameter containing:\n",
      "tensor([[-0.3638,  0.0883,  0.3988],\n",
      "        [-0.8532,  0.7946,  0.0202],\n",
      "        [ 0.6182, -0.3414, -0.6250]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.2.bias Parameter containing:\n",
      "tensor([-0.3194,  0.1028, -0.0644], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.4.weight Parameter containing:\n",
      "tensor([[-0.9567, -0.8551,  0.3988],\n",
      "        [-0.0558,  0.6411, -1.0589],\n",
      "        [-0.9559, -0.3376,  0.4157]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.4.bias Parameter containing:\n",
      "tensor([ 0.6531, -0.7333,  0.0990], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.6.weight Parameter containing:\n",
      "tensor([[-0.3342,  0.6046, -0.5793],\n",
      "        [ 0.8406, -0.1699,  0.9292],\n",
      "        [-0.8268,  0.7494, -0.5748]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.6.bias Parameter containing:\n",
      "tensor([0.0897, 0.0708, 0.0854], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.8.weight Parameter containing:\n",
      "tensor([[ 0.6013, -0.5137,  0.6291],\n",
      "        [-0.7596,  0.6397, -0.7679],\n",
      "        [ 0.1897, -0.8687,  0.8630]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.8.bias Parameter containing:\n",
      "tensor([-0.2372, -0.0642, -0.3505], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.10.weight Parameter containing:\n",
      "tensor([[-0.9046,  0.7536, -0.7514]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.14.10.bias Parameter containing:\n",
      "tensor([0.1606], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.0.weight Parameter containing:\n",
      "tensor([[-0.3456,  0.2097, -0.1898],\n",
      "        [ 0.4726, -0.4263, -0.4571],\n",
      "        [ 0.4926,  0.2004,  0.0671]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.0.bias Parameter containing:\n",
      "tensor([-0.4115,  0.4935, -0.1842], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.2.weight Parameter containing:\n",
      "tensor([[ 0.5789, -0.5217, -0.2570],\n",
      "        [ 0.1037,  0.1070,  0.4009],\n",
      "        [ 0.2843, -0.2626,  0.7085]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.2.bias Parameter containing:\n",
      "tensor([0.6410, 0.4615, 0.6831], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.4.weight Parameter containing:\n",
      "tensor([[-0.6252, -0.3578,  0.3257],\n",
      "        [ 0.3934,  0.8831,  0.8891],\n",
      "        [-0.5717,  0.1515, -0.4095]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.4.bias Parameter containing:\n",
      "tensor([ 0.1499,  0.0785, -0.6754], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.6.weight Parameter containing:\n",
      "tensor([[ 0.1164,  1.0331, -0.2213],\n",
      "        [-0.3292,  0.7662, -0.4379],\n",
      "        [ 0.0926, -0.1351,  0.8080]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.6.bias Parameter containing:\n",
      "tensor([ 0.2861,  0.4250, -0.8973], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.8.weight Parameter containing:\n",
      "tensor([[ 0.6265,  0.8163, -0.1289],\n",
      "        [-0.5763, -0.3968,  0.5415],\n",
      "        [ 0.0490,  0.9151, -0.8321]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.8.bias Parameter containing:\n",
      "tensor([ 0.4713, -0.4835,  0.6370], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.10.weight Parameter containing:\n",
      "tensor([[ 1.0039, -0.8953,  1.0223]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.15.10.bias Parameter containing:\n",
      "tensor([0.1254], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.0.weight Parameter containing:\n",
      "tensor([[-0.5415,  0.4718,  0.4775],\n",
      "        [-0.1745,  0.2819,  0.0041],\n",
      "        [ 0.4130, -0.2368, -0.0643]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.0.bias Parameter containing:\n",
      "tensor([-0.4004, -0.3039, -0.2180], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.2.weight Parameter containing:\n",
      "tensor([[-0.3209, -0.4738,  0.6990],\n",
      "        [ 0.7377,  0.3247, -0.6032],\n",
      "        [ 0.3952, -0.1189, -0.8104]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.2.bias Parameter containing:\n",
      "tensor([ 0.2148, -0.0193,  0.0765], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.4.weight Parameter containing:\n",
      "tensor([[ 0.6856, -0.4452, -0.2657],\n",
      "        [ 0.7106, -0.0952, -0.4162],\n",
      "        [-0.5107,  0.3904,  0.6038]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.4.bias Parameter containing:\n",
      "tensor([ 0.0228, -0.3954,  0.5976], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.6.weight Parameter containing:\n",
      "tensor([[ 0.7671,  0.0838, -0.4679],\n",
      "        [-0.5141, -0.7597,  0.8412],\n",
      "        [ 0.7023,  0.5536, -0.4457]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.6.bias Parameter containing:\n",
      "tensor([-0.6517, -0.1298, -0.0357], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.8.weight Parameter containing:\n",
      "tensor([[-0.1831,  0.3778, -0.7709],\n",
      "        [-0.9182,  0.2571, -0.8047],\n",
      "        [-0.3294,  0.6323, -0.6956]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.8.bias Parameter containing:\n",
      "tensor([0.5676, 0.0654, 0.5455], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.10.weight Parameter containing:\n",
      "tensor([[0.4324, 1.0654, 1.0512]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.16.10.bias Parameter containing:\n",
      "tensor([0.2703], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.0.weight Parameter containing:\n",
      "tensor([[-0.0122,  0.4490, -0.3718],\n",
      "        [ 0.3696,  0.0385, -0.2788],\n",
      "        [-0.4438, -0.4032, -0.0611]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.0.bias Parameter containing:\n",
      "tensor([-0.5687,  0.1909, -0.0995], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.2.weight Parameter containing:\n",
      "tensor([[ 0.2558, -0.3341,  0.2200],\n",
      "        [-0.0273,  0.1353,  0.6500],\n",
      "        [ 0.2412, -0.7037,  0.5350]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.2.bias Parameter containing:\n",
      "tensor([ 0.2479, -0.7483, -0.4876], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.4.weight Parameter containing:\n",
      "tensor([[-0.1028,  0.7142,  0.7064],\n",
      "        [ 0.2750, -0.8828, -0.1788],\n",
      "        [ 0.2870,  0.5882,  0.4071]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.4.bias Parameter containing:\n",
      "tensor([-0.2114,  0.7836, -0.0417], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.6.weight Parameter containing:\n",
      "tensor([[ 0.3968, -0.9272,  0.2747],\n",
      "        [-0.4531,  0.4865, -0.1906],\n",
      "        [-0.5474,  0.1689, -0.4269]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.6.bias Parameter containing:\n",
      "tensor([-0.2619,  0.7013,  0.2011], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.8.weight Parameter containing:\n",
      "tensor([[ 0.6535, -0.6403, -0.9339],\n",
      "        [-0.5109,  0.4954,  0.9159],\n",
      "        [ 1.1390, -0.7261, -0.9575]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.8.bias Parameter containing:\n",
      "tensor([-0.4731,  0.4481,  0.2071], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.10.weight Parameter containing:\n",
      "tensor([[-0.7034,  1.1245, -0.5223]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.17.10.bias Parameter containing:\n",
      "tensor([0.9065], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.0.weight Parameter containing:\n",
      "tensor([[-0.5407, -0.3714, -0.2354],\n",
      "        [-0.4647, -0.2096,  0.3681],\n",
      "        [-0.4418, -0.4122, -0.1017]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.0.bias Parameter containing:\n",
      "tensor([ 0.3435, -0.0876, -0.5342], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.2.weight Parameter containing:\n",
      "tensor([[ 0.1219,  0.5188,  0.6909],\n",
      "        [-0.0237,  0.3934,  0.7667],\n",
      "        [-0.5063,  0.0506, -0.4335]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.2.bias Parameter containing:\n",
      "tensor([-0.1922, -0.3726,  0.4288], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.4.weight Parameter containing:\n",
      "tensor([[ 4.0624e-01,  7.6634e-01, -3.3824e-01],\n",
      "        [ 6.9001e-05,  8.1300e-01, -6.1026e-01],\n",
      "        [ 4.5939e-01,  2.4238e-01, -7.8404e-01]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "rho_l1.18.4.bias Parameter containing:\n",
      "tensor([-0.3204, -0.2941, -0.5903], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.6.weight Parameter containing:\n",
      "tensor([[ 0.1887,  0.7808,  0.1945],\n",
      "        [-0.4634, -0.8280, -0.6783],\n",
      "        [-0.5341, -0.1021, -0.9303]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.6.bias Parameter containing:\n",
      "tensor([-0.9769,  0.2680,  0.5752], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.8.weight Parameter containing:\n",
      "tensor([[ 0.2687, -0.9329, -0.7249],\n",
      "        [-0.6959,  0.7253,  0.1921],\n",
      "        [ 0.8821, -0.5623, -0.6671]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.8.bias Parameter containing:\n",
      "tensor([ 0.0524,  0.1869, -0.2650], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.10.weight Parameter containing:\n",
      "tensor([[-0.7759,  0.7183, -1.1490]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.18.10.bias Parameter containing:\n",
      "tensor([-0.0149], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.0.weight Parameter containing:\n",
      "tensor([[ 0.3815, -0.0600,  0.5533],\n",
      "        [ 0.1277,  0.2720, -0.0080],\n",
      "        [ 0.5125, -0.5513,  0.1055]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.0.bias Parameter containing:\n",
      "tensor([0.3286, 0.4911, 0.4433], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.2.weight Parameter containing:\n",
      "tensor([[-0.4722,  0.4654, -0.3125],\n",
      "        [ 0.1244,  0.7503, -0.1018],\n",
      "        [ 0.1166,  0.0543, -0.1173]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.2.bias Parameter containing:\n",
      "tensor([ 0.3103,  0.2143, -0.0798], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.4.weight Parameter containing:\n",
      "tensor([[ 0.3812,  0.7082,  0.4561],\n",
      "        [-0.1644,  0.7529,  0.1789],\n",
      "        [ 0.8418,  0.7881, -0.5424]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.4.bias Parameter containing:\n",
      "tensor([ 0.3337,  0.4403, -0.1952], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.6.weight Parameter containing:\n",
      "tensor([[ 0.9069,  0.3539,  0.7654],\n",
      "        [-0.7350, -0.0647, -0.4313],\n",
      "        [ 0.7822,  0.6123,  0.1186]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.6.bias Parameter containing:\n",
      "tensor([-0.0973, -0.4769,  0.3930], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.8.weight Parameter containing:\n",
      "tensor([[ 0.6364, -0.5022,  0.6826],\n",
      "        [-0.9197,  0.7164, -0.5572],\n",
      "        [-0.0371, -0.6851,  0.9786]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.8.bias Parameter containing:\n",
      "tensor([0.6642, 0.0015, 0.3838], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.10.weight Parameter containing:\n",
      "tensor([[ 1.0193, -1.0760,  0.8536]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.19.10.bias Parameter containing:\n",
      "tensor([0.3203], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.0.weight Parameter containing:\n",
      "tensor([[-0.1796, -0.2478, -0.0807],\n",
      "        [ 0.2017, -0.3605,  0.3632],\n",
      "        [-0.1946, -0.5512, -0.2820]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.0.bias Parameter containing:\n",
      "tensor([0.2524, 0.1009, 0.1101], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.2.weight Parameter containing:\n",
      "tensor([[ 0.1685, -0.1131,  0.4513],\n",
      "        [ 0.6641,  0.0407,  0.3669],\n",
      "        [ 0.2158, -0.2551,  0.2751]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.2.bias Parameter containing:\n",
      "tensor([-0.3707, -0.0194, -0.1997], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.4.weight Parameter containing:\n",
      "tensor([[ 0.4728,  0.9879,  0.4004],\n",
      "        [-0.5533, -0.7364, -0.0627],\n",
      "        [-0.0652,  0.9264,  0.5038]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.4.bias Parameter containing:\n",
      "tensor([-0.0815,  0.7410, -0.6944], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.6.weight Parameter containing:\n",
      "tensor([[ 0.4236, -0.7465,  0.9034],\n",
      "        [-0.2167,  0.1583, -0.4791],\n",
      "        [-0.7883,  0.3562, -0.8106]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.6.bias Parameter containing:\n",
      "tensor([-0.1744, -0.0311, -0.0688], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.8.weight Parameter containing:\n",
      "tensor([[-0.5192,  0.2979,  0.9994],\n",
      "        [ 1.1143, -0.3780, -0.7825],\n",
      "        [ 0.3104, -0.4530, -1.0114]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.8.bias Parameter containing:\n",
      "tensor([ 0.8164, -0.0368, -0.2238], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.10.weight Parameter containing:\n",
      "tensor([[ 0.7388, -0.8302, -0.9479]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.20.10.bias Parameter containing:\n",
      "tensor([0.3632], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.0.weight Parameter containing:\n",
      "tensor([[-0.5438,  0.1398, -0.4018],\n",
      "        [-0.0958,  0.5767, -0.0797],\n",
      "        [ 0.3853,  0.2694, -0.1093]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.0.bias Parameter containing:\n",
      "tensor([ 0.3905, -0.3679,  0.0579], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.2.weight Parameter containing:\n",
      "tensor([[ 0.6529,  0.1621,  0.2642],\n",
      "        [ 0.4139,  0.2506,  0.6549],\n",
      "        [ 0.2445,  0.5657, -0.1151]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.2.bias Parameter containing:\n",
      "tensor([0.7442, 0.4352, 0.7058], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.4.weight Parameter containing:\n",
      "tensor([[ 0.4715,  0.3836,  0.6942],\n",
      "        [ 0.7220,  0.4850,  0.2972],\n",
      "        [-0.6778, -0.4197, -0.6030]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.4.bias Parameter containing:\n",
      "tensor([0.3706, 0.1623, 0.0920], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.6.weight Parameter containing:\n",
      "tensor([[ 0.4254,  0.1321, -0.7129],\n",
      "        [-0.3440, -0.6884,  0.0356],\n",
      "        [ 0.4874,  0.7948, -0.8543]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.6.bias Parameter containing:\n",
      "tensor([0.6315, 0.0589, 0.0042], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.8.weight Parameter containing:\n",
      "tensor([[-0.7821,  0.5702, -0.7357],\n",
      "        [ 0.4779, -0.0964,  0.8248],\n",
      "        [ 0.6179, -0.7815,  1.0257]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.8.bias Parameter containing:\n",
      "tensor([-0.0095,  0.6471,  0.6482], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.10.weight Parameter containing:\n",
      "tensor([[-1.0149,  1.0957,  0.6414]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.21.10.bias Parameter containing:\n",
      "tensor([0.1780], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.0.weight Parameter containing:\n",
      "tensor([[-0.3576, -0.5048, -0.5271],\n",
      "        [-0.4384,  0.4557, -0.2648],\n",
      "        [ 0.1968, -0.3712, -0.4791]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.0.bias Parameter containing:\n",
      "tensor([-0.4489,  0.0159,  0.1325], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.2.weight Parameter containing:\n",
      "tensor([[ 0.8134, -0.0752,  0.3483],\n",
      "        [ 0.7276, -0.6535,  0.4593],\n",
      "        [-0.1264, -0.7223,  0.9380]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.2.bias Parameter containing:\n",
      "tensor([-0.8064,  0.1061, -0.3859], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.4.weight Parameter containing:\n",
      "tensor([[ 0.9729, -0.0628,  0.8293],\n",
      "        [ 0.5985,  0.8337,  0.3292],\n",
      "        [ 0.8245,  0.5108,  0.2703]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.4.bias Parameter containing:\n",
      "tensor([ 0.0096, -0.6122, -0.2740], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.6.weight Parameter containing:\n",
      "tensor([[-0.6459, -0.7741, -0.4702],\n",
      "        [-0.5956, -0.3592, -0.5804],\n",
      "        [-0.6255, -0.5478, -0.1591]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.6.bias Parameter containing:\n",
      "tensor([-0.1333,  0.5931,  0.0393], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.8.weight Parameter containing:\n",
      "tensor([[-0.6458, -0.9395, -0.5744],\n",
      "        [-0.8458, -0.6022, -0.2137],\n",
      "        [-1.0300, -0.8401, -0.3119]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.8.bias Parameter containing:\n",
      "tensor([-0.0032, -0.3559, -0.2013], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.10.weight Parameter containing:\n",
      "tensor([[-0.7644, -1.1253, -0.7990]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.22.10.bias Parameter containing:\n",
      "tensor([0.8875], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.0.weight Parameter containing:\n",
      "tensor([[-0.5766,  0.2635, -0.2446],\n",
      "        [-0.0746, -0.1511, -0.4993],\n",
      "        [ 0.3964,  0.0584,  0.2097]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.0.bias Parameter containing:\n",
      "tensor([ 0.1096, -0.5731,  0.3812], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho_l1.23.2.weight Parameter containing:\n",
      "tensor([[-0.4453,  0.6725, -0.3660],\n",
      "        [-0.2477, -0.2461, -0.6250],\n",
      "        [-0.6804,  0.2249, -0.1918]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.2.bias Parameter containing:\n",
      "tensor([-0.4550, -0.2439, -0.5151], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.4.weight Parameter containing:\n",
      "tensor([[-0.1150,  0.2930, -0.1775],\n",
      "        [ 0.1437, -0.4381, -0.1161],\n",
      "        [ 0.7540,  0.6687,  0.6378]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.4.bias Parameter containing:\n",
      "tensor([0.3212, 0.8359, 0.1614], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.6.weight Parameter containing:\n",
      "tensor([[-0.6888, -0.4847,  0.9049],\n",
      "        [-0.0390,  0.8746, -0.1578],\n",
      "        [-0.3142,  0.8947, -0.7593]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.6.bias Parameter containing:\n",
      "tensor([-0.1215,  0.8372,  0.4299], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.8.weight Parameter containing:\n",
      "tensor([[-0.4075,  0.8869,  0.7645],\n",
      "        [ 0.6029, -0.4910, -0.8042],\n",
      "        [ 1.0133, -0.8552, -0.7539]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.8.bias Parameter containing:\n",
      "tensor([ 0.5908, -0.4299, -0.5974], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.10.weight Parameter containing:\n",
      "tensor([[ 0.7798, -1.0770, -0.6759]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.23.10.bias Parameter containing:\n",
      "tensor([0.4284], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.0.weight Parameter containing:\n",
      "tensor([[-0.3669, -0.2644,  0.0372],\n",
      "        [ 0.5518,  0.0494,  0.0425],\n",
      "        [-0.2168,  0.4750,  0.0306]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.0.bias Parameter containing:\n",
      "tensor([ 0.2181, -0.2019,  0.4103], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.2.weight Parameter containing:\n",
      "tensor([[ 0.0538,  0.3233,  0.3431],\n",
      "        [ 0.3564, -0.4033, -0.1385],\n",
      "        [ 0.0556,  0.1403, -0.6534]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.2.bias Parameter containing:\n",
      "tensor([ 0.4362, -0.3783,  0.1338], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.4.weight Parameter containing:\n",
      "tensor([[-0.2645,  0.2972,  0.0393],\n",
      "        [ 0.0839, -0.7960, -0.3157],\n",
      "        [-0.0740,  0.8506, -0.0792]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.4.bias Parameter containing:\n",
      "tensor([-0.6255,  0.4471, -0.7615], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.6.weight Parameter containing:\n",
      "tensor([[ 0.0593, -0.2723,  0.0267],\n",
      "        [-0.4559,  0.6025, -0.9399],\n",
      "        [ 0.0265,  0.7291, -0.5031]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.6.bias Parameter containing:\n",
      "tensor([-0.4676,  0.1438,  0.5313], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.8.weight Parameter containing:\n",
      "tensor([[ 0.1617,  1.0768,  1.0680],\n",
      "        [ 0.4683, -0.9203, -0.5748],\n",
      "        [ 0.6265, -1.1368, -0.1798]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.8.bias Parameter containing:\n",
      "tensor([-0.1026, -0.5934, -0.4928], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.10.weight Parameter containing:\n",
      "tensor([[ 0.7252, -0.9712, -0.4646]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.24.10.bias Parameter containing:\n",
      "tensor([0.7852], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.0.weight Parameter containing:\n",
      "tensor([[-0.3575,  0.1889,  0.2408],\n",
      "        [-0.5185, -0.3071, -0.5226],\n",
      "        [-0.0131,  0.0182, -0.5631]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.0.bias Parameter containing:\n",
      "tensor([-0.0574,  0.5090, -0.0060], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.2.weight Parameter containing:\n",
      "tensor([[ 0.3040,  0.3058,  0.0741],\n",
      "        [-0.6315,  0.3727, -0.1694],\n",
      "        [ 0.0896,  0.1840,  0.0234]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.2.bias Parameter containing:\n",
      "tensor([ 0.5925,  0.1586, -0.0851], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.4.weight Parameter containing:\n",
      "tensor([[ 0.0766, -0.7811, -0.4454],\n",
      "        [ 0.8180, -0.1957, -0.2507],\n",
      "        [-0.8206,  0.4505, -0.5099]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.4.bias Parameter containing:\n",
      "tensor([ 0.6587,  0.4267, -0.5659], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.6.weight Parameter containing:\n",
      "tensor([[ 0.8371, -0.2226, -0.5204],\n",
      "        [ 0.5579,  0.4771, -0.8823],\n",
      "        [-0.0145, -1.1311,  0.2278]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.6.bias Parameter containing:\n",
      "tensor([ 0.6598,  0.7973, -0.9034], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.8.weight Parameter containing:\n",
      "tensor([[ 0.9245,  0.4769, -0.6400],\n",
      "        [-0.7991, -0.4425,  0.3371],\n",
      "        [-0.2297, -0.4443,  0.5446]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.8.bias Parameter containing:\n",
      "tensor([ 0.0836, -0.5392, -0.6505], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.10.weight Parameter containing:\n",
      "tensor([[ 1.0629, -0.8420, -1.0360]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.25.10.bias Parameter containing:\n",
      "tensor([0.3978], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.0.weight Parameter containing:\n",
      "tensor([[-0.4164,  0.1064, -0.1162],\n",
      "        [ 0.3978,  0.3821,  0.3588],\n",
      "        [ 0.5620,  0.5632,  0.2993]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.0.bias Parameter containing:\n",
      "tensor([ 0.5689,  0.3278, -0.5629], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.2.weight Parameter containing:\n",
      "tensor([[-0.3081,  0.0146, -0.2460],\n",
      "        [-0.3659,  0.6583,  0.4340],\n",
      "        [-0.5540, -0.0290, -0.4357]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.2.bias Parameter containing:\n",
      "tensor([-0.4701,  0.3425, -0.0316], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.4.weight Parameter containing:\n",
      "tensor([[-0.6594,  0.7788, -0.8835],\n",
      "        [ 0.6083, -0.5188,  0.7283],\n",
      "        [-0.1875,  0.6445, -0.2402]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.4.bias Parameter containing:\n",
      "tensor([ 0.1794, -0.5035,  0.5154], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.6.weight Parameter containing:\n",
      "tensor([[ 0.3423, -0.7654,  0.7643],\n",
      "        [-0.5520,  0.8676, -0.0681],\n",
      "        [-0.5458,  0.9135, -0.5579]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.6.bias Parameter containing:\n",
      "tensor([-0.0039, -0.3048, -0.6760], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.8.weight Parameter containing:\n",
      "tensor([[ 0.8857, -0.5455, -0.8826],\n",
      "        [-0.7697,  0.8162,  0.0240],\n",
      "        [-0.5357,  1.0202,  0.2392]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.8.bias Parameter containing:\n",
      "tensor([-0.2097, -0.4036, -0.4571], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.10.weight Parameter containing:\n",
      "tensor([[ 0.9880, -1.1679, -0.5328]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.26.10.bias Parameter containing:\n",
      "tensor([0.7554], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.0.weight Parameter containing:\n",
      "tensor([[-0.2121,  0.0689,  0.4930],\n",
      "        [-0.1704, -0.4535,  0.0069],\n",
      "        [-0.0286, -0.0750, -0.0277]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.0.bias Parameter containing:\n",
      "tensor([ 0.1994, -0.2940,  0.4805], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.2.weight Parameter containing:\n",
      "tensor([[-0.3266,  0.0474,  0.4283],\n",
      "        [ 0.0547,  0.8648,  0.0238],\n",
      "        [ 0.0264,  0.8070,  0.6754]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.2.bias Parameter containing:\n",
      "tensor([ 0.2391, -0.8513, -0.6357], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.4.weight Parameter containing:\n",
      "tensor([[-0.4825, -0.4524,  0.2498],\n",
      "        [ 0.4615,  0.2812,  0.7126],\n",
      "        [-0.0284,  0.5848,  0.6459]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.4.bias Parameter containing:\n",
      "tensor([ 0.6410, -0.2488,  0.0508], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.6.weight Parameter containing:\n",
      "tensor([[ 0.5871, -0.7284, -0.8807],\n",
      "        [-0.1552,  0.9050,  0.0544],\n",
      "        [ 0.8411, -0.0257, -1.0042]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.6.bias Parameter containing:\n",
      "tensor([-0.0474, -0.7296,  0.8985], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.8.weight Parameter containing:\n",
      "tensor([[-0.7116,  0.8226, -0.1992],\n",
      "        [ 0.4973, -0.2247,  0.5229],\n",
      "        [-0.5460, -0.0723, -0.8798]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.8.bias Parameter containing:\n",
      "tensor([-0.3523,  0.9440, -0.6448], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.10.weight Parameter containing:\n",
      "tensor([[-1.2129,  0.7064, -0.9423]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.27.10.bias Parameter containing:\n",
      "tensor([0.4311], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.0.weight Parameter containing:\n",
      "tensor([[-0.0328,  0.1684,  0.0502],\n",
      "        [-0.4073,  0.4466, -0.0169],\n",
      "        [-0.1580,  0.3848,  0.5586]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.0.bias Parameter containing:\n",
      "tensor([-0.4205,  0.1627, -0.1992], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.2.weight Parameter containing:\n",
      "tensor([[-0.5393, -0.1869, -0.2444],\n",
      "        [-0.2816,  0.7134,  0.4400],\n",
      "        [ 0.4499, -0.1060,  0.5843]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.2.bias Parameter containing:\n",
      "tensor([-0.0680,  0.3697,  0.1177], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.4.weight Parameter containing:\n",
      "tensor([[-0.1506,  0.5223, -0.1867],\n",
      "        [-0.7349,  0.1713,  0.5990],\n",
      "        [-0.6939,  0.5837,  0.7770]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.4.bias Parameter containing:\n",
      "tensor([0.4424, 0.8209, 0.1186], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.6.weight Parameter containing:\n",
      "tensor([[-0.2613, -0.9193, -0.9425],\n",
      "        [ 0.1601,  0.7732,  0.9362],\n",
      "        [ 0.1820, -0.0626,  0.4121]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.6.bias Parameter containing:\n",
      "tensor([-0.7194,  0.7284, -0.0655], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.8.weight Parameter containing:\n",
      "tensor([[-0.6041,  1.0579, -0.5675],\n",
      "        [-0.6168,  0.6743,  0.1943],\n",
      "        [ 0.5901, -1.0108, -0.3392]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.8.bias Parameter containing:\n",
      "tensor([ 0.6330,  0.1099, -0.6360], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.10.weight Parameter containing:\n",
      "tensor([[ 0.8024,  0.9008, -0.7988]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.28.10.bias Parameter containing:\n",
      "tensor([0.4786], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.0.weight Parameter containing:\n",
      "tensor([[-0.3236, -0.2715, -0.5250],\n",
      "        [-0.2253,  0.1217, -0.2969],\n",
      "        [-0.0544,  0.2801,  0.2857]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.0.bias Parameter containing:\n",
      "tensor([-0.3953, -0.5113,  0.4216], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.2.weight Parameter containing:\n",
      "tensor([[-0.1341,  0.4394,  0.2720],\n",
      "        [-0.6446,  0.5007,  0.6620],\n",
      "        [ 0.5014, -0.1270, -0.8067]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.2.bias Parameter containing:\n",
      "tensor([ 0.1722,  0.6426, -0.0271], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.4.weight Parameter containing:\n",
      "tensor([[-0.5385, -0.6912,  0.6369],\n",
      "        [ 1.0166,  0.1077, -0.8273],\n",
      "        [ 0.1166,  0.0550, -0.3638]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.4.bias Parameter containing:\n",
      "tensor([-0.6715, -0.2426,  0.5274], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.6.weight Parameter containing:\n",
      "tensor([[-0.7600,  0.4755,  0.1546],\n",
      "        [-0.3662,  0.4121,  0.0092],\n",
      "        [ 0.8851, -0.5088, -0.1290]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.6.bias Parameter containing:\n",
      "tensor([ 0.2063, -0.3841, -0.3382], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.8.weight Parameter containing:\n",
      "tensor([[ 1.1182,  0.3473, -0.4206],\n",
      "        [-0.8028, -0.1747,  0.4053],\n",
      "        [ 0.6001, -0.3088, -1.4002]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.8.bias Parameter containing:\n",
      "tensor([ 0.4849, -0.8842,  0.3458], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.10.weight Parameter containing:\n",
      "tensor([[ 1.1638, -1.0645,  1.0436]], device='cuda:0', requires_grad=True)\n",
      "rho_l1.29.10.bias Parameter containing:\n",
      "tensor([-0.0258], device='cuda:0', requires_grad=True)\n",
      "lambda_f.0.0.weight Parameter containing:\n",
      "tensor([[ 0.6398, -0.6772],\n",
      "        [-0.7996, -0.6702],\n",
      "        [ 0.6736, -0.6948]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.0.0.bias Parameter containing:\n",
      "tensor([-0.0380,  0.1442, -0.0614], device='cuda:0', requires_grad=True)\n",
      "lambda_f.0.2.weight Parameter containing:\n",
      "tensor([[ 0.7816, -0.2624,  0.1832],\n",
      "        [-0.3106, -0.0637, -0.5670],\n",
      "        [-0.6574,  0.6827, -0.8451]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.0.2.bias Parameter containing:\n",
      "tensor([ 0.4442, -0.6815, -0.1629], device='cuda:0', requires_grad=True)\n",
      "lambda_f.0.4.weight Parameter containing:\n",
      "tensor([[ 0.2724, -0.5685, -0.6360],\n",
      "        [ 0.5275, -0.2060, -1.0934],\n",
      "        [ 0.9539, -0.8604, -0.8996]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.0.4.bias Parameter containing:\n",
      "tensor([ 0.7805,  0.6341, -0.2559], device='cuda:0', requires_grad=True)\n",
      "lambda_f.0.6.weight Parameter containing:\n",
      "tensor([[0.6821, 0.7242, 0.9472]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.0.6.bias Parameter containing:\n",
      "tensor([-0.0468], device='cuda:0', requires_grad=True)\n",
      "lambda_f.1.0.weight Parameter containing:\n",
      "tensor([[ 0.6494,  0.5399],\n",
      "        [-0.1382,  0.5240],\n",
      "        [ 0.4179,  0.4595]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.1.0.bias Parameter containing:\n",
      "tensor([-0.2990, -0.0899,  0.6007], device='cuda:0', requires_grad=True)\n",
      "lambda_f.1.2.weight Parameter containing:\n",
      "tensor([[-0.3404,  0.4467,  0.0940],\n",
      "        [-0.3175,  0.1888,  0.2485],\n",
      "        [-0.5711,  0.5785, -0.5979]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.1.2.bias Parameter containing:\n",
      "tensor([-0.5111, -0.7681,  0.2918], device='cuda:0', requires_grad=True)\n",
      "lambda_f.1.4.weight Parameter containing:\n",
      "tensor([[ 0.2440,  1.0939,  0.3507],\n",
      "        [ 0.7148,  0.3588,  0.8358],\n",
      "        [-0.8106, -0.8110, -0.4462]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.1.4.bias Parameter containing:\n",
      "tensor([-0.4333, -0.8336,  0.2307], device='cuda:0', requires_grad=True)\n",
      "lambda_f.1.6.weight Parameter containing:\n",
      "tensor([[-1.2002, -0.5108,  1.1173]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.1.6.bias Parameter containing:\n",
      "tensor([0.3224], device='cuda:0', requires_grad=True)\n",
      "lambda_f.2.0.weight Parameter containing:\n",
      "tensor([[-0.5053, -0.3719],\n",
      "        [ 0.0852, -0.5862],\n",
      "        [-0.1134,  0.6092]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.2.0.bias Parameter containing:\n",
      "tensor([-0.3912, -0.3845, -0.0901], device='cuda:0', requires_grad=True)\n",
      "lambda_f.2.2.weight Parameter containing:\n",
      "tensor([[-0.7749,  0.4851,  0.0112],\n",
      "        [ 0.7599,  0.0390,  0.9143],\n",
      "        [ 0.4835, -0.5865,  0.4300]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.2.2.bias Parameter containing:\n",
      "tensor([ 0.2230, -0.4628, -0.6633], device='cuda:0', requires_grad=True)\n",
      "lambda_f.2.4.weight Parameter containing:\n",
      "tensor([[ 0.2191, -0.6898, -0.7188],\n",
      "        [ 0.2726, -0.6842, -0.5823],\n",
      "        [ 0.7651,  0.0801, -0.7647]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.2.4.bias Parameter containing:\n",
      "tensor([0.4858, 0.6840, 0.7167], device='cuda:0', requires_grad=True)\n",
      "lambda_f.2.6.weight Parameter containing:\n",
      "tensor([[0.9408, 0.7748, 0.8919]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.2.6.bias Parameter containing:\n",
      "tensor([0.1027], device='cuda:0', requires_grad=True)\n",
      "lambda_f.3.0.weight Parameter containing:\n",
      "tensor([[-0.6382, -0.6456],\n",
      "        [ 0.3589,  0.4745],\n",
      "        [ 0.5417, -0.2784]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.3.0.bias Parameter containing:\n",
      "tensor([-0.5811,  0.5200, -0.1278], device='cuda:0', requires_grad=True)\n",
      "lambda_f.3.2.weight Parameter containing:\n",
      "tensor([[-0.8803,  0.0849,  0.4441],\n",
      "        [ 0.4986, -0.3139, -0.4085],\n",
      "        [-0.1125,  0.7108,  0.5460]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.3.2.bias Parameter containing:\n",
      "tensor([-0.2405,  0.0201,  0.6640], device='cuda:0', requires_grad=True)\n",
      "lambda_f.3.4.weight Parameter containing:\n",
      "tensor([[-0.8835, -0.2366, -0.7973],\n",
      "        [-0.9784,  0.5746, -0.7850],\n",
      "        [-1.1243,  0.7042, -0.3976]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.3.4.bias Parameter containing:\n",
      "tensor([-0.8197, -0.1945,  0.1043], device='cuda:0', requires_grad=True)\n",
      "lambda_f.3.6.weight Parameter containing:\n",
      "tensor([[-0.9978, -1.0465, -0.7837]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.3.6.bias Parameter containing:\n",
      "tensor([-0.1031], device='cuda:0', requires_grad=True)\n",
      "lambda_f.4.0.weight Parameter containing:\n",
      "tensor([[ 0.4151,  0.6602],\n",
      "        [ 0.3650, -0.4087],\n",
      "        [ 0.5972, -0.5032]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.4.0.bias Parameter containing:\n",
      "tensor([-0.6727,  0.4905,  0.0764], device='cuda:0', requires_grad=True)\n",
      "lambda_f.4.2.weight Parameter containing:\n",
      "tensor([[-0.3842, -0.3368, -0.1141],\n",
      "        [-0.1184, -0.5410, -0.7586],\n",
      "        [-0.6516, -0.0683, -0.2024]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.4.2.bias Parameter containing:\n",
      "tensor([-0.6135, -0.2661, -0.3893], device='cuda:0', requires_grad=True)\n",
      "lambda_f.4.4.weight Parameter containing:\n",
      "tensor([[0.1167, 0.5186, 0.5028],\n",
      "        [0.5143, 1.0398, 0.7826],\n",
      "        [0.8188, 0.3949, 0.5929]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.4.4.bias Parameter containing:\n",
      "tensor([-0.8284, -0.0699, -0.2918], device='cuda:0', requires_grad=True)\n",
      "lambda_f.4.6.weight Parameter containing:\n",
      "tensor([[-0.9298, -1.0745, -0.9324]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.4.6.bias Parameter containing:\n",
      "tensor([0.2966], device='cuda:0', requires_grad=True)\n",
      "lambda_f.5.0.weight Parameter containing:\n",
      "tensor([[ 0.6115, -0.0668],\n",
      "        [-0.5027, -0.6650],\n",
      "        [-0.6985, -0.7043]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.5.0.bias Parameter containing:\n",
      "tensor([-0.3242,  0.0474,  0.0886], device='cuda:0', requires_grad=True)\n",
      "lambda_f.5.2.weight Parameter containing:\n",
      "tensor([[ 0.3151,  0.0443,  0.1949],\n",
      "        [-0.7149,  0.5304,  0.5044],\n",
      "        [-0.2420,  0.7504,  0.3393]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.5.2.bias Parameter containing:\n",
      "tensor([ 0.4283, -0.5447, -0.4963], device='cuda:0', requires_grad=True)\n",
      "lambda_f.5.4.weight Parameter containing:\n",
      "tensor([[-0.3321,  0.1023,  0.8306],\n",
      "        [-0.2286,  0.4909,  0.6631],\n",
      "        [ 0.5931,  0.9946,  0.6107]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.5.4.bias Parameter containing:\n",
      "tensor([-0.9053, -0.3259, -0.8664], device='cuda:0', requires_grad=True)\n",
      "lambda_f.5.6.weight Parameter containing:\n",
      "tensor([[-0.7664, -1.4517, -0.5617]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.5.6.bias Parameter containing:\n",
      "tensor([0.7741], device='cuda:0', requires_grad=True)\n",
      "lambda_f.6.0.weight Parameter containing:\n",
      "tensor([[-0.3978,  0.7054],\n",
      "        [-0.2129, -0.0785],\n",
      "        [ 0.4886,  0.3736]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.6.0.bias Parameter containing:\n",
      "tensor([-0.5992,  0.1111, -0.4633], device='cuda:0', requires_grad=True)\n",
      "lambda_f.6.2.weight Parameter containing:\n",
      "tensor([[-0.7569, -0.7478, -0.1225],\n",
      "        [-0.5391, -0.7153,  0.4270],\n",
      "        [ 0.2099,  0.3772, -0.3545]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.6.2.bias Parameter containing:\n",
      "tensor([ 0.6883,  0.7163, -0.5537], device='cuda:0', requires_grad=True)\n",
      "lambda_f.6.4.weight Parameter containing:\n",
      "tensor([[-0.1079, -0.4534,  0.7991],\n",
      "        [ 0.6772,  0.8397, -0.7260],\n",
      "        [-0.7144, -0.7595,  0.1673]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.6.4.bias Parameter containing:\n",
      "tensor([-0.6870,  0.0707, -0.8174], device='cuda:0', requires_grad=True)\n",
      "lambda_f.6.6.weight Parameter containing:\n",
      "tensor([[-1.0689,  0.9995, -0.6859]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.6.6.bias Parameter containing:\n",
      "tensor([0.5734], device='cuda:0', requires_grad=True)\n",
      "lambda_f.7.0.weight Parameter containing:\n",
      "tensor([[-0.3155,  0.6583],\n",
      "        [ 0.0549,  0.5838],\n",
      "        [-0.6035, -0.5349]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.7.0.bias Parameter containing:\n",
      "tensor([ 0.4559,  0.3276, -0.0919], device='cuda:0', requires_grad=True)\n",
      "lambda_f.7.2.weight Parameter containing:\n",
      "tensor([[ 0.2081, -0.5923,  0.7569],\n",
      "        [ 0.0872,  0.6714, -0.1096],\n",
      "        [-0.1470,  0.6073, -0.5029]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.7.2.bias Parameter containing:\n",
      "tensor([-0.5306,  0.9795,  0.6940], device='cuda:0', requires_grad=True)\n",
      "lambda_f.7.4.weight Parameter containing:\n",
      "tensor([[ 0.0309, -1.1484, -0.4338],\n",
      "        [-0.7737,  0.9439,  0.0752],\n",
      "        [ 0.4081, -0.1527, -0.6983]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.7.4.bias Parameter containing:\n",
      "tensor([-0.4605,  0.7386, -0.8563], device='cuda:0', requires_grad=True)\n",
      "lambda_f.7.6.weight Parameter containing:\n",
      "tensor([[-0.8050,  0.8142, -1.0904]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.7.6.bias Parameter containing:\n",
      "tensor([0.2866], device='cuda:0', requires_grad=True)\n",
      "lambda_f.8.0.weight Parameter containing:\n",
      "tensor([[-0.0613, -0.5976],\n",
      "        [ 0.1981,  0.3316],\n",
      "        [ 0.6422,  0.5471]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.8.0.bias Parameter containing:\n",
      "tensor([-0.6333,  0.4627,  0.2186], device='cuda:0', requires_grad=True)\n",
      "lambda_f.8.2.weight Parameter containing:\n",
      "tensor([[ 0.5154,  0.2601,  0.0568],\n",
      "        [-0.6593,  0.0769,  0.2425],\n",
      "        [-0.3044,  0.6976,  0.6710]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.8.2.bias Parameter containing:\n",
      "tensor([-0.6750,  0.3835, -0.1046], device='cuda:0', requires_grad=True)\n",
      "lambda_f.8.4.weight Parameter containing:\n",
      "tensor([[-0.2097,  1.1863,  0.5849],\n",
      "        [ 0.2793,  1.0039,  0.1566],\n",
      "        [-0.3663,  0.0016,  1.0328]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.8.4.bias Parameter containing:\n",
      "tensor([0.4746, 1.0271, 0.5060], device='cuda:0', requires_grad=True)\n",
      "lambda_f.8.6.weight Parameter containing:\n",
      "tensor([[0.9668, 0.5464, 1.2785]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.8.6.bias Parameter containing:\n",
      "tensor([0.4989], device='cuda:0', requires_grad=True)\n",
      "lambda_f.9.0.weight Parameter containing:\n",
      "tensor([[ 0.3055,  0.4474],\n",
      "        [ 0.0770,  0.0466],\n",
      "        [-0.3741,  0.5171]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.9.0.bias Parameter containing:\n",
      "tensor([-0.2544, -0.0923,  0.4461], device='cuda:0', requires_grad=True)\n",
      "lambda_f.9.2.weight Parameter containing:\n",
      "tensor([[ 0.7389,  0.7596, -0.6328],\n",
      "        [ 0.4453,  0.7199, -0.1585],\n",
      "        [ 0.8297,  0.4274, -0.3721]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.9.2.bias Parameter containing:\n",
      "tensor([ 0.6537,  0.2121, -0.0272], device='cuda:0', requires_grad=True)\n",
      "lambda_f.9.4.weight Parameter containing:\n",
      "tensor([[ 0.1952,  0.9248,  0.5317],\n",
      "        [ 0.0764, -0.5155, -0.4704],\n",
      "        [-0.8450, -0.6909, -0.6993]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.9.4.bias Parameter containing:\n",
      "tensor([ 0.4548, -0.0651,  0.1092], device='cuda:0', requires_grad=True)\n",
      "lambda_f.9.6.weight Parameter containing:\n",
      "tensor([[ 1.0906, -0.2712, -0.9835]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.9.6.bias Parameter containing:\n",
      "tensor([0.9521], device='cuda:0', requires_grad=True)\n",
      "lambda_f.10.0.weight Parameter containing:\n",
      "tensor([[ 0.1840, -0.4781],\n",
      "        [ 0.0558,  0.4216],\n",
      "        [ 0.1038,  0.3124]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.10.0.bias Parameter containing:\n",
      "tensor([ 0.1387, -0.0663,  0.6325], device='cuda:0', requires_grad=True)\n",
      "lambda_f.10.2.weight Parameter containing:\n",
      "tensor([[ 0.1894,  0.9058,  0.0556],\n",
      "        [-0.4503,  0.2434, -0.6317],\n",
      "        [ 0.2475,  0.4667,  0.7746]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.10.2.bias Parameter containing:\n",
      "tensor([ 0.1343, -0.7386,  0.7420], device='cuda:0', requires_grad=True)\n",
      "lambda_f.10.4.weight Parameter containing:\n",
      "tensor([[-0.5390,  0.6291, -0.8944],\n",
      "        [-0.5350,  0.6947, -0.6176],\n",
      "        [ 0.2230,  0.8315, -0.8625]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.10.4.bias Parameter containing:\n",
      "tensor([-0.0584, -0.7210, -0.5202], device='cuda:0', requires_grad=True)\n",
      "lambda_f.10.6.weight Parameter containing:\n",
      "tensor([[-1.1151, -0.5880, -0.7742]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.10.6.bias Parameter containing:\n",
      "tensor([-0.0644], device='cuda:0', requires_grad=True)\n",
      "lambda_f.11.0.weight Parameter containing:\n",
      "tensor([[ 0.1218,  0.7301],\n",
      "        [-0.0770,  0.1536],\n",
      "        [-0.4560,  0.5431]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_f.11.0.bias Parameter containing:\n",
      "tensor([ 0.6491,  0.1822, -0.3722], device='cuda:0', requires_grad=True)\n",
      "lambda_f.11.2.weight Parameter containing:\n",
      "tensor([[-0.5295,  0.1016,  0.3032],\n",
      "        [ 0.7362,  0.1217, -0.3631],\n",
      "        [ 0.5597, -0.4071,  0.0568]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.11.2.bias Parameter containing:\n",
      "tensor([-0.1045,  0.7395,  0.5436], device='cuda:0', requires_grad=True)\n",
      "lambda_f.11.4.weight Parameter containing:\n",
      "tensor([[ 0.5311, -0.4522, -0.8291],\n",
      "        [-0.1880,  0.1932,  1.1731],\n",
      "        [ 0.9164, -0.7261, -1.1046]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.11.4.bias Parameter containing:\n",
      "tensor([-0.5314,  0.9102, -0.6607], device='cuda:0', requires_grad=True)\n",
      "lambda_f.11.6.weight Parameter containing:\n",
      "tensor([[-1.1122,  1.0045, -0.5499]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.11.6.bias Parameter containing:\n",
      "tensor([0.0163], device='cuda:0', requires_grad=True)\n",
      "lambda_f.12.0.weight Parameter containing:\n",
      "tensor([[ 0.6884,  0.2322],\n",
      "        [ 0.2532, -0.6375],\n",
      "        [ 0.3005, -0.5365]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.12.0.bias Parameter containing:\n",
      "tensor([-0.6514, -0.5174,  0.1644], device='cuda:0', requires_grad=True)\n",
      "lambda_f.12.2.weight Parameter containing:\n",
      "tensor([[ 0.8640,  0.3539,  0.5328],\n",
      "        [-0.1932, -0.4921,  0.2989],\n",
      "        [-0.6991,  0.1080, -0.6737]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.12.2.bias Parameter containing:\n",
      "tensor([ 0.1123,  0.1703, -0.7697], device='cuda:0', requires_grad=True)\n",
      "lambda_f.12.4.weight Parameter containing:\n",
      "tensor([[-0.5996,  0.2058,  0.5673],\n",
      "        [ 0.6209, -0.2643, -0.6989],\n",
      "        [-1.0614, -0.2527,  0.1825]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.12.4.bias Parameter containing:\n",
      "tensor([-0.8341,  0.6212, -1.0480], device='cuda:0', requires_grad=True)\n",
      "lambda_f.12.6.weight Parameter containing:\n",
      "tensor([[-0.9003,  1.1507, -0.8253]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.12.6.bias Parameter containing:\n",
      "tensor([0.9533], device='cuda:0', requires_grad=True)\n",
      "lambda_f.13.0.weight Parameter containing:\n",
      "tensor([[-0.2215, -0.3512],\n",
      "        [ 0.4668, -0.3478],\n",
      "        [-0.5606, -0.1189]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.13.0.bias Parameter containing:\n",
      "tensor([ 0.1268,  0.5973, -0.2598], device='cuda:0', requires_grad=True)\n",
      "lambda_f.13.2.weight Parameter containing:\n",
      "tensor([[ 0.9168, -0.6911, -0.1728],\n",
      "        [ 0.6481, -0.3713,  0.0793],\n",
      "        [-0.0340, -0.3886,  0.0657]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.13.2.bias Parameter containing:\n",
      "tensor([-0.7724, -0.2186,  0.1876], device='cuda:0', requires_grad=True)\n",
      "lambda_f.13.4.weight Parameter containing:\n",
      "tensor([[-0.4775, -0.5487,  0.3535],\n",
      "        [-0.5488, -0.3387, -0.1368],\n",
      "        [-0.9313, -0.8548, -0.3406]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.13.4.bias Parameter containing:\n",
      "tensor([ 0.8906,  0.0119, -0.0711], device='cuda:0', requires_grad=True)\n",
      "lambda_f.13.6.weight Parameter containing:\n",
      "tensor([[0.8524, 0.4117, 0.7303]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.13.6.bias Parameter containing:\n",
      "tensor([0.7553], device='cuda:0', requires_grad=True)\n",
      "lambda_f.14.0.weight Parameter containing:\n",
      "tensor([[-0.3342, -0.5612],\n",
      "        [-0.4164, -0.1525],\n",
      "        [-0.0755, -0.2148]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.14.0.bias Parameter containing:\n",
      "tensor([-0.3022,  0.0931,  0.0743], device='cuda:0', requires_grad=True)\n",
      "lambda_f.14.2.weight Parameter containing:\n",
      "tensor([[ 0.8256,  0.3720,  0.9613],\n",
      "        [ 0.2957,  0.4925,  0.5516],\n",
      "        [-0.3822, -0.0256, -0.5485]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.14.2.bias Parameter containing:\n",
      "tensor([-0.2105, -0.4699,  0.7087], device='cuda:0', requires_grad=True)\n",
      "lambda_f.14.4.weight Parameter containing:\n",
      "tensor([[ 0.6680,  0.6938, -0.5213],\n",
      "        [-0.8383, -0.5842,  0.5971],\n",
      "        [ 0.6890,  0.8420, -0.0598]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.14.4.bias Parameter containing:\n",
      "tensor([-0.6572,  0.6528, -0.5871], device='cuda:0', requires_grad=True)\n",
      "lambda_f.14.6.weight Parameter containing:\n",
      "tensor([[-0.9624,  0.6786, -0.4732]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.14.6.bias Parameter containing:\n",
      "tensor([-0.0033], device='cuda:0', requires_grad=True)\n",
      "lambda_f.15.0.weight Parameter containing:\n",
      "tensor([[ 0.3827,  0.0010],\n",
      "        [-0.1193,  0.2339],\n",
      "        [ 0.0841, -0.4247]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.15.0.bias Parameter containing:\n",
      "tensor([-0.6972, -0.3740, -0.1994], device='cuda:0', requires_grad=True)\n",
      "lambda_f.15.2.weight Parameter containing:\n",
      "tensor([[ 0.8355, -0.4744,  0.6311],\n",
      "        [-0.3945,  0.7348, -0.4076],\n",
      "        [ 0.3236, -0.6319,  0.1672]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.15.2.bias Parameter containing:\n",
      "tensor([ 0.0488, -0.6107,  0.6113], device='cuda:0', requires_grad=True)\n",
      "lambda_f.15.4.weight Parameter containing:\n",
      "tensor([[ 0.7055, -0.4889,  0.4515],\n",
      "        [-0.5850,  0.6817, -0.5227],\n",
      "        [-0.7117,  0.8499, -0.0946]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.15.4.bias Parameter containing:\n",
      "tensor([ 0.9174, -0.0048, -0.6876], device='cuda:0', requires_grad=True)\n",
      "lambda_f.15.6.weight Parameter containing:\n",
      "tensor([[ 0.5832, -1.0846, -0.5511]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.15.6.bias Parameter containing:\n",
      "tensor([0.3908], device='cuda:0', requires_grad=True)\n",
      "lambda_f.16.0.weight Parameter containing:\n",
      "tensor([[-0.4268,  0.1752],\n",
      "        [-0.0484,  0.1036],\n",
      "        [-0.6803,  0.1307]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.16.0.bias Parameter containing:\n",
      "tensor([ 0.3130, -0.5691, -0.6119], device='cuda:0', requires_grad=True)\n",
      "lambda_f.16.2.weight Parameter containing:\n",
      "tensor([[-0.5879, -0.2946, -0.7414],\n",
      "        [ 0.5315,  0.3767,  0.2839],\n",
      "        [-0.6064, -0.6686, -0.7020]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.16.2.bias Parameter containing:\n",
      "tensor([-0.0241, -0.4114, -0.1509], device='cuda:0', requires_grad=True)\n",
      "lambda_f.16.4.weight Parameter containing:\n",
      "tensor([[ 1.0808, -0.6236,  0.5576],\n",
      "        [-0.6453,  0.7596, -0.3929],\n",
      "        [ 1.0527, -0.4845,  0.4853]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.16.4.bias Parameter containing:\n",
      "tensor([ 0.8108, -0.3729,  0.4417], device='cuda:0', requires_grad=True)\n",
      "lambda_f.16.6.weight Parameter containing:\n",
      "tensor([[ 0.6038, -1.1464,  0.7169]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.16.6.bias Parameter containing:\n",
      "tensor([0.8190], device='cuda:0', requires_grad=True)\n",
      "lambda_f.17.0.weight Parameter containing:\n",
      "tensor([[ 0.1620,  0.4736],\n",
      "        [ 0.0432,  0.4939],\n",
      "        [-0.3729, -0.5481]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.17.0.bias Parameter containing:\n",
      "tensor([-0.1272,  0.3166, -0.1063], device='cuda:0', requires_grad=True)\n",
      "lambda_f.17.2.weight Parameter containing:\n",
      "tensor([[ 0.2646,  0.4527, -0.1564],\n",
      "        [-0.6021, -0.2280,  0.6687],\n",
      "        [ 0.1115, -0.3668, -0.3014]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.17.2.bias Parameter containing:\n",
      "tensor([ 0.7320, -0.7499,  0.3161], device='cuda:0', requires_grad=True)\n",
      "lambda_f.17.4.weight Parameter containing:\n",
      "tensor([[ 0.7371, -0.5842,  0.1789],\n",
      "        [-0.8277,  0.5699,  0.3960],\n",
      "        [-0.9283,  0.7516, -0.3152]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.17.4.bias Parameter containing:\n",
      "tensor([ 0.3456, -0.6006, -0.2619], device='cuda:0', requires_grad=True)\n",
      "lambda_f.17.6.weight Parameter containing:\n",
      "tensor([[ 1.0398, -0.9550, -0.8392]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.17.6.bias Parameter containing:\n",
      "tensor([-0.1772], device='cuda:0', requires_grad=True)\n",
      "lambda_f.18.0.weight Parameter containing:\n",
      "tensor([[ 0.5547, -0.2735],\n",
      "        [ 0.0662,  0.6388],\n",
      "        [ 0.4243,  0.5580]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.18.0.bias Parameter containing:\n",
      "tensor([ 0.1391,  0.2371, -0.6324], device='cuda:0', requires_grad=True)\n",
      "lambda_f.18.2.weight Parameter containing:\n",
      "tensor([[ 0.4209,  0.2290, -0.1918],\n",
      "        [ 0.0174,  0.3498,  0.3485],\n",
      "        [ 0.3422,  0.3724,  0.9245]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.18.2.bias Parameter containing:\n",
      "tensor([-0.0238,  0.0906, -0.1035], device='cuda:0', requires_grad=True)\n",
      "lambda_f.18.4.weight Parameter containing:\n",
      "tensor([[-0.3097, -0.0679, -1.1478],\n",
      "        [-0.2864, -0.4439, -1.1732],\n",
      "        [-0.4204,  0.2117,  1.4301]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.18.4.bias Parameter containing:\n",
      "tensor([-0.4635, -0.2305,  0.6479], device='cuda:0', requires_grad=True)\n",
      "lambda_f.18.6.weight Parameter containing:\n",
      "tensor([[-0.9845, -0.6664,  0.5044]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.18.6.bias Parameter containing:\n",
      "tensor([0.3991], device='cuda:0', requires_grad=True)\n",
      "lambda_f.19.0.weight Parameter containing:\n",
      "tensor([[ 0.6999, -0.1625],\n",
      "        [ 0.6448, -0.0582],\n",
      "        [ 0.2376, -0.5911]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.19.0.bias Parameter containing:\n",
      "tensor([-0.4092,  0.5737,  0.4908], device='cuda:0', requires_grad=True)\n",
      "lambda_f.19.2.weight Parameter containing:\n",
      "tensor([[ 0.4775, -0.4095, -0.0526],\n",
      "        [ 0.7002,  0.1326,  0.4585],\n",
      "        [ 0.2854,  0.3838,  0.5118]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.19.2.bias Parameter containing:\n",
      "tensor([-0.4367, -0.0481, -0.0118], device='cuda:0', requires_grad=True)\n",
      "lambda_f.19.4.weight Parameter containing:\n",
      "tensor([[-0.5493,  1.1672,  0.2616],\n",
      "        [ 0.5658, -1.1378, -0.7517],\n",
      "        [ 0.2624,  1.2400, -0.1953]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.19.4.bias Parameter containing:\n",
      "tensor([ 0.5502, -0.0372,  0.6943], device='cuda:0', requires_grad=True)\n",
      "lambda_f.19.6.weight Parameter containing:\n",
      "tensor([[ 0.7145, -1.2404,  1.0684]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.19.6.bias Parameter containing:\n",
      "tensor([0.8000], device='cuda:0', requires_grad=True)\n",
      "lambda_f.20.0.weight Parameter containing:\n",
      "tensor([[ 0.1415,  0.6662],\n",
      "        [ 0.2908, -0.1768],\n",
      "        [-0.4448, -0.4445]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.20.0.bias Parameter containing:\n",
      "tensor([ 0.2775, -0.0735, -0.1989], device='cuda:0', requires_grad=True)\n",
      "lambda_f.20.2.weight Parameter containing:\n",
      "tensor([[ 0.6097,  0.3095, -0.8372],\n",
      "        [-0.0857, -0.5541,  0.3421],\n",
      "        [ 0.3947,  0.1968, -0.6514]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.20.2.bias Parameter containing:\n",
      "tensor([-0.0770, -0.8262,  0.3767], device='cuda:0', requires_grad=True)\n",
      "lambda_f.20.4.weight Parameter containing:\n",
      "tensor([[ 7.0559e-01, -5.4137e-01,  4.6870e-01],\n",
      "        [ 6.9020e-04,  4.8939e-01, -4.7147e-01],\n",
      "        [-3.1857e-01,  1.8780e-01, -8.7567e-01]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "lambda_f.20.4.bias Parameter containing:\n",
      "tensor([-0.0107, -0.5616, -0.3899], device='cuda:0', requires_grad=True)\n",
      "lambda_f.20.6.weight Parameter containing:\n",
      "tensor([[ 1.5392, -0.8117, -1.2399]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.20.6.bias Parameter containing:\n",
      "tensor([0.7425], device='cuda:0', requires_grad=True)\n",
      "lambda_f.21.0.weight Parameter containing:\n",
      "tensor([[ 0.4206,  0.5389],\n",
      "        [ 0.2456, -0.3355],\n",
      "        [ 0.6115,  0.3099]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.21.0.bias Parameter containing:\n",
      "tensor([ 0.4342, -0.0562, -0.0129], device='cuda:0', requires_grad=True)\n",
      "lambda_f.21.2.weight Parameter containing:\n",
      "tensor([[-0.4489, -0.3153, -0.5592],\n",
      "        [-0.0437,  0.0621,  0.7813],\n",
      "        [ 0.3234,  0.3253,  0.4387]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.21.2.bias Parameter containing:\n",
      "tensor([-0.2645,  0.3769,  0.6549], device='cuda:0', requires_grad=True)\n",
      "lambda_f.21.4.weight Parameter containing:\n",
      "tensor([[-0.9527,  0.7707,  0.6361],\n",
      "        [ 0.9705, -0.8766, -0.5182],\n",
      "        [-0.5322,  0.6403,  0.0551]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.21.4.bias Parameter containing:\n",
      "tensor([ 0.0124, -0.6215, -0.0590], device='cuda:0', requires_grad=True)\n",
      "lambda_f.21.6.weight Parameter containing:\n",
      "tensor([[ 1.3212, -0.7243,  0.5037]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.21.6.bias Parameter containing:\n",
      "tensor([0.9752], device='cuda:0', requires_grad=True)\n",
      "lambda_f.22.0.weight Parameter containing:\n",
      "tensor([[-0.0834, -0.4956],\n",
      "        [ 0.0227, -0.5301],\n",
      "        [ 0.1091,  0.2160]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.22.0.bias Parameter containing:\n",
      "tensor([ 0.4203, -0.5327, -0.6311], device='cuda:0', requires_grad=True)\n",
      "lambda_f.22.2.weight Parameter containing:\n",
      "tensor([[ 0.7451,  0.2679, -0.5085],\n",
      "        [ 0.6645, -0.0973, -0.5206],\n",
      "        [ 0.5415, -0.6924, -0.4650]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.22.2.bias Parameter containing:\n",
      "tensor([-0.3752, -0.1057, -0.6808], device='cuda:0', requires_grad=True)\n",
      "lambda_f.22.4.weight Parameter containing:\n",
      "tensor([[ 1.0943,  0.8156,  0.0825],\n",
      "        [-1.0442, -0.4299, -0.2300],\n",
      "        [-0.6816, -0.7159, -0.4614]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.22.4.bias Parameter containing:\n",
      "tensor([-0.4455,  0.8959,  0.6685], device='cuda:0', requires_grad=True)\n",
      "lambda_f.22.6.weight Parameter containing:\n",
      "tensor([[-1.0467,  0.7105,  1.0609]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.22.6.bias Parameter containing:\n",
      "tensor([1.0197], device='cuda:0', requires_grad=True)\n",
      "lambda_f.23.0.weight Parameter containing:\n",
      "tensor([[-0.2640, -0.0215],\n",
      "        [-0.6192,  0.5840],\n",
      "        [-0.3888,  0.1439]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.23.0.bias Parameter containing:\n",
      "tensor([-0.6969, -0.6463,  0.4873], device='cuda:0', requires_grad=True)\n",
      "lambda_f.23.2.weight Parameter containing:\n",
      "tensor([[ 0.2274, -0.5688, -0.6615],\n",
      "        [ 0.3918,  0.2095,  0.7577],\n",
      "        [ 0.7565, -0.1746,  0.5063]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.23.2.bias Parameter containing:\n",
      "tensor([ 0.3798,  0.2889, -0.5210], device='cuda:0', requires_grad=True)\n",
      "lambda_f.23.4.weight Parameter containing:\n",
      "tensor([[-1.0163,  0.2114,  0.7106],\n",
      "        [-0.7366,  0.7768,  0.7934],\n",
      "        [-0.6404,  0.9968,  0.5115]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.23.4.bias Parameter containing:\n",
      "tensor([-0.6196, -0.1401, -0.0294], device='cuda:0', requires_grad=True)\n",
      "lambda_f.23.6.weight Parameter containing:\n",
      "tensor([[-0.7103, -0.8900, -1.2872]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.23.6.bias Parameter containing:\n",
      "tensor([0.8591], device='cuda:0', requires_grad=True)\n",
      "lambda_f.24.0.weight Parameter containing:\n",
      "tensor([[-0.2999, -0.5856],\n",
      "        [-0.0645, -0.0569],\n",
      "        [ 0.1801,  0.3598]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.24.0.bias Parameter containing:\n",
      "tensor([-0.6243,  0.0262,  0.0393], device='cuda:0', requires_grad=True)\n",
      "lambda_f.24.2.weight Parameter containing:\n",
      "tensor([[ 0.3349,  0.0483, -0.1763],\n",
      "        [ 0.0961,  0.6081,  0.1718],\n",
      "        [-0.3241,  0.6349, -0.5435]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.24.2.bias Parameter containing:\n",
      "tensor([-0.6811, -0.7884, -0.5928], device='cuda:0', requires_grad=True)\n",
      "lambda_f.24.4.weight Parameter containing:\n",
      "tensor([[ 0.6412,  0.2011,  0.5538],\n",
      "        [ 0.2448, -0.6052, -0.9187],\n",
      "        [ 0.3222,  0.1570,  0.9142]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.24.4.bias Parameter containing:\n",
      "tensor([-0.5311,  0.6399, -0.8114], device='cuda:0', requires_grad=True)\n",
      "lambda_f.24.6.weight Parameter containing:\n",
      "tensor([[-0.9573,  1.0902, -0.7494]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.24.6.bias Parameter containing:\n",
      "tensor([0.9036], device='cuda:0', requires_grad=True)\n",
      "lambda_f.25.0.weight Parameter containing:\n",
      "tensor([[-0.3945, -0.0384],\n",
      "        [ 0.3389, -0.4955],\n",
      "        [ 0.0774, -0.2461]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.25.0.bias Parameter containing:\n",
      "tensor([ 0.0765, -0.3932,  0.2720], device='cuda:0', requires_grad=True)\n",
      "lambda_f.25.2.weight Parameter containing:\n",
      "tensor([[ 0.2334,  0.2339, -0.5451],\n",
      "        [ 0.6468, -0.2109, -0.0372],\n",
      "        [-0.6915,  0.8342,  0.2939]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.25.2.bias Parameter containing:\n",
      "tensor([-0.6222, -0.6495,  0.0311], device='cuda:0', requires_grad=True)\n",
      "lambda_f.25.4.weight Parameter containing:\n",
      "tensor([[-0.7428, -0.7882,  0.3241],\n",
      "        [-0.2340, -0.7636,  0.6895],\n",
      "        [ 0.5033,  0.6323, -0.5012]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.25.4.bias Parameter containing:\n",
      "tensor([-0.1845,  0.7681, -0.5418], device='cuda:0', requires_grad=True)\n",
      "lambda_f.25.6.weight Parameter containing:\n",
      "tensor([[ 0.9675,  0.9865, -0.8234]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.25.6.bias Parameter containing:\n",
      "tensor([0.2448], device='cuda:0', requires_grad=True)\n",
      "lambda_f.26.0.weight Parameter containing:\n",
      "tensor([[ 0.0423,  0.5635],\n",
      "        [-0.3943,  0.2679],\n",
      "        [-0.2924,  0.7034]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.26.0.bias Parameter containing:\n",
      "tensor([ 0.3252, -0.2873,  0.2043], device='cuda:0', requires_grad=True)\n",
      "lambda_f.26.2.weight Parameter containing:\n",
      "tensor([[-0.4283,  0.4065,  0.4391],\n",
      "        [-0.2078,  0.6265,  0.1963],\n",
      "        [-0.5912,  0.2155,  0.2373]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.26.2.bias Parameter containing:\n",
      "tensor([-0.6323, -0.5288, -0.4369], device='cuda:0', requires_grad=True)\n",
      "lambda_f.26.4.weight Parameter containing:\n",
      "tensor([[ 0.4521, -0.0574,  0.6547],\n",
      "        [-0.3690, -0.5684, -0.5291],\n",
      "        [ 0.6849,  0.4663,  0.8749]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.26.4.bias Parameter containing:\n",
      "tensor([-0.5612,  0.5099,  0.1703], device='cuda:0', requires_grad=True)\n",
      "lambda_f.26.6.weight Parameter containing:\n",
      "tensor([[-1.0698,  0.9467, -1.0660]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.26.6.bias Parameter containing:\n",
      "tensor([0.2428], device='cuda:0', requires_grad=True)\n",
      "lambda_f.27.0.weight Parameter containing:\n",
      "tensor([[ 0.6089, -0.6173],\n",
      "        [ 0.0791,  0.1778],\n",
      "        [-0.4394, -0.5230]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.27.0.bias Parameter containing:\n",
      "tensor([0.4211, 0.3280, 0.0636], device='cuda:0', requires_grad=True)\n",
      "lambda_f.27.2.weight Parameter containing:\n",
      "tensor([[-0.4453, -0.4875,  0.5395],\n",
      "        [-0.8493, -0.2470, -0.1546],\n",
      "        [-0.8497, -0.8572,  0.2743]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.27.2.bias Parameter containing:\n",
      "tensor([-0.0632,  0.0295, -0.3956], device='cuda:0', requires_grad=True)\n",
      "lambda_f.27.4.weight Parameter containing:\n",
      "tensor([[ 0.3224,  0.1624,  0.5325],\n",
      "        [-0.4675, -0.3077, -0.0104],\n",
      "        [ 0.2467,  0.4961,  0.8639]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.27.4.bias Parameter containing:\n",
      "tensor([-0.8287,  0.8508, -0.0344], device='cuda:0', requires_grad=True)\n",
      "lambda_f.27.6.weight Parameter containing:\n",
      "tensor([[-0.6988,  1.1685, -1.1459]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.27.6.bias Parameter containing:\n",
      "tensor([0.4837], device='cuda:0', requires_grad=True)\n",
      "lambda_f.28.0.weight Parameter containing:\n",
      "tensor([[-0.3288,  0.3612],\n",
      "        [ 0.2938, -0.5281],\n",
      "        [-0.3485, -0.5553]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.28.0.bias Parameter containing:\n",
      "tensor([0.6560, 0.3166, 0.1538], device='cuda:0', requires_grad=True)\n",
      "lambda_f.28.2.weight Parameter containing:\n",
      "tensor([[-0.7633,  0.2249, -0.0425],\n",
      "        [ 0.8784, -0.6538,  0.7371],\n",
      "        [-0.3825,  0.4665, -0.3246]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.28.2.bias Parameter containing:\n",
      "tensor([ 0.8570, -0.1983,  0.5429], device='cuda:0', requires_grad=True)\n",
      "lambda_f.28.4.weight Parameter containing:\n",
      "tensor([[-0.7242,  0.3189, -0.1052],\n",
      "        [ 0.6406, -0.3620,  0.3012],\n",
      "        [-0.5524,  0.4584, -0.5156]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.28.4.bias Parameter containing:\n",
      "tensor([-0.3312,  0.4620, -0.5171], device='cuda:0', requires_grad=True)\n",
      "lambda_f.28.6.weight Parameter containing:\n",
      "tensor([[-1.1544,  0.6260, -1.0906]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.28.6.bias Parameter containing:\n",
      "tensor([0.0222], device='cuda:0', requires_grad=True)\n",
      "lambda_f.29.0.weight Parameter containing:\n",
      "tensor([[ 0.2682,  0.4920],\n",
      "        [-0.5216,  0.1860],\n",
      "        [-0.4050,  0.6978]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.29.0.bias Parameter containing:\n",
      "tensor([-0.1452,  0.2836,  0.2721], device='cuda:0', requires_grad=True)\n",
      "lambda_f.29.2.weight Parameter containing:\n",
      "tensor([[-0.5112,  0.5616, -0.0335],\n",
      "        [ 0.0779, -0.2231, -0.3494],\n",
      "        [ 0.3409,  0.2163,  0.3512]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.29.2.bias Parameter containing:\n",
      "tensor([-0.4474,  0.5284,  0.3348], device='cuda:0', requires_grad=True)\n",
      "lambda_f.29.4.weight Parameter containing:\n",
      "tensor([[ 0.3203,  0.4741, -0.5684],\n",
      "        [-0.4782,  0.3938, -0.5335],\n",
      "        [-0.3796, -0.5318, -0.3128]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.29.4.bias Parameter containing:\n",
      "tensor([ 0.4490, -0.5221,  0.4061], device='cuda:0', requires_grad=True)\n",
      "lambda_f.29.6.weight Parameter containing:\n",
      "tensor([[ 0.1617, -0.3129, -0.2468]], device='cuda:0', requires_grad=True)\n",
      "lambda_f.29.6.bias Parameter containing:\n",
      "tensor([-0.2980], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMING check:\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.179,\n",
       " 8.65713,\n",
       " 0.17863,\n",
       " 0.08955,\n",
       " 0.54383,\n",
       " 0.05061,\n",
       " 0.6451956927776337,\n",
       " array(1.1601645, dtype=float32),\n",
       " 1.096644,\n",
       " 0.014583419214124765)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Plot = False\n",
    "if TRAIN == True:\n",
    "    print('Training the glasso model')\n",
    "    print('check: ', train_data[0].shape, train_data[1].shape)\n",
    "    nmse_model, ps_model = train_glasso(train_data, val_data)\n",
    "\n",
    "model = nmse_model  # shd_model # or nmse_model\n",
    "\n",
    "torch.save(nmse_model.state_dict(), model_path)\n",
    "\n",
    "print('TIMING check:')\n",
    "glasso_predict(model, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained: Predicting on...\n",
      "****Train Data, same pred matrix, different samples****\n",
      "****Test Data, model_NMSE: average results over different samples****\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  64\n",
      "Adjusting the minimum eigenvalue to 1, SHOULD NOT BE CALLED AFTER THE GAMMA ADDITION!\n",
      "Adjusting the minimum eigenvalue to 1, SHOULD NOT BE CALLED AFTER THE GAMMA ADDITION!\n",
      "Adjusting the minimum eigenvalue to 1, SHOULD NOT BE CALLED AFTER THE GAMMA ADDITION!\n",
      "Structure learning Metrics\n",
      "Average result over test graphs\n",
      "FDRs, TPRs, FPRs, SHDs, Ts, Ps, precisions, recalls, F_betas, auprs, aucs\n",
      "nan, nan, 0.08561, 0.12144, 0.01128, 0.04226, 19.21875, 6.78802, 18.93750, 3.79092, 3.56250, 9.14104, nan, nan, 0.08561, 0.12144, 0.11853, 0.12507, 0.16947, 0.09362, 0.53874, 0.05119\n",
      "(3.5625, 9.14104, 0.16947, 0.09362, 0.53874, 0.05119, 1.4715729653835297, array(1.4033219, dtype=float32), 1.1230464, 0.1756373496116388)\n",
      "****Test Data, tag: model_SHD : average results over different samples****\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  64\n",
      "Structure learning Metrics\n",
      "Average result over test graphs\n",
      "FDRs, TPRs, FPRs, SHDs, Ts, Ps, precisions, recalls, F_betas, auprs, aucs\n",
      "nan, nan, 0.20322, 0.18509, 0.05799, 0.09802, 24.96875, 14.12994, 18.93750, 3.79092, 13.78125, 19.92131, nan, nan, 0.20322, 0.18509, 0.20725, 0.11959, 0.23997, 0.10958, 0.57914, 0.06603\n",
      "(13.78125, 19.92131, 0.23997, 0.10958, 0.57914, 0.06603, 3.438950479030609, array(2.2074711, dtype=float32), 2.0844219, 0.9891717288593245)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('model trained: Predicting on...')\n",
    "# torch.save(model.state_dict(), 'Gista_model.pt')\n",
    "print('****Train Data, same pred matrix, different samples****')\n",
    "#glasso_predict(nmse_model, train_data, True)\n",
    "# res_train = glasso_predict(model, train_data, True)\n",
    "# print(res_train)\n",
    "# if len(valid_data)>0:\n",
    "#     print('****Valid Data****')\n",
    "#     #glasso_predict(nmse_model, valid_data, True)\n",
    "#     glasso_predict(model, valid_data, True)\n",
    "print('****Test Data, model_NMSE: average results over different samples****')\n",
    "res_test_model_NMSE = glasso_predict(model, test_data, True)\n",
    "print(res_test_model_NMSE)\n",
    "print('****Test Data, tag: model_SHD : average results over different samples****')\n",
    "res_test_model_SHD = glasso_predict(ps_model, test_data, True)\n",
    "print(res_test_model_SHD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shifting to cuda\n",
      "CHECK RHO INITIAL:  Parameter containing:\n",
      "tensor([[-0.3799, -0.0895, -0.3191],\n",
      "        [-0.0772, -0.0326, -0.2469],\n",
      "        [ 0.1088,  0.3374, -0.1493]], device='cuda:0', requires_grad=True)\n",
      "Running unrolled ADMM predict\n",
      "CEHCKK: Total graphs =  64\n",
      "Structure learning Metrics\n",
      "Average result over test graphs\n",
      "FDRs, TPRs, FPRs, SHDs, Ts, Ps, precisions, recalls, F_betas, auprs, aucs\n",
      "0.81002, 0.08219, 0.99870, 0.01033, 0.56839, 0.24181, 96.53125, 40.09246, 18.93750, 3.79092, 115.43750, 43.11499, 0.18998, 0.08219, 0.99870, 0.01033, 0.31193, 0.10171, 0.43186, 0.08604, 0.81742, 0.05214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(115.4375,\n",
       " 43.11499,\n",
       " 0.43186,\n",
       " 0.08604,\n",
       " 0.81742,\n",
       " 0.05214,\n",
       " 10.987707376480103,\n",
       " array(12.553672, dtype=float32),\n",
       " 26.037508,\n",
       " 7.124815483485574)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"M100_N20_Ktrain10_gtBA_prob0.1_bs10_L30_lr0.004.pth\"\n",
    "# load model\n",
    "model  = threshold_NN_lambda_unrolled_model(L, rho_init, lambda_init, theta_init_offset, gamma_init, N, nF, H, USE_CUDA=USE_CUDA)\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "Plot = False\n",
    "glasso_predict(model, test_data, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-glad] *",
   "language": "python",
   "name": "conda-env-.conda-glad-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}